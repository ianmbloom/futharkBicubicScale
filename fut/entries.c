// Generated by Futhark 0.22.0
// git: 0dff108 (Tue Jan 4 13:33:44 2022 +0100)

// We need to define _GNU_SOURCE before
// _any_ headers files are imported to get
// the usage statistics of a thread (i.e. have RUSAGE_THREAD) on GNU/Linux
// https://manpages.courier-mta.org/htmlman2/getrusage.2.html
#ifndef _GNU_SOURCE // Avoid possible double-definition warning.
#define _GNU_SOURCE
#endif

#ifdef __clang__
#pragma clang diagnostic ignored "-Wunused-function"
#pragma clang diagnostic ignored "-Wunused-variable"
#pragma clang diagnostic ignored "-Wparentheses"
#pragma clang diagnostic ignored "-Wunused-label"
#elif __GNUC__
#pragma GCC diagnostic ignored "-Wunused-function"
#pragma GCC diagnostic ignored "-Wunused-variable"
#pragma GCC diagnostic ignored "-Wparentheses"
#pragma GCC diagnostic ignored "-Wunused-label"
#pragma GCC diagnostic ignored "-Wunused-but-set-variable"
#endif

// Headers\n")
#include <stdint.h>
#include <stddef.h>
#include <stdbool.h>
#include <stdio.h>
#include <float.h>

#include <cuda.h>
#include <cuda_runtime.h>
#include <nvrtc.h>

#ifdef __cplusplus
extern "C" {
#endif

// Initialisation
struct futhark_context_config;
struct futhark_context_config *futhark_context_config_new(void);
void futhark_context_config_free(struct futhark_context_config *cfg);
void futhark_context_config_add_nvrtc_option(struct futhark_context_config *cfg,
                                             const char *opt);
void futhark_context_config_set_debugging(struct futhark_context_config *cfg,
                                          int flag);
void futhark_context_config_set_profiling(struct futhark_context_config *cfg,
                                          int flag);
void futhark_context_config_set_logging(struct futhark_context_config *cfg,
                                        int flag);
void futhark_context_config_set_device(struct futhark_context_config *cfg, const
                                       char *s);
void futhark_context_config_dump_program_to(struct futhark_context_config *cfg,
                                            const char *path);
void
futhark_context_config_load_program_from(struct futhark_context_config *cfg,
                                         const char *path);
void futhark_context_config_dump_ptx_to(struct futhark_context_config *cfg,
                                        const char *path);
void futhark_context_config_load_ptx_from(struct futhark_context_config *cfg,
                                          const char *path);
void
futhark_context_config_set_default_group_size(struct futhark_context_config *cfg,
                                              int size);
void
futhark_context_config_set_default_num_groups(struct futhark_context_config *cfg,
                                              int num);
void
futhark_context_config_set_default_tile_size(struct futhark_context_config *cfg,
                                             int num);
void
futhark_context_config_set_default_reg_tile_size(struct futhark_context_config *cfg,
                                                 int num);
void
futhark_context_config_set_default_threshold(struct futhark_context_config *cfg,
                                             int num);
int futhark_context_config_set_tuning_param(struct futhark_context_config *cfg,
                                            const char *param_name,
                                            size_t new_value);
struct futhark_context;
struct futhark_context *futhark_context_new(struct futhark_context_config *cfg);
void futhark_context_free(struct futhark_context *ctx);
int futhark_get_tuning_param_count(void);
const char *futhark_get_tuning_param_name(int);
const char *futhark_get_tuning_param_class(int);

// Arrays
struct futhark_f32_3d;
struct futhark_f32_3d *futhark_new_f32_3d(struct futhark_context *ctx, const
                                          float *data, int64_t dim0,
                                          int64_t dim1, int64_t dim2);
struct futhark_f32_3d *futhark_new_raw_f32_3d(struct futhark_context *ctx, const
                                              CUdeviceptr data, int64_t offset,
                                              int64_t dim0, int64_t dim1,
                                              int64_t dim2);
int futhark_free_f32_3d(struct futhark_context *ctx,
                        struct futhark_f32_3d *arr);
int futhark_values_f32_3d(struct futhark_context *ctx,
                          struct futhark_f32_3d *arr, float *data);
CUdeviceptr futhark_values_raw_f32_3d(struct futhark_context *ctx,
                                      struct futhark_f32_3d *arr);
const int64_t *futhark_shape_f32_3d(struct futhark_context *ctx,
                                    struct futhark_f32_3d *arr);
struct futhark_i64_3d;
struct futhark_i64_3d *futhark_new_i64_3d(struct futhark_context *ctx, const
                                          int64_t *data, int64_t dim0,
                                          int64_t dim1, int64_t dim2);
struct futhark_i64_3d *futhark_new_raw_i64_3d(struct futhark_context *ctx, const
                                              CUdeviceptr data, int64_t offset,
                                              int64_t dim0, int64_t dim1,
                                              int64_t dim2);
int futhark_free_i64_3d(struct futhark_context *ctx,
                        struct futhark_i64_3d *arr);
int futhark_values_i64_3d(struct futhark_context *ctx,
                          struct futhark_i64_3d *arr, int64_t *data);
CUdeviceptr futhark_values_raw_i64_3d(struct futhark_context *ctx,
                                      struct futhark_i64_3d *arr);
const int64_t *futhark_shape_i64_3d(struct futhark_context *ctx,
                                    struct futhark_i64_3d *arr);

// Opaque values


// Entry points
int futhark_entry_bicubicInterpolationImage(struct futhark_context *ctx,
                                            struct futhark_f32_3d **out0, const
                                            int64_t in0, const int64_t in1,
                                            const struct futhark_f32_3d *in2);
int futhark_entry_shuffler(struct futhark_context *ctx,
                           struct futhark_i64_3d **out0, const int64_t in0,
                           const int64_t in1, const int64_t in2);

// Miscellaneous
int futhark_context_sync(struct futhark_context *ctx);
char *futhark_context_report(struct futhark_context *ctx);
char *futhark_context_get_error(struct futhark_context *ctx);
void futhark_context_set_logging_file(struct futhark_context *ctx, FILE *f);
void futhark_context_pause_profiling(struct futhark_context *ctx);
void futhark_context_unpause_profiling(struct futhark_context *ctx);
int futhark_context_clear_caches(struct futhark_context *ctx);
#define FUTHARK_BACKEND_cuda

#ifdef __cplusplus
}
#endif

#include <stdio.h>
#include <stdlib.h>
#include <stdbool.h>
#include <math.h>
#include <stdint.h>
// If NDEBUG is set, the assert() macro will do nothing. Since Futhark
// (unfortunately) makes use of assert() for error detection (and even some
// side effects), we want to avoid that.
#undef NDEBUG
#include <assert.h>
#include <stdarg.h>
// Start of util.h.
//
// Various helper functions that are useful in all generated C code.

#include <errno.h>
#include <string.h>

static const char *fut_progname = "(embedded Futhark)";

static void futhark_panic(int eval, const char *fmt, ...) __attribute__((noreturn));
static char* msgprintf(const char *s, ...);
static void* slurp_file(const char *filename, size_t *size);
static int dump_file(const char *file, const void *buf, size_t n);
struct str_builder;
static void str_builder_init(struct str_builder *b);
static void str_builder(struct str_builder *b, const char *s, ...);

static void futhark_panic(int eval, const char *fmt, ...) {
  va_list ap;
  va_start(ap, fmt);
  fprintf(stderr, "%s: ", fut_progname);
  vfprintf(stderr, fmt, ap);
  va_end(ap);
  exit(eval);
}

// For generating arbitrary-sized error messages.  It is the callers
// responsibility to free the buffer at some point.
static char* msgprintf(const char *s, ...) {
  va_list vl;
  va_start(vl, s);
  size_t needed = 1 + (size_t)vsnprintf(NULL, 0, s, vl);
  char *buffer = (char*) malloc(needed);
  va_start(vl, s); // Must re-init.
  vsnprintf(buffer, needed, s, vl);
  return buffer;
}

static inline void check_err(int errval, int sets_errno, const char *fun, int line,
                            const char *msg, ...) {
  if (errval) {
    char errnum[10];

    va_list vl;
    va_start(vl, msg);

    fprintf(stderr, "ERROR: ");
    vfprintf(stderr, msg, vl);
    fprintf(stderr, " in %s() at line %d with error code %s\n",
            fun, line,
            sets_errno ? strerror(errno) : errnum);
    exit(errval);
  }
}

#define CHECK_ERR(err, ...) check_err(err, 0, __func__, __LINE__, __VA_ARGS__)
#define CHECK_ERRNO(err, ...) check_err(err, 1, __func__, __LINE__, __VA_ARGS__)

// Read the rest of an open file into a NUL-terminated string; returns
// NULL on error.
static void* fslurp_file(FILE *f, size_t *size) {
  long start = ftell(f);
  fseek(f, 0, SEEK_END);
  long src_size = ftell(f)-start;
  fseek(f, start, SEEK_SET);
  unsigned char *s = (unsigned char*) malloc((size_t)src_size + 1);
  if (fread(s, 1, (size_t)src_size, f) != (size_t)src_size) {
    free(s);
    s = NULL;
  } else {
    s[src_size] = '\0';
  }

  if (size) {
    *size = (size_t)src_size;
  }

  return s;
}

// Read a file into a NUL-terminated string; returns NULL on error.
static void* slurp_file(const char *filename, size_t *size) {
  FILE *f = fopen(filename, "rb"); // To avoid Windows messing with linebreaks.
  if (f == NULL) return NULL;
  unsigned char *s = fslurp_file(f, size);
  fclose(f);
  return s;
}

// Dump 'n' bytes from 'buf' into the file at the designated location.
// Returns 0 on success.
static int dump_file(const char *file, const void *buf, size_t n) {
  FILE *f = fopen(file, "w");

  if (f == NULL) {
    return 1;
  }

  if (fwrite(buf, sizeof(char), n, f) != n) {
    return 1;
  }

  if (fclose(f) != 0) {
    return 1;
  }

  return 0;
}

struct str_builder {
  char *str;
  size_t capacity; // Size of buffer.
  size_t used; // Bytes used, *not* including final zero.
};

static void str_builder_init(struct str_builder *b) {
  b->capacity = 10;
  b->used = 0;
  b->str = malloc(b->capacity);
  b->str[0] = 0;
}

static void str_builder(struct str_builder *b, const char *s, ...) {
  va_list vl;
  va_start(vl, s);
  size_t needed = (size_t)vsnprintf(NULL, 0, s, vl);

  while (b->capacity < b->used + needed + 1) {
    b->capacity *= 2;
    b->str = realloc(b->str, b->capacity);
  }

  va_start(vl, s); // Must re-init.
  vsnprintf(b->str+b->used, b->capacity-b->used, s, vl);
  b->used += needed;
}

// End of util.h.
// Start of half.h.

// Conversion functions are from http://half.sourceforge.net/, but
// translated to C.
//
// Copyright (c) 2012-2021 Christian Rau
//
// Permission is hereby granted, free of charge, to any person obtaining a copy
// of this software and associated documentation files (the "Software"), to deal
// in the Software without restriction, including without limitation the rights
// to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
// copies of the Software, and to permit persons to whom the Software is
// furnished to do so, subject to the following conditions:
//
// The above copyright notice and this permission notice shall be included in
// all copies or substantial portions of the Software.
//
// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
// THE SOFTWARE.

#ifndef __OPENCL_VERSION__
#define __constant
#endif

__constant static const uint16_t base_table[512] = {
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0001, 0x0002, 0x0004, 0x0008, 0x0010, 0x0020, 0x0040, 0x0080, 0x0100,
  0x0200, 0x0400, 0x0800, 0x0C00, 0x1000, 0x1400, 0x1800, 0x1C00, 0x2000, 0x2400, 0x2800, 0x2C00, 0x3000, 0x3400, 0x3800, 0x3C00,
  0x4000, 0x4400, 0x4800, 0x4C00, 0x5000, 0x5400, 0x5800, 0x5C00, 0x6000, 0x6400, 0x6800, 0x6C00, 0x7000, 0x7400, 0x7800, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8001, 0x8002, 0x8004, 0x8008, 0x8010, 0x8020, 0x8040, 0x8080, 0x8100,
  0x8200, 0x8400, 0x8800, 0x8C00, 0x9000, 0x9400, 0x9800, 0x9C00, 0xA000, 0xA400, 0xA800, 0xAC00, 0xB000, 0xB400, 0xB800, 0xBC00,
  0xC000, 0xC400, 0xC800, 0xCC00, 0xD000, 0xD400, 0xD800, 0xDC00, 0xE000, 0xE400, 0xE800, 0xEC00, 0xF000, 0xF400, 0xF800, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00 };

__constant static const unsigned char shift_table[512] = {
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,
  13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 13,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,
  13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 13 };

__constant static const uint32_t mantissa_table[2048] = {
  0x00000000, 0x33800000, 0x34000000, 0x34400000, 0x34800000, 0x34A00000, 0x34C00000, 0x34E00000, 0x35000000, 0x35100000, 0x35200000, 0x35300000, 0x35400000, 0x35500000, 0x35600000, 0x35700000,
  0x35800000, 0x35880000, 0x35900000, 0x35980000, 0x35A00000, 0x35A80000, 0x35B00000, 0x35B80000, 0x35C00000, 0x35C80000, 0x35D00000, 0x35D80000, 0x35E00000, 0x35E80000, 0x35F00000, 0x35F80000,
  0x36000000, 0x36040000, 0x36080000, 0x360C0000, 0x36100000, 0x36140000, 0x36180000, 0x361C0000, 0x36200000, 0x36240000, 0x36280000, 0x362C0000, 0x36300000, 0x36340000, 0x36380000, 0x363C0000,
  0x36400000, 0x36440000, 0x36480000, 0x364C0000, 0x36500000, 0x36540000, 0x36580000, 0x365C0000, 0x36600000, 0x36640000, 0x36680000, 0x366C0000, 0x36700000, 0x36740000, 0x36780000, 0x367C0000,
  0x36800000, 0x36820000, 0x36840000, 0x36860000, 0x36880000, 0x368A0000, 0x368C0000, 0x368E0000, 0x36900000, 0x36920000, 0x36940000, 0x36960000, 0x36980000, 0x369A0000, 0x369C0000, 0x369E0000,
  0x36A00000, 0x36A20000, 0x36A40000, 0x36A60000, 0x36A80000, 0x36AA0000, 0x36AC0000, 0x36AE0000, 0x36B00000, 0x36B20000, 0x36B40000, 0x36B60000, 0x36B80000, 0x36BA0000, 0x36BC0000, 0x36BE0000,
  0x36C00000, 0x36C20000, 0x36C40000, 0x36C60000, 0x36C80000, 0x36CA0000, 0x36CC0000, 0x36CE0000, 0x36D00000, 0x36D20000, 0x36D40000, 0x36D60000, 0x36D80000, 0x36DA0000, 0x36DC0000, 0x36DE0000,
  0x36E00000, 0x36E20000, 0x36E40000, 0x36E60000, 0x36E80000, 0x36EA0000, 0x36EC0000, 0x36EE0000, 0x36F00000, 0x36F20000, 0x36F40000, 0x36F60000, 0x36F80000, 0x36FA0000, 0x36FC0000, 0x36FE0000,
  0x37000000, 0x37010000, 0x37020000, 0x37030000, 0x37040000, 0x37050000, 0x37060000, 0x37070000, 0x37080000, 0x37090000, 0x370A0000, 0x370B0000, 0x370C0000, 0x370D0000, 0x370E0000, 0x370F0000,
  0x37100000, 0x37110000, 0x37120000, 0x37130000, 0x37140000, 0x37150000, 0x37160000, 0x37170000, 0x37180000, 0x37190000, 0x371A0000, 0x371B0000, 0x371C0000, 0x371D0000, 0x371E0000, 0x371F0000,
  0x37200000, 0x37210000, 0x37220000, 0x37230000, 0x37240000, 0x37250000, 0x37260000, 0x37270000, 0x37280000, 0x37290000, 0x372A0000, 0x372B0000, 0x372C0000, 0x372D0000, 0x372E0000, 0x372F0000,
  0x37300000, 0x37310000, 0x37320000, 0x37330000, 0x37340000, 0x37350000, 0x37360000, 0x37370000, 0x37380000, 0x37390000, 0x373A0000, 0x373B0000, 0x373C0000, 0x373D0000, 0x373E0000, 0x373F0000,
  0x37400000, 0x37410000, 0x37420000, 0x37430000, 0x37440000, 0x37450000, 0x37460000, 0x37470000, 0x37480000, 0x37490000, 0x374A0000, 0x374B0000, 0x374C0000, 0x374D0000, 0x374E0000, 0x374F0000,
  0x37500000, 0x37510000, 0x37520000, 0x37530000, 0x37540000, 0x37550000, 0x37560000, 0x37570000, 0x37580000, 0x37590000, 0x375A0000, 0x375B0000, 0x375C0000, 0x375D0000, 0x375E0000, 0x375F0000,
  0x37600000, 0x37610000, 0x37620000, 0x37630000, 0x37640000, 0x37650000, 0x37660000, 0x37670000, 0x37680000, 0x37690000, 0x376A0000, 0x376B0000, 0x376C0000, 0x376D0000, 0x376E0000, 0x376F0000,
  0x37700000, 0x37710000, 0x37720000, 0x37730000, 0x37740000, 0x37750000, 0x37760000, 0x37770000, 0x37780000, 0x37790000, 0x377A0000, 0x377B0000, 0x377C0000, 0x377D0000, 0x377E0000, 0x377F0000,
  0x37800000, 0x37808000, 0x37810000, 0x37818000, 0x37820000, 0x37828000, 0x37830000, 0x37838000, 0x37840000, 0x37848000, 0x37850000, 0x37858000, 0x37860000, 0x37868000, 0x37870000, 0x37878000,
  0x37880000, 0x37888000, 0x37890000, 0x37898000, 0x378A0000, 0x378A8000, 0x378B0000, 0x378B8000, 0x378C0000, 0x378C8000, 0x378D0000, 0x378D8000, 0x378E0000, 0x378E8000, 0x378F0000, 0x378F8000,
  0x37900000, 0x37908000, 0x37910000, 0x37918000, 0x37920000, 0x37928000, 0x37930000, 0x37938000, 0x37940000, 0x37948000, 0x37950000, 0x37958000, 0x37960000, 0x37968000, 0x37970000, 0x37978000,
  0x37980000, 0x37988000, 0x37990000, 0x37998000, 0x379A0000, 0x379A8000, 0x379B0000, 0x379B8000, 0x379C0000, 0x379C8000, 0x379D0000, 0x379D8000, 0x379E0000, 0x379E8000, 0x379F0000, 0x379F8000,
  0x37A00000, 0x37A08000, 0x37A10000, 0x37A18000, 0x37A20000, 0x37A28000, 0x37A30000, 0x37A38000, 0x37A40000, 0x37A48000, 0x37A50000, 0x37A58000, 0x37A60000, 0x37A68000, 0x37A70000, 0x37A78000,
  0x37A80000, 0x37A88000, 0x37A90000, 0x37A98000, 0x37AA0000, 0x37AA8000, 0x37AB0000, 0x37AB8000, 0x37AC0000, 0x37AC8000, 0x37AD0000, 0x37AD8000, 0x37AE0000, 0x37AE8000, 0x37AF0000, 0x37AF8000,
  0x37B00000, 0x37B08000, 0x37B10000, 0x37B18000, 0x37B20000, 0x37B28000, 0x37B30000, 0x37B38000, 0x37B40000, 0x37B48000, 0x37B50000, 0x37B58000, 0x37B60000, 0x37B68000, 0x37B70000, 0x37B78000,
  0x37B80000, 0x37B88000, 0x37B90000, 0x37B98000, 0x37BA0000, 0x37BA8000, 0x37BB0000, 0x37BB8000, 0x37BC0000, 0x37BC8000, 0x37BD0000, 0x37BD8000, 0x37BE0000, 0x37BE8000, 0x37BF0000, 0x37BF8000,
  0x37C00000, 0x37C08000, 0x37C10000, 0x37C18000, 0x37C20000, 0x37C28000, 0x37C30000, 0x37C38000, 0x37C40000, 0x37C48000, 0x37C50000, 0x37C58000, 0x37C60000, 0x37C68000, 0x37C70000, 0x37C78000,
  0x37C80000, 0x37C88000, 0x37C90000, 0x37C98000, 0x37CA0000, 0x37CA8000, 0x37CB0000, 0x37CB8000, 0x37CC0000, 0x37CC8000, 0x37CD0000, 0x37CD8000, 0x37CE0000, 0x37CE8000, 0x37CF0000, 0x37CF8000,
  0x37D00000, 0x37D08000, 0x37D10000, 0x37D18000, 0x37D20000, 0x37D28000, 0x37D30000, 0x37D38000, 0x37D40000, 0x37D48000, 0x37D50000, 0x37D58000, 0x37D60000, 0x37D68000, 0x37D70000, 0x37D78000,
  0x37D80000, 0x37D88000, 0x37D90000, 0x37D98000, 0x37DA0000, 0x37DA8000, 0x37DB0000, 0x37DB8000, 0x37DC0000, 0x37DC8000, 0x37DD0000, 0x37DD8000, 0x37DE0000, 0x37DE8000, 0x37DF0000, 0x37DF8000,
  0x37E00000, 0x37E08000, 0x37E10000, 0x37E18000, 0x37E20000, 0x37E28000, 0x37E30000, 0x37E38000, 0x37E40000, 0x37E48000, 0x37E50000, 0x37E58000, 0x37E60000, 0x37E68000, 0x37E70000, 0x37E78000,
  0x37E80000, 0x37E88000, 0x37E90000, 0x37E98000, 0x37EA0000, 0x37EA8000, 0x37EB0000, 0x37EB8000, 0x37EC0000, 0x37EC8000, 0x37ED0000, 0x37ED8000, 0x37EE0000, 0x37EE8000, 0x37EF0000, 0x37EF8000,
  0x37F00000, 0x37F08000, 0x37F10000, 0x37F18000, 0x37F20000, 0x37F28000, 0x37F30000, 0x37F38000, 0x37F40000, 0x37F48000, 0x37F50000, 0x37F58000, 0x37F60000, 0x37F68000, 0x37F70000, 0x37F78000,
  0x37F80000, 0x37F88000, 0x37F90000, 0x37F98000, 0x37FA0000, 0x37FA8000, 0x37FB0000, 0x37FB8000, 0x37FC0000, 0x37FC8000, 0x37FD0000, 0x37FD8000, 0x37FE0000, 0x37FE8000, 0x37FF0000, 0x37FF8000,
  0x38000000, 0x38004000, 0x38008000, 0x3800C000, 0x38010000, 0x38014000, 0x38018000, 0x3801C000, 0x38020000, 0x38024000, 0x38028000, 0x3802C000, 0x38030000, 0x38034000, 0x38038000, 0x3803C000,
  0x38040000, 0x38044000, 0x38048000, 0x3804C000, 0x38050000, 0x38054000, 0x38058000, 0x3805C000, 0x38060000, 0x38064000, 0x38068000, 0x3806C000, 0x38070000, 0x38074000, 0x38078000, 0x3807C000,
  0x38080000, 0x38084000, 0x38088000, 0x3808C000, 0x38090000, 0x38094000, 0x38098000, 0x3809C000, 0x380A0000, 0x380A4000, 0x380A8000, 0x380AC000, 0x380B0000, 0x380B4000, 0x380B8000, 0x380BC000,
  0x380C0000, 0x380C4000, 0x380C8000, 0x380CC000, 0x380D0000, 0x380D4000, 0x380D8000, 0x380DC000, 0x380E0000, 0x380E4000, 0x380E8000, 0x380EC000, 0x380F0000, 0x380F4000, 0x380F8000, 0x380FC000,
  0x38100000, 0x38104000, 0x38108000, 0x3810C000, 0x38110000, 0x38114000, 0x38118000, 0x3811C000, 0x38120000, 0x38124000, 0x38128000, 0x3812C000, 0x38130000, 0x38134000, 0x38138000, 0x3813C000,
  0x38140000, 0x38144000, 0x38148000, 0x3814C000, 0x38150000, 0x38154000, 0x38158000, 0x3815C000, 0x38160000, 0x38164000, 0x38168000, 0x3816C000, 0x38170000, 0x38174000, 0x38178000, 0x3817C000,
  0x38180000, 0x38184000, 0x38188000, 0x3818C000, 0x38190000, 0x38194000, 0x38198000, 0x3819C000, 0x381A0000, 0x381A4000, 0x381A8000, 0x381AC000, 0x381B0000, 0x381B4000, 0x381B8000, 0x381BC000,
  0x381C0000, 0x381C4000, 0x381C8000, 0x381CC000, 0x381D0000, 0x381D4000, 0x381D8000, 0x381DC000, 0x381E0000, 0x381E4000, 0x381E8000, 0x381EC000, 0x381F0000, 0x381F4000, 0x381F8000, 0x381FC000,
  0x38200000, 0x38204000, 0x38208000, 0x3820C000, 0x38210000, 0x38214000, 0x38218000, 0x3821C000, 0x38220000, 0x38224000, 0x38228000, 0x3822C000, 0x38230000, 0x38234000, 0x38238000, 0x3823C000,
  0x38240000, 0x38244000, 0x38248000, 0x3824C000, 0x38250000, 0x38254000, 0x38258000, 0x3825C000, 0x38260000, 0x38264000, 0x38268000, 0x3826C000, 0x38270000, 0x38274000, 0x38278000, 0x3827C000,
  0x38280000, 0x38284000, 0x38288000, 0x3828C000, 0x38290000, 0x38294000, 0x38298000, 0x3829C000, 0x382A0000, 0x382A4000, 0x382A8000, 0x382AC000, 0x382B0000, 0x382B4000, 0x382B8000, 0x382BC000,
  0x382C0000, 0x382C4000, 0x382C8000, 0x382CC000, 0x382D0000, 0x382D4000, 0x382D8000, 0x382DC000, 0x382E0000, 0x382E4000, 0x382E8000, 0x382EC000, 0x382F0000, 0x382F4000, 0x382F8000, 0x382FC000,
  0x38300000, 0x38304000, 0x38308000, 0x3830C000, 0x38310000, 0x38314000, 0x38318000, 0x3831C000, 0x38320000, 0x38324000, 0x38328000, 0x3832C000, 0x38330000, 0x38334000, 0x38338000, 0x3833C000,
  0x38340000, 0x38344000, 0x38348000, 0x3834C000, 0x38350000, 0x38354000, 0x38358000, 0x3835C000, 0x38360000, 0x38364000, 0x38368000, 0x3836C000, 0x38370000, 0x38374000, 0x38378000, 0x3837C000,
  0x38380000, 0x38384000, 0x38388000, 0x3838C000, 0x38390000, 0x38394000, 0x38398000, 0x3839C000, 0x383A0000, 0x383A4000, 0x383A8000, 0x383AC000, 0x383B0000, 0x383B4000, 0x383B8000, 0x383BC000,
  0x383C0000, 0x383C4000, 0x383C8000, 0x383CC000, 0x383D0000, 0x383D4000, 0x383D8000, 0x383DC000, 0x383E0000, 0x383E4000, 0x383E8000, 0x383EC000, 0x383F0000, 0x383F4000, 0x383F8000, 0x383FC000,
  0x38400000, 0x38404000, 0x38408000, 0x3840C000, 0x38410000, 0x38414000, 0x38418000, 0x3841C000, 0x38420000, 0x38424000, 0x38428000, 0x3842C000, 0x38430000, 0x38434000, 0x38438000, 0x3843C000,
  0x38440000, 0x38444000, 0x38448000, 0x3844C000, 0x38450000, 0x38454000, 0x38458000, 0x3845C000, 0x38460000, 0x38464000, 0x38468000, 0x3846C000, 0x38470000, 0x38474000, 0x38478000, 0x3847C000,
  0x38480000, 0x38484000, 0x38488000, 0x3848C000, 0x38490000, 0x38494000, 0x38498000, 0x3849C000, 0x384A0000, 0x384A4000, 0x384A8000, 0x384AC000, 0x384B0000, 0x384B4000, 0x384B8000, 0x384BC000,
  0x384C0000, 0x384C4000, 0x384C8000, 0x384CC000, 0x384D0000, 0x384D4000, 0x384D8000, 0x384DC000, 0x384E0000, 0x384E4000, 0x384E8000, 0x384EC000, 0x384F0000, 0x384F4000, 0x384F8000, 0x384FC000,
  0x38500000, 0x38504000, 0x38508000, 0x3850C000, 0x38510000, 0x38514000, 0x38518000, 0x3851C000, 0x38520000, 0x38524000, 0x38528000, 0x3852C000, 0x38530000, 0x38534000, 0x38538000, 0x3853C000,
  0x38540000, 0x38544000, 0x38548000, 0x3854C000, 0x38550000, 0x38554000, 0x38558000, 0x3855C000, 0x38560000, 0x38564000, 0x38568000, 0x3856C000, 0x38570000, 0x38574000, 0x38578000, 0x3857C000,
  0x38580000, 0x38584000, 0x38588000, 0x3858C000, 0x38590000, 0x38594000, 0x38598000, 0x3859C000, 0x385A0000, 0x385A4000, 0x385A8000, 0x385AC000, 0x385B0000, 0x385B4000, 0x385B8000, 0x385BC000,
  0x385C0000, 0x385C4000, 0x385C8000, 0x385CC000, 0x385D0000, 0x385D4000, 0x385D8000, 0x385DC000, 0x385E0000, 0x385E4000, 0x385E8000, 0x385EC000, 0x385F0000, 0x385F4000, 0x385F8000, 0x385FC000,
  0x38600000, 0x38604000, 0x38608000, 0x3860C000, 0x38610000, 0x38614000, 0x38618000, 0x3861C000, 0x38620000, 0x38624000, 0x38628000, 0x3862C000, 0x38630000, 0x38634000, 0x38638000, 0x3863C000,
  0x38640000, 0x38644000, 0x38648000, 0x3864C000, 0x38650000, 0x38654000, 0x38658000, 0x3865C000, 0x38660000, 0x38664000, 0x38668000, 0x3866C000, 0x38670000, 0x38674000, 0x38678000, 0x3867C000,
  0x38680000, 0x38684000, 0x38688000, 0x3868C000, 0x38690000, 0x38694000, 0x38698000, 0x3869C000, 0x386A0000, 0x386A4000, 0x386A8000, 0x386AC000, 0x386B0000, 0x386B4000, 0x386B8000, 0x386BC000,
  0x386C0000, 0x386C4000, 0x386C8000, 0x386CC000, 0x386D0000, 0x386D4000, 0x386D8000, 0x386DC000, 0x386E0000, 0x386E4000, 0x386E8000, 0x386EC000, 0x386F0000, 0x386F4000, 0x386F8000, 0x386FC000,
  0x38700000, 0x38704000, 0x38708000, 0x3870C000, 0x38710000, 0x38714000, 0x38718000, 0x3871C000, 0x38720000, 0x38724000, 0x38728000, 0x3872C000, 0x38730000, 0x38734000, 0x38738000, 0x3873C000,
  0x38740000, 0x38744000, 0x38748000, 0x3874C000, 0x38750000, 0x38754000, 0x38758000, 0x3875C000, 0x38760000, 0x38764000, 0x38768000, 0x3876C000, 0x38770000, 0x38774000, 0x38778000, 0x3877C000,
  0x38780000, 0x38784000, 0x38788000, 0x3878C000, 0x38790000, 0x38794000, 0x38798000, 0x3879C000, 0x387A0000, 0x387A4000, 0x387A8000, 0x387AC000, 0x387B0000, 0x387B4000, 0x387B8000, 0x387BC000,
  0x387C0000, 0x387C4000, 0x387C8000, 0x387CC000, 0x387D0000, 0x387D4000, 0x387D8000, 0x387DC000, 0x387E0000, 0x387E4000, 0x387E8000, 0x387EC000, 0x387F0000, 0x387F4000, 0x387F8000, 0x387FC000,
  0x38000000, 0x38002000, 0x38004000, 0x38006000, 0x38008000, 0x3800A000, 0x3800C000, 0x3800E000, 0x38010000, 0x38012000, 0x38014000, 0x38016000, 0x38018000, 0x3801A000, 0x3801C000, 0x3801E000,
  0x38020000, 0x38022000, 0x38024000, 0x38026000, 0x38028000, 0x3802A000, 0x3802C000, 0x3802E000, 0x38030000, 0x38032000, 0x38034000, 0x38036000, 0x38038000, 0x3803A000, 0x3803C000, 0x3803E000,
  0x38040000, 0x38042000, 0x38044000, 0x38046000, 0x38048000, 0x3804A000, 0x3804C000, 0x3804E000, 0x38050000, 0x38052000, 0x38054000, 0x38056000, 0x38058000, 0x3805A000, 0x3805C000, 0x3805E000,
  0x38060000, 0x38062000, 0x38064000, 0x38066000, 0x38068000, 0x3806A000, 0x3806C000, 0x3806E000, 0x38070000, 0x38072000, 0x38074000, 0x38076000, 0x38078000, 0x3807A000, 0x3807C000, 0x3807E000,
  0x38080000, 0x38082000, 0x38084000, 0x38086000, 0x38088000, 0x3808A000, 0x3808C000, 0x3808E000, 0x38090000, 0x38092000, 0x38094000, 0x38096000, 0x38098000, 0x3809A000, 0x3809C000, 0x3809E000,
  0x380A0000, 0x380A2000, 0x380A4000, 0x380A6000, 0x380A8000, 0x380AA000, 0x380AC000, 0x380AE000, 0x380B0000, 0x380B2000, 0x380B4000, 0x380B6000, 0x380B8000, 0x380BA000, 0x380BC000, 0x380BE000,
  0x380C0000, 0x380C2000, 0x380C4000, 0x380C6000, 0x380C8000, 0x380CA000, 0x380CC000, 0x380CE000, 0x380D0000, 0x380D2000, 0x380D4000, 0x380D6000, 0x380D8000, 0x380DA000, 0x380DC000, 0x380DE000,
  0x380E0000, 0x380E2000, 0x380E4000, 0x380E6000, 0x380E8000, 0x380EA000, 0x380EC000, 0x380EE000, 0x380F0000, 0x380F2000, 0x380F4000, 0x380F6000, 0x380F8000, 0x380FA000, 0x380FC000, 0x380FE000,
  0x38100000, 0x38102000, 0x38104000, 0x38106000, 0x38108000, 0x3810A000, 0x3810C000, 0x3810E000, 0x38110000, 0x38112000, 0x38114000, 0x38116000, 0x38118000, 0x3811A000, 0x3811C000, 0x3811E000,
  0x38120000, 0x38122000, 0x38124000, 0x38126000, 0x38128000, 0x3812A000, 0x3812C000, 0x3812E000, 0x38130000, 0x38132000, 0x38134000, 0x38136000, 0x38138000, 0x3813A000, 0x3813C000, 0x3813E000,
  0x38140000, 0x38142000, 0x38144000, 0x38146000, 0x38148000, 0x3814A000, 0x3814C000, 0x3814E000, 0x38150000, 0x38152000, 0x38154000, 0x38156000, 0x38158000, 0x3815A000, 0x3815C000, 0x3815E000,
  0x38160000, 0x38162000, 0x38164000, 0x38166000, 0x38168000, 0x3816A000, 0x3816C000, 0x3816E000, 0x38170000, 0x38172000, 0x38174000, 0x38176000, 0x38178000, 0x3817A000, 0x3817C000, 0x3817E000,
  0x38180000, 0x38182000, 0x38184000, 0x38186000, 0x38188000, 0x3818A000, 0x3818C000, 0x3818E000, 0x38190000, 0x38192000, 0x38194000, 0x38196000, 0x38198000, 0x3819A000, 0x3819C000, 0x3819E000,
  0x381A0000, 0x381A2000, 0x381A4000, 0x381A6000, 0x381A8000, 0x381AA000, 0x381AC000, 0x381AE000, 0x381B0000, 0x381B2000, 0x381B4000, 0x381B6000, 0x381B8000, 0x381BA000, 0x381BC000, 0x381BE000,
  0x381C0000, 0x381C2000, 0x381C4000, 0x381C6000, 0x381C8000, 0x381CA000, 0x381CC000, 0x381CE000, 0x381D0000, 0x381D2000, 0x381D4000, 0x381D6000, 0x381D8000, 0x381DA000, 0x381DC000, 0x381DE000,
  0x381E0000, 0x381E2000, 0x381E4000, 0x381E6000, 0x381E8000, 0x381EA000, 0x381EC000, 0x381EE000, 0x381F0000, 0x381F2000, 0x381F4000, 0x381F6000, 0x381F8000, 0x381FA000, 0x381FC000, 0x381FE000,
  0x38200000, 0x38202000, 0x38204000, 0x38206000, 0x38208000, 0x3820A000, 0x3820C000, 0x3820E000, 0x38210000, 0x38212000, 0x38214000, 0x38216000, 0x38218000, 0x3821A000, 0x3821C000, 0x3821E000,
  0x38220000, 0x38222000, 0x38224000, 0x38226000, 0x38228000, 0x3822A000, 0x3822C000, 0x3822E000, 0x38230000, 0x38232000, 0x38234000, 0x38236000, 0x38238000, 0x3823A000, 0x3823C000, 0x3823E000,
  0x38240000, 0x38242000, 0x38244000, 0x38246000, 0x38248000, 0x3824A000, 0x3824C000, 0x3824E000, 0x38250000, 0x38252000, 0x38254000, 0x38256000, 0x38258000, 0x3825A000, 0x3825C000, 0x3825E000,
  0x38260000, 0x38262000, 0x38264000, 0x38266000, 0x38268000, 0x3826A000, 0x3826C000, 0x3826E000, 0x38270000, 0x38272000, 0x38274000, 0x38276000, 0x38278000, 0x3827A000, 0x3827C000, 0x3827E000,
  0x38280000, 0x38282000, 0x38284000, 0x38286000, 0x38288000, 0x3828A000, 0x3828C000, 0x3828E000, 0x38290000, 0x38292000, 0x38294000, 0x38296000, 0x38298000, 0x3829A000, 0x3829C000, 0x3829E000,
  0x382A0000, 0x382A2000, 0x382A4000, 0x382A6000, 0x382A8000, 0x382AA000, 0x382AC000, 0x382AE000, 0x382B0000, 0x382B2000, 0x382B4000, 0x382B6000, 0x382B8000, 0x382BA000, 0x382BC000, 0x382BE000,
  0x382C0000, 0x382C2000, 0x382C4000, 0x382C6000, 0x382C8000, 0x382CA000, 0x382CC000, 0x382CE000, 0x382D0000, 0x382D2000, 0x382D4000, 0x382D6000, 0x382D8000, 0x382DA000, 0x382DC000, 0x382DE000,
  0x382E0000, 0x382E2000, 0x382E4000, 0x382E6000, 0x382E8000, 0x382EA000, 0x382EC000, 0x382EE000, 0x382F0000, 0x382F2000, 0x382F4000, 0x382F6000, 0x382F8000, 0x382FA000, 0x382FC000, 0x382FE000,
  0x38300000, 0x38302000, 0x38304000, 0x38306000, 0x38308000, 0x3830A000, 0x3830C000, 0x3830E000, 0x38310000, 0x38312000, 0x38314000, 0x38316000, 0x38318000, 0x3831A000, 0x3831C000, 0x3831E000,
  0x38320000, 0x38322000, 0x38324000, 0x38326000, 0x38328000, 0x3832A000, 0x3832C000, 0x3832E000, 0x38330000, 0x38332000, 0x38334000, 0x38336000, 0x38338000, 0x3833A000, 0x3833C000, 0x3833E000,
  0x38340000, 0x38342000, 0x38344000, 0x38346000, 0x38348000, 0x3834A000, 0x3834C000, 0x3834E000, 0x38350000, 0x38352000, 0x38354000, 0x38356000, 0x38358000, 0x3835A000, 0x3835C000, 0x3835E000,
  0x38360000, 0x38362000, 0x38364000, 0x38366000, 0x38368000, 0x3836A000, 0x3836C000, 0x3836E000, 0x38370000, 0x38372000, 0x38374000, 0x38376000, 0x38378000, 0x3837A000, 0x3837C000, 0x3837E000,
  0x38380000, 0x38382000, 0x38384000, 0x38386000, 0x38388000, 0x3838A000, 0x3838C000, 0x3838E000, 0x38390000, 0x38392000, 0x38394000, 0x38396000, 0x38398000, 0x3839A000, 0x3839C000, 0x3839E000,
  0x383A0000, 0x383A2000, 0x383A4000, 0x383A6000, 0x383A8000, 0x383AA000, 0x383AC000, 0x383AE000, 0x383B0000, 0x383B2000, 0x383B4000, 0x383B6000, 0x383B8000, 0x383BA000, 0x383BC000, 0x383BE000,
  0x383C0000, 0x383C2000, 0x383C4000, 0x383C6000, 0x383C8000, 0x383CA000, 0x383CC000, 0x383CE000, 0x383D0000, 0x383D2000, 0x383D4000, 0x383D6000, 0x383D8000, 0x383DA000, 0x383DC000, 0x383DE000,
  0x383E0000, 0x383E2000, 0x383E4000, 0x383E6000, 0x383E8000, 0x383EA000, 0x383EC000, 0x383EE000, 0x383F0000, 0x383F2000, 0x383F4000, 0x383F6000, 0x383F8000, 0x383FA000, 0x383FC000, 0x383FE000,
  0x38400000, 0x38402000, 0x38404000, 0x38406000, 0x38408000, 0x3840A000, 0x3840C000, 0x3840E000, 0x38410000, 0x38412000, 0x38414000, 0x38416000, 0x38418000, 0x3841A000, 0x3841C000, 0x3841E000,
  0x38420000, 0x38422000, 0x38424000, 0x38426000, 0x38428000, 0x3842A000, 0x3842C000, 0x3842E000, 0x38430000, 0x38432000, 0x38434000, 0x38436000, 0x38438000, 0x3843A000, 0x3843C000, 0x3843E000,
  0x38440000, 0x38442000, 0x38444000, 0x38446000, 0x38448000, 0x3844A000, 0x3844C000, 0x3844E000, 0x38450000, 0x38452000, 0x38454000, 0x38456000, 0x38458000, 0x3845A000, 0x3845C000, 0x3845E000,
  0x38460000, 0x38462000, 0x38464000, 0x38466000, 0x38468000, 0x3846A000, 0x3846C000, 0x3846E000, 0x38470000, 0x38472000, 0x38474000, 0x38476000, 0x38478000, 0x3847A000, 0x3847C000, 0x3847E000,
  0x38480000, 0x38482000, 0x38484000, 0x38486000, 0x38488000, 0x3848A000, 0x3848C000, 0x3848E000, 0x38490000, 0x38492000, 0x38494000, 0x38496000, 0x38498000, 0x3849A000, 0x3849C000, 0x3849E000,
  0x384A0000, 0x384A2000, 0x384A4000, 0x384A6000, 0x384A8000, 0x384AA000, 0x384AC000, 0x384AE000, 0x384B0000, 0x384B2000, 0x384B4000, 0x384B6000, 0x384B8000, 0x384BA000, 0x384BC000, 0x384BE000,
  0x384C0000, 0x384C2000, 0x384C4000, 0x384C6000, 0x384C8000, 0x384CA000, 0x384CC000, 0x384CE000, 0x384D0000, 0x384D2000, 0x384D4000, 0x384D6000, 0x384D8000, 0x384DA000, 0x384DC000, 0x384DE000,
  0x384E0000, 0x384E2000, 0x384E4000, 0x384E6000, 0x384E8000, 0x384EA000, 0x384EC000, 0x384EE000, 0x384F0000, 0x384F2000, 0x384F4000, 0x384F6000, 0x384F8000, 0x384FA000, 0x384FC000, 0x384FE000,
  0x38500000, 0x38502000, 0x38504000, 0x38506000, 0x38508000, 0x3850A000, 0x3850C000, 0x3850E000, 0x38510000, 0x38512000, 0x38514000, 0x38516000, 0x38518000, 0x3851A000, 0x3851C000, 0x3851E000,
  0x38520000, 0x38522000, 0x38524000, 0x38526000, 0x38528000, 0x3852A000, 0x3852C000, 0x3852E000, 0x38530000, 0x38532000, 0x38534000, 0x38536000, 0x38538000, 0x3853A000, 0x3853C000, 0x3853E000,
  0x38540000, 0x38542000, 0x38544000, 0x38546000, 0x38548000, 0x3854A000, 0x3854C000, 0x3854E000, 0x38550000, 0x38552000, 0x38554000, 0x38556000, 0x38558000, 0x3855A000, 0x3855C000, 0x3855E000,
  0x38560000, 0x38562000, 0x38564000, 0x38566000, 0x38568000, 0x3856A000, 0x3856C000, 0x3856E000, 0x38570000, 0x38572000, 0x38574000, 0x38576000, 0x38578000, 0x3857A000, 0x3857C000, 0x3857E000,
  0x38580000, 0x38582000, 0x38584000, 0x38586000, 0x38588000, 0x3858A000, 0x3858C000, 0x3858E000, 0x38590000, 0x38592000, 0x38594000, 0x38596000, 0x38598000, 0x3859A000, 0x3859C000, 0x3859E000,
  0x385A0000, 0x385A2000, 0x385A4000, 0x385A6000, 0x385A8000, 0x385AA000, 0x385AC000, 0x385AE000, 0x385B0000, 0x385B2000, 0x385B4000, 0x385B6000, 0x385B8000, 0x385BA000, 0x385BC000, 0x385BE000,
  0x385C0000, 0x385C2000, 0x385C4000, 0x385C6000, 0x385C8000, 0x385CA000, 0x385CC000, 0x385CE000, 0x385D0000, 0x385D2000, 0x385D4000, 0x385D6000, 0x385D8000, 0x385DA000, 0x385DC000, 0x385DE000,
  0x385E0000, 0x385E2000, 0x385E4000, 0x385E6000, 0x385E8000, 0x385EA000, 0x385EC000, 0x385EE000, 0x385F0000, 0x385F2000, 0x385F4000, 0x385F6000, 0x385F8000, 0x385FA000, 0x385FC000, 0x385FE000,
  0x38600000, 0x38602000, 0x38604000, 0x38606000, 0x38608000, 0x3860A000, 0x3860C000, 0x3860E000, 0x38610000, 0x38612000, 0x38614000, 0x38616000, 0x38618000, 0x3861A000, 0x3861C000, 0x3861E000,
  0x38620000, 0x38622000, 0x38624000, 0x38626000, 0x38628000, 0x3862A000, 0x3862C000, 0x3862E000, 0x38630000, 0x38632000, 0x38634000, 0x38636000, 0x38638000, 0x3863A000, 0x3863C000, 0x3863E000,
  0x38640000, 0x38642000, 0x38644000, 0x38646000, 0x38648000, 0x3864A000, 0x3864C000, 0x3864E000, 0x38650000, 0x38652000, 0x38654000, 0x38656000, 0x38658000, 0x3865A000, 0x3865C000, 0x3865E000,
  0x38660000, 0x38662000, 0x38664000, 0x38666000, 0x38668000, 0x3866A000, 0x3866C000, 0x3866E000, 0x38670000, 0x38672000, 0x38674000, 0x38676000, 0x38678000, 0x3867A000, 0x3867C000, 0x3867E000,
  0x38680000, 0x38682000, 0x38684000, 0x38686000, 0x38688000, 0x3868A000, 0x3868C000, 0x3868E000, 0x38690000, 0x38692000, 0x38694000, 0x38696000, 0x38698000, 0x3869A000, 0x3869C000, 0x3869E000,
  0x386A0000, 0x386A2000, 0x386A4000, 0x386A6000, 0x386A8000, 0x386AA000, 0x386AC000, 0x386AE000, 0x386B0000, 0x386B2000, 0x386B4000, 0x386B6000, 0x386B8000, 0x386BA000, 0x386BC000, 0x386BE000,
  0x386C0000, 0x386C2000, 0x386C4000, 0x386C6000, 0x386C8000, 0x386CA000, 0x386CC000, 0x386CE000, 0x386D0000, 0x386D2000, 0x386D4000, 0x386D6000, 0x386D8000, 0x386DA000, 0x386DC000, 0x386DE000,
  0x386E0000, 0x386E2000, 0x386E4000, 0x386E6000, 0x386E8000, 0x386EA000, 0x386EC000, 0x386EE000, 0x386F0000, 0x386F2000, 0x386F4000, 0x386F6000, 0x386F8000, 0x386FA000, 0x386FC000, 0x386FE000,
  0x38700000, 0x38702000, 0x38704000, 0x38706000, 0x38708000, 0x3870A000, 0x3870C000, 0x3870E000, 0x38710000, 0x38712000, 0x38714000, 0x38716000, 0x38718000, 0x3871A000, 0x3871C000, 0x3871E000,
  0x38720000, 0x38722000, 0x38724000, 0x38726000, 0x38728000, 0x3872A000, 0x3872C000, 0x3872E000, 0x38730000, 0x38732000, 0x38734000, 0x38736000, 0x38738000, 0x3873A000, 0x3873C000, 0x3873E000,
  0x38740000, 0x38742000, 0x38744000, 0x38746000, 0x38748000, 0x3874A000, 0x3874C000, 0x3874E000, 0x38750000, 0x38752000, 0x38754000, 0x38756000, 0x38758000, 0x3875A000, 0x3875C000, 0x3875E000,
  0x38760000, 0x38762000, 0x38764000, 0x38766000, 0x38768000, 0x3876A000, 0x3876C000, 0x3876E000, 0x38770000, 0x38772000, 0x38774000, 0x38776000, 0x38778000, 0x3877A000, 0x3877C000, 0x3877E000,
  0x38780000, 0x38782000, 0x38784000, 0x38786000, 0x38788000, 0x3878A000, 0x3878C000, 0x3878E000, 0x38790000, 0x38792000, 0x38794000, 0x38796000, 0x38798000, 0x3879A000, 0x3879C000, 0x3879E000,
  0x387A0000, 0x387A2000, 0x387A4000, 0x387A6000, 0x387A8000, 0x387AA000, 0x387AC000, 0x387AE000, 0x387B0000, 0x387B2000, 0x387B4000, 0x387B6000, 0x387B8000, 0x387BA000, 0x387BC000, 0x387BE000,
  0x387C0000, 0x387C2000, 0x387C4000, 0x387C6000, 0x387C8000, 0x387CA000, 0x387CC000, 0x387CE000, 0x387D0000, 0x387D2000, 0x387D4000, 0x387D6000, 0x387D8000, 0x387DA000, 0x387DC000, 0x387DE000,
  0x387E0000, 0x387E2000, 0x387E4000, 0x387E6000, 0x387E8000, 0x387EA000, 0x387EC000, 0x387EE000, 0x387F0000, 0x387F2000, 0x387F4000, 0x387F6000, 0x387F8000, 0x387FA000, 0x387FC000, 0x387FE000 };
__constant static const uint32_t exponent_table[64] = {
  0x00000000, 0x00800000, 0x01000000, 0x01800000, 0x02000000, 0x02800000, 0x03000000, 0x03800000, 0x04000000, 0x04800000, 0x05000000, 0x05800000, 0x06000000, 0x06800000, 0x07000000, 0x07800000,
  0x08000000, 0x08800000, 0x09000000, 0x09800000, 0x0A000000, 0x0A800000, 0x0B000000, 0x0B800000, 0x0C000000, 0x0C800000, 0x0D000000, 0x0D800000, 0x0E000000, 0x0E800000, 0x0F000000, 0x47800000,
  0x80000000, 0x80800000, 0x81000000, 0x81800000, 0x82000000, 0x82800000, 0x83000000, 0x83800000, 0x84000000, 0x84800000, 0x85000000, 0x85800000, 0x86000000, 0x86800000, 0x87000000, 0x87800000,
  0x88000000, 0x88800000, 0x89000000, 0x89800000, 0x8A000000, 0x8A800000, 0x8B000000, 0x8B800000, 0x8C000000, 0x8C800000, 0x8D000000, 0x8D800000, 0x8E000000, 0x8E800000, 0x8F000000, 0xC7800000 };
__constant static const unsigned short offset_table[64] = {
  0, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024,
  0, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024 };

static uint16_t float2halfbits(float value) {
  union { float x; uint32_t y; } u;
  u.x = value;
  uint32_t bits = u.y;

  uint16_t hbits = base_table[bits>>23] + (uint16_t)((bits&0x7FFFFF)>>shift_table[bits>>23]);;

  return hbits;
}

static float halfbits2float(uint16_t value) {
  uint32_t bits = mantissa_table[offset_table[value>>10]+(value&0x3FF)] + exponent_table[value>>10];

  union { uint32_t x; float y; } u;
  u.x = bits;
  return u.y;
}

// End of half.h.
// Start of timing.h.

// The function get_wall_time() returns the wall time in microseconds
// (with an unspecified offset).

#ifdef _WIN32

#include <windows.h>

static int64_t get_wall_time(void) {
  LARGE_INTEGER time,freq;
  assert(QueryPerformanceFrequency(&freq));
  assert(QueryPerformanceCounter(&time));
  return ((double)time.QuadPart / freq.QuadPart) * 1000000;
}

#else
// Assuming POSIX

#include <time.h>
#include <sys/time.h>

static int64_t get_wall_time(void) {
  struct timeval time;
  assert(gettimeofday(&time,NULL) == 0);
  return time.tv_sec * 1000000 + time.tv_usec;
}

static int64_t get_wall_time_ns(void) {
  struct timespec time;
  assert(clock_gettime(CLOCK_REALTIME, &time) == 0);
  return time.tv_sec * 1000000000 + time.tv_nsec;
}

#endif

// End of timing.h.

#ifdef _MSC_VER
#define inline __inline
#endif
#include <string.h>
#include <string.h>
#include <errno.h>
#include <assert.h>
#include <ctype.h>


#include <cuda.h>
#include <cuda_runtime.h>
#include <nvrtc.h>


// Start of lock.h.

// A very simple cross-platform implementation of locks.  Uses
// pthreads on Unix and some Windows thing there.  Futhark's
// host-level code is not multithreaded, but user code may be, so we
// need some mechanism for ensuring atomic access to API functions.
// This is that mechanism.  It is not exposed to user code at all, so
// we do not have to worry about name collisions.

#ifdef _WIN32

typedef HANDLE lock_t;

static void create_lock(lock_t *lock) {
  *lock = CreateMutex(NULL,  // Default security attributes.
                      FALSE, // Initially unlocked.
                      NULL); // Unnamed.
}

static void lock_lock(lock_t *lock) {
  assert(WaitForSingleObject(*lock, INFINITE) == WAIT_OBJECT_0);
}

static void lock_unlock(lock_t *lock) {
  assert(ReleaseMutex(*lock));
}

static void free_lock(lock_t *lock) {
  CloseHandle(*lock);
}

#else
// Assuming POSIX

#include <pthread.h>

typedef pthread_mutex_t lock_t;

static void create_lock(lock_t *lock) {
  int r = pthread_mutex_init(lock, NULL);
  assert(r == 0);
}

static void lock_lock(lock_t *lock) {
  int r = pthread_mutex_lock(lock);
  assert(r == 0);
}

static void lock_unlock(lock_t *lock) {
  int r = pthread_mutex_unlock(lock);
  assert(r == 0);
}

static void free_lock(lock_t *lock) {
  // Nothing to do for pthreads.
  (void)lock;
}

#endif

// End of lock.h.

#define FUTHARK_F64_ENABLED

// Start of scalar.h.

// Implementation of the primitive scalar operations.  Very
// repetitive.  This code is inserted directly into both CUDA and
// OpenCL programs, as well as the CPU code, so it has some #ifdefs to
// work everywhere.  Some operations are defined as macros because
// this allows us to use them as constant expressions in things like
// array sizes and static initialisers.

// Some of the #ifdefs are because OpenCL uses type-generic functions
// for some operations (e.g. sqrt), while C and CUDA sensibly use
// distinct functions for different precisions (e.g. sqrtf() and
// sqrt()).  This is quite annoying.  Due to C's unfortunate casting
// rules, it is also really easy to accidentally implement
// floating-point functions in the wrong precision, so be careful.

// Double-precision definitions are only included if the preprocessor
// macro FUTHARK_F64_ENABLED is set.

static inline uint8_t add8(uint8_t x, uint8_t y) {
  return x + y;
}

static inline uint16_t add16(uint16_t x, uint16_t y) {
  return x + y;
}

static inline uint32_t add32(uint32_t x, uint32_t y) {
  return x + y;
}

static inline uint64_t add64(uint64_t x, uint64_t y) {
  return x + y;
}

static inline uint8_t sub8(uint8_t x, uint8_t y) {
  return x - y;
}

static inline uint16_t sub16(uint16_t x, uint16_t y) {
  return x - y;
}

static inline uint32_t sub32(uint32_t x, uint32_t y) {
  return x - y;
}

static inline uint64_t sub64(uint64_t x, uint64_t y) {
  return x - y;
}

static inline uint8_t mul8(uint8_t x, uint8_t y) {
  return x * y;
}

static inline uint16_t mul16(uint16_t x, uint16_t y) {
  return x * y;
}

static inline uint32_t mul32(uint32_t x, uint32_t y) {
  return x * y;
}

static inline uint64_t mul64(uint64_t x, uint64_t y) {
  return x * y;
}

static inline uint8_t udiv8(uint8_t x, uint8_t y) {
  return x / y;
}

static inline uint16_t udiv16(uint16_t x, uint16_t y) {
  return x / y;
}

static inline uint32_t udiv32(uint32_t x, uint32_t y) {
  return x / y;
}

static inline uint64_t udiv64(uint64_t x, uint64_t y) {
  return x / y;
}

static inline uint8_t udiv_up8(uint8_t x, uint8_t y) {
  return (x + y - 1) / y;
}

static inline uint16_t udiv_up16(uint16_t x, uint16_t y) {
  return (x + y - 1) / y;
}

static inline uint32_t udiv_up32(uint32_t x, uint32_t y) {
  return (x + y - 1) / y;
}

static inline uint64_t udiv_up64(uint64_t x, uint64_t y) {
  return (x + y - 1) / y;
}

static inline uint8_t umod8(uint8_t x, uint8_t y) {
  return x % y;
}

static inline uint16_t umod16(uint16_t x, uint16_t y) {
  return x % y;
}

static inline uint32_t umod32(uint32_t x, uint32_t y) {
  return x % y;
}

static inline uint64_t umod64(uint64_t x, uint64_t y) {
  return x % y;
}

static inline uint8_t udiv_safe8(uint8_t x, uint8_t y) {
  return y == 0 ? 0 : x / y;
}

static inline uint16_t udiv_safe16(uint16_t x, uint16_t y) {
  return y == 0 ? 0 : x / y;
}

static inline uint32_t udiv_safe32(uint32_t x, uint32_t y) {
  return y == 0 ? 0 : x / y;
}

static inline uint64_t udiv_safe64(uint64_t x, uint64_t y) {
  return y == 0 ? 0 : x / y;
}

static inline uint8_t udiv_up_safe8(uint8_t x, uint8_t y) {
  return y == 0 ? 0 : (x + y - 1) / y;
}

static inline uint16_t udiv_up_safe16(uint16_t x, uint16_t y) {
  return y == 0 ? 0 : (x + y - 1) / y;
}

static inline uint32_t udiv_up_safe32(uint32_t x, uint32_t y) {
  return y == 0 ? 0 : (x + y - 1) / y;
}

static inline uint64_t udiv_up_safe64(uint64_t x, uint64_t y) {
  return y == 0 ? 0 : (x + y - 1) / y;
}

static inline uint8_t umod_safe8(uint8_t x, uint8_t y) {
  return y == 0 ? 0 : x % y;
}

static inline uint16_t umod_safe16(uint16_t x, uint16_t y) {
  return y == 0 ? 0 : x % y;
}

static inline uint32_t umod_safe32(uint32_t x, uint32_t y) {
  return y == 0 ? 0 : x % y;
}

static inline uint64_t umod_safe64(uint64_t x, uint64_t y) {
  return y == 0 ? 0 : x % y;
}

static inline int8_t sdiv8(int8_t x, int8_t y) {
  int8_t q = x / y;
  int8_t r = x % y;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

static inline int16_t sdiv16(int16_t x, int16_t y) {
  int16_t q = x / y;
  int16_t r = x % y;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

static inline int32_t sdiv32(int32_t x, int32_t y) {
  int32_t q = x / y;
  int32_t r = x % y;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

static inline int64_t sdiv64(int64_t x, int64_t y) {
  int64_t q = x / y;
  int64_t r = x % y;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

static inline int8_t sdiv_up8(int8_t x, int8_t y) {
  return sdiv8(x + y - 1, y);
}

static inline int16_t sdiv_up16(int16_t x, int16_t y) {
  return sdiv16(x + y - 1, y);
}

static inline int32_t sdiv_up32(int32_t x, int32_t y) {
  return sdiv32(x + y - 1, y);
}

static inline int64_t sdiv_up64(int64_t x, int64_t y) {
  return sdiv64(x + y - 1, y);
}

static inline int8_t smod8(int8_t x, int8_t y) {
  int8_t r = x % y;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

static inline int16_t smod16(int16_t x, int16_t y) {
  int16_t r = x % y;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

static inline int32_t smod32(int32_t x, int32_t y) {
  int32_t r = x % y;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

static inline int64_t smod64(int64_t x, int64_t y) {
  int64_t r = x % y;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

static inline int8_t sdiv_safe8(int8_t x, int8_t y) {
  return y == 0 ? 0 : sdiv8(x, y);
}

static inline int16_t sdiv_safe16(int16_t x, int16_t y) {
  return y == 0 ? 0 : sdiv16(x, y);
}

static inline int32_t sdiv_safe32(int32_t x, int32_t y) {
  return y == 0 ? 0 : sdiv32(x, y);
}

static inline int64_t sdiv_safe64(int64_t x, int64_t y) {
  return y == 0 ? 0 : sdiv64(x, y);
}

static inline int8_t sdiv_up_safe8(int8_t x, int8_t y) {
  return sdiv_safe8(x + y - 1, y);
}

static inline int16_t sdiv_up_safe16(int16_t x, int16_t y) {
  return sdiv_safe16(x + y - 1, y);
}

static inline int32_t sdiv_up_safe32(int32_t x, int32_t y) {
  return sdiv_safe32(x + y - 1, y);
}

static inline int64_t sdiv_up_safe64(int64_t x, int64_t y) {
  return sdiv_safe64(x + y - 1, y);
}

static inline int8_t smod_safe8(int8_t x, int8_t y) {
  return y == 0 ? 0 : smod8(x, y);
}

static inline int16_t smod_safe16(int16_t x, int16_t y) {
  return y == 0 ? 0 : smod16(x, y);
}

static inline int32_t smod_safe32(int32_t x, int32_t y) {
  return y == 0 ? 0 : smod32(x, y);
}

static inline int64_t smod_safe64(int64_t x, int64_t y) {
  return y == 0 ? 0 : smod64(x, y);
}

static inline int8_t squot8(int8_t x, int8_t y) {
  return x / y;
}

static inline int16_t squot16(int16_t x, int16_t y) {
  return x / y;
}

static inline int32_t squot32(int32_t x, int32_t y) {
  return x / y;
}

static inline int64_t squot64(int64_t x, int64_t y) {
  return x / y;
}

static inline int8_t srem8(int8_t x, int8_t y) {
  return x % y;
}

static inline int16_t srem16(int16_t x, int16_t y) {
  return x % y;
}

static inline int32_t srem32(int32_t x, int32_t y) {
  return x % y;
}

static inline int64_t srem64(int64_t x, int64_t y) {
  return x % y;
}

static inline int8_t squot_safe8(int8_t x, int8_t y) {
  return y == 0 ? 0 : x / y;
}

static inline int16_t squot_safe16(int16_t x, int16_t y) {
  return y == 0 ? 0 : x / y;
}

static inline int32_t squot_safe32(int32_t x, int32_t y) {
  return y == 0 ? 0 : x / y;
}

static inline int64_t squot_safe64(int64_t x, int64_t y) {
  return y == 0 ? 0 : x / y;
}

static inline int8_t srem_safe8(int8_t x, int8_t y) {
  return y == 0 ? 0 : x % y;
}

static inline int16_t srem_safe16(int16_t x, int16_t y) {
  return y == 0 ? 0 : x % y;
}

static inline int32_t srem_safe32(int32_t x, int32_t y) {
  return y == 0 ? 0 : x % y;
}

static inline int64_t srem_safe64(int64_t x, int64_t y) {
  return y == 0 ? 0 : x % y;
}

static inline int8_t smin8(int8_t x, int8_t y) {
  return x < y ? x : y;
}

static inline int16_t smin16(int16_t x, int16_t y) {
  return x < y ? x : y;
}

static inline int32_t smin32(int32_t x, int32_t y) {
  return x < y ? x : y;
}

static inline int64_t smin64(int64_t x, int64_t y) {
  return x < y ? x : y;
}

static inline uint8_t umin8(uint8_t x, uint8_t y) {
  return x < y ? x : y;
}

static inline uint16_t umin16(uint16_t x, uint16_t y) {
  return x < y ? x : y;
}

static inline uint32_t umin32(uint32_t x, uint32_t y) {
  return x < y ? x : y;
}

static inline uint64_t umin64(uint64_t x, uint64_t y) {
  return x < y ? x : y;
}

static inline int8_t smax8(int8_t x, int8_t y) {
  return x < y ? y : x;
}

static inline int16_t smax16(int16_t x, int16_t y) {
  return x < y ? y : x;
}

static inline int32_t smax32(int32_t x, int32_t y) {
  return x < y ? y : x;
}

static inline int64_t smax64(int64_t x, int64_t y) {
  return x < y ? y : x;
}

static inline uint8_t umax8(uint8_t x, uint8_t y) {
  return x < y ? y : x;
}

static inline uint16_t umax16(uint16_t x, uint16_t y) {
  return x < y ? y : x;
}

static inline uint32_t umax32(uint32_t x, uint32_t y) {
  return x < y ? y : x;
}

static inline uint64_t umax64(uint64_t x, uint64_t y) {
  return x < y ? y : x;
}

static inline uint8_t shl8(uint8_t x, uint8_t y) {
  return (uint8_t)(x << y);
}

static inline uint16_t shl16(uint16_t x, uint16_t y) {
  return (uint16_t)(x << y);
}

static inline uint32_t shl32(uint32_t x, uint32_t y) {
  return x << y;
}

static inline uint64_t shl64(uint64_t x, uint64_t y) {
  return x << y;
}

static inline uint8_t lshr8(uint8_t x, uint8_t y) {
  return x >> y;
}

static inline uint16_t lshr16(uint16_t x, uint16_t y) {
  return x >> y;
}

static inline uint32_t lshr32(uint32_t x, uint32_t y) {
  return x >> y;
}

static inline uint64_t lshr64(uint64_t x, uint64_t y) {
  return x >> y;
}

static inline int8_t ashr8(int8_t x, int8_t y) {
  return x >> y;
}

static inline int16_t ashr16(int16_t x, int16_t y) {
  return x >> y;
}

static inline int32_t ashr32(int32_t x, int32_t y) {
  return x >> y;
}

static inline int64_t ashr64(int64_t x, int64_t y) {
  return x >> y;
}

static inline uint8_t and8(uint8_t x, uint8_t y) {
  return x & y;
}

static inline uint16_t and16(uint16_t x, uint16_t y) {
  return x & y;
}

static inline uint32_t and32(uint32_t x, uint32_t y) {
  return x & y;
}

static inline uint64_t and64(uint64_t x, uint64_t y) {
  return x & y;
}

static inline uint8_t or8(uint8_t x, uint8_t y) {
  return x | y;
}

static inline uint16_t or16(uint16_t x, uint16_t y) {
  return x | y;
}

static inline uint32_t or32(uint32_t x, uint32_t y) {
  return x | y;
}

static inline uint64_t or64(uint64_t x, uint64_t y) {
  return x | y;
}

static inline uint8_t xor8(uint8_t x, uint8_t y) {
  return x ^ y;
}

static inline uint16_t xor16(uint16_t x, uint16_t y) {
  return x ^ y;
}

static inline uint32_t xor32(uint32_t x, uint32_t y) {
  return x ^ y;
}

static inline uint64_t xor64(uint64_t x, uint64_t y) {
  return x ^ y;
}

static inline bool ult8(uint8_t x, uint8_t y) {
  return x < y;
}

static inline bool ult16(uint16_t x, uint16_t y) {
  return x < y;
}

static inline bool ult32(uint32_t x, uint32_t y) {
  return x < y;
}

static inline bool ult64(uint64_t x, uint64_t y) {
  return x < y;
}

static inline bool ule8(uint8_t x, uint8_t y) {
  return x <= y;
}

static inline bool ule16(uint16_t x, uint16_t y) {
  return x <= y;
}

static inline bool ule32(uint32_t x, uint32_t y) {
  return x <= y;
}

static inline bool ule64(uint64_t x, uint64_t y) {
  return x <= y;
}

static inline bool slt8(int8_t x, int8_t y) {
  return x < y;
}

static inline bool slt16(int16_t x, int16_t y) {
  return x < y;
}

static inline bool slt32(int32_t x, int32_t y) {
  return x < y;
}

static inline bool slt64(int64_t x, int64_t y) {
  return x < y;
}

static inline bool sle8(int8_t x, int8_t y) {
  return x <= y;
}

static inline bool sle16(int16_t x, int16_t y) {
  return x <= y;
}

static inline bool sle32(int32_t x, int32_t y) {
  return x <= y;
}

static inline bool sle64(int64_t x, int64_t y) {
  return x <= y;
}

static inline uint8_t pow8(uint8_t x, uint8_t y) {
  uint8_t res = 1, rem = y;

  while (rem != 0) {
    if (rem & 1)
      res *= x;
    rem >>= 1;
    x *= x;
  }
  return res;
}

static inline uint16_t pow16(uint16_t x, uint16_t y) {
  uint16_t res = 1, rem = y;

  while (rem != 0) {
    if (rem & 1)
      res *= x;
    rem >>= 1;
    x *= x;
  }
  return res;
}

static inline uint32_t pow32(uint32_t x, uint32_t y) {
  uint32_t res = 1, rem = y;

  while (rem != 0) {
    if (rem & 1)
      res *= x;
    rem >>= 1;
    x *= x;
  }
  return res;
}

static inline uint64_t pow64(uint64_t x, uint64_t y) {
  uint64_t res = 1, rem = y;

  while (rem != 0) {
    if (rem & 1)
      res *= x;
    rem >>= 1;
    x *= x;
  }
  return res;
}

static inline bool itob_i8_bool(int8_t x) {
  return x;
}

static inline bool itob_i16_bool(int16_t x) {
  return x;
}

static inline bool itob_i32_bool(int32_t x) {
  return x;
}

static inline bool itob_i64_bool(int64_t x) {
  return x;
}

static inline int8_t btoi_bool_i8(bool x) {
  return x;
}

static inline int16_t btoi_bool_i16(bool x) {
  return x;
}

static inline int32_t btoi_bool_i32(bool x) {
  return x;
}

static inline int64_t btoi_bool_i64(bool x) {
  return x;
}

#define sext_i8_i8(x) ((int8_t) (int8_t) (x))
#define sext_i8_i16(x) ((int16_t) (int8_t) (x))
#define sext_i8_i32(x) ((int32_t) (int8_t) (x))
#define sext_i8_i64(x) ((int64_t) (int8_t) (x))
#define sext_i16_i8(x) ((int8_t) (int16_t) (x))
#define sext_i16_i16(x) ((int16_t) (int16_t) (x))
#define sext_i16_i32(x) ((int32_t) (int16_t) (x))
#define sext_i16_i64(x) ((int64_t) (int16_t) (x))
#define sext_i32_i8(x) ((int8_t) (int32_t) (x))
#define sext_i32_i16(x) ((int16_t) (int32_t) (x))
#define sext_i32_i32(x) ((int32_t) (int32_t) (x))
#define sext_i32_i64(x) ((int64_t) (int32_t) (x))
#define sext_i64_i8(x) ((int8_t) (int64_t) (x))
#define sext_i64_i16(x) ((int16_t) (int64_t) (x))
#define sext_i64_i32(x) ((int32_t) (int64_t) (x))
#define sext_i64_i64(x) ((int64_t) (int64_t) (x))
#define zext_i8_i8(x) ((int8_t) (uint8_t) (x))
#define zext_i8_i16(x) ((int16_t) (uint8_t) (x))
#define zext_i8_i32(x) ((int32_t) (uint8_t) (x))
#define zext_i8_i64(x) ((int64_t) (uint8_t) (x))
#define zext_i16_i8(x) ((int8_t) (uint16_t) (x))
#define zext_i16_i16(x) ((int16_t) (uint16_t) (x))
#define zext_i16_i32(x) ((int32_t) (uint16_t) (x))
#define zext_i16_i64(x) ((int64_t) (uint16_t) (x))
#define zext_i32_i8(x) ((int8_t) (uint32_t) (x))
#define zext_i32_i16(x) ((int16_t) (uint32_t) (x))
#define zext_i32_i32(x) ((int32_t) (uint32_t) (x))
#define zext_i32_i64(x) ((int64_t) (uint32_t) (x))
#define zext_i64_i8(x) ((int8_t) (uint64_t) (x))
#define zext_i64_i16(x) ((int16_t) (uint64_t) (x))
#define zext_i64_i32(x) ((int32_t) (uint64_t) (x))
#define zext_i64_i64(x) ((int64_t) (uint64_t) (x))

static int8_t abs8(int8_t x) {
  return (int8_t)abs(x);
}

static int16_t abs16(int16_t x) {
  return (int16_t)abs(x);
}

static int32_t abs32(int32_t x) {
  return abs(x);
}

static int64_t abs64(int64_t x) {
#if defined(__OPENCL_VERSION__)
  return abs(x);
#else
  return llabs(x);
#endif
}

#if defined(__OPENCL_VERSION__)
static int32_t futrts_popc8(int8_t x) {
  return popcount(x);
}

static int32_t futrts_popc16(int16_t x) {
  return popcount(x);
}

static int32_t futrts_popc32(int32_t x) {
  return popcount(x);
}

static int32_t futrts_popc64(int64_t x) {
  return popcount(x);
}
#elif defined(__CUDA_ARCH__)

static int32_t futrts_popc8(int8_t x) {
  return __popc(zext_i8_i32(x));
}

static int32_t futrts_popc16(int16_t x) {
  return __popc(zext_i16_i32(x));
}

static int32_t futrts_popc32(int32_t x) {
  return __popc(x);
}

static int32_t futrts_popc64(int64_t x) {
  return __popcll(x);
}

#else // Not OpenCL or CUDA, but plain C.

static int32_t futrts_popc8(uint8_t x) {
  int c = 0;
  for (; x; ++c) { x &= x - 1; }
  return c;
}

static int32_t futrts_popc16(uint16_t x) {
  int c = 0;
  for (; x; ++c) { x &= x - 1; }
  return c;
}

static int32_t futrts_popc32(uint32_t x) {
  int c = 0;
  for (; x; ++c) { x &= x - 1; }
  return c;
}

static int32_t futrts_popc64(uint64_t x) {
  int c = 0;
  for (; x; ++c) { x &= x - 1; }
  return c;
}
#endif

#if defined(__OPENCL_VERSION__)
static uint8_t futrts_mul_hi8(uint8_t a, uint8_t b) {
  return mul_hi(a, b);
}

static uint16_t futrts_mul_hi16(uint16_t a, uint16_t b) {
  return mul_hi(a, b);
}

static uint32_t futrts_mul_hi32(uint32_t a, uint32_t b) {
  return mul_hi(a, b);
}

static uint64_t futrts_mul_hi64(uint64_t a, uint64_t b) {
  return mul_hi(a, b);
}

#elif defined(__CUDA_ARCH__)

static uint8_t futrts_mul_hi8(uint8_t a, uint8_t b) {
  uint16_t aa = a;
  uint16_t bb = b;

  return aa * bb >> 8;
}

static uint16_t futrts_mul_hi16(uint16_t a, uint16_t b) {
  uint32_t aa = a;
  uint32_t bb = b;

  return aa * bb >> 16;
}

static uint32_t futrts_mul_hi32(uint32_t a, uint32_t b) {
  return mulhi(a, b);
}

static uint64_t futrts_mul_hi64(uint64_t a, uint64_t b) {
  return mul64hi(a, b);
}

#else // Not OpenCL or CUDA, but plain C.

static uint8_t futrts_mul_hi8(uint8_t a, uint8_t b) {
  uint16_t aa = a;
  uint16_t bb = b;

  return aa * bb >> 8;
}

static uint16_t futrts_mul_hi16(uint16_t a, uint16_t b) {
  uint32_t aa = a;
  uint32_t bb = b;

  return aa * bb >> 16;
}

static uint32_t futrts_mul_hi32(uint32_t a, uint32_t b) {
  uint64_t aa = a;
  uint64_t bb = b;

  return aa * bb >> 32;
}

static uint64_t futrts_mul_hi64(uint64_t a, uint64_t b) {
  __uint128_t aa = a;
  __uint128_t bb = b;

  return aa * bb >> 64;
}
#endif

#if defined(__OPENCL_VERSION__)
static uint8_t futrts_mad_hi8(uint8_t a, uint8_t b, uint8_t c) {
  return mad_hi(a, b, c);
}

static uint16_t futrts_mad_hi16(uint16_t a, uint16_t b, uint16_t c) {
  return mad_hi(a, b, c);
}

static uint32_t futrts_mad_hi32(uint32_t a, uint32_t b, uint32_t c) {
  return mad_hi(a, b, c);
}

static uint64_t futrts_mad_hi64(uint64_t a, uint64_t b, uint64_t c) {
  return mad_hi(a, b, c);
}

#else // Not OpenCL

static uint8_t futrts_mad_hi8(uint8_t a, uint8_t b, uint8_t c) {
  return futrts_mul_hi8(a, b) + c;
}

static uint16_t futrts_mad_hi16(uint16_t a, uint16_t b, uint16_t c) {
  return futrts_mul_hi16(a, b) + c;
}

static uint32_t futrts_mad_hi32(uint32_t a, uint32_t b, uint32_t c) {
  return futrts_mul_hi32(a, b) + c;
}

static uint64_t futrts_mad_hi64(uint64_t a, uint64_t b, uint64_t c) {
  return futrts_mul_hi64(a, b) + c;
}
#endif

#if defined(__OPENCL_VERSION__)
static int32_t futrts_clzz8(int8_t x) {
  return clz(x);
}

static int32_t futrts_clzz16(int16_t x) {
  return clz(x);
}

static int32_t futrts_clzz32(int32_t x) {
  return clz(x);
}

static int32_t futrts_clzz64(int64_t x) {
  return clz(x);
}

#elif defined(__CUDA_ARCH__)

static int32_t futrts_clzz8(int8_t x) {
  return __clz(zext_i8_i32(x)) - 24;
}

static int32_t futrts_clzz16(int16_t x) {
  return __clz(zext_i16_i32(x)) - 16;
}

static int32_t futrts_clzz32(int32_t x) {
  return __clz(x);
}

static int32_t futrts_clzz64(int64_t x) {
  return __clzll(x);
}

#else // Not OpenCL or CUDA, but plain C.

static int32_t futrts_clzz8(int8_t x) {
  return x == 0 ? 8 : __builtin_clz((uint32_t)zext_i8_i32(x)) - 24;
}

static int32_t futrts_clzz16(int16_t x) {
  return x == 0 ? 16 : __builtin_clz((uint32_t)zext_i16_i32(x)) - 16;
}

static int32_t futrts_clzz32(int32_t x) {
  return x == 0 ? 32 : __builtin_clz((uint32_t)x);
}

static int32_t futrts_clzz64(int64_t x) {
  return x == 0 ? 64 : __builtin_clzll((uint64_t)x);
}
#endif

#if defined(__OPENCL_VERSION__)
static int32_t futrts_ctzz8(int8_t x) {
  int i = 0;
  for (; i < 8 && (x & 1) == 0; i++, x >>= 1)
    ;
  return i;
}

static int32_t futrts_ctzz16(int16_t x) {
  int i = 0;
  for (; i < 16 && (x & 1) == 0; i++, x >>= 1)
    ;
  return i;
}

static int32_t futrts_ctzz32(int32_t x) {
  int i = 0;
  for (; i < 32 && (x & 1) == 0; i++, x >>= 1)
    ;
  return i;
}

static int32_t futrts_ctzz64(int64_t x) {
  int i = 0;
  for (; i < 64 && (x & 1) == 0; i++, x >>= 1)
    ;
  return i;
}

#elif defined(__CUDA_ARCH__)

static int32_t futrts_ctzz8(int8_t x) {
  int y = __ffs(x);
  return y == 0 ? 8 : y - 1;
}

static int32_t futrts_ctzz16(int16_t x) {
  int y = __ffs(x);
  return y == 0 ? 16 : y - 1;
}

static int32_t futrts_ctzz32(int32_t x) {
  int y = __ffs(x);
  return y == 0 ? 32 : y - 1;
}

static int32_t futrts_ctzz64(int64_t x) {
  int y = __ffsll(x);
  return y == 0 ? 64 : y - 1;
}

#else // Not OpenCL or CUDA, but plain C.

static int32_t futrts_ctzz8(int8_t x) {
  return x == 0 ? 8 : __builtin_ctz((uint32_t)x);
}

static int32_t futrts_ctzz16(int16_t x) {
  return x == 0 ? 16 : __builtin_ctz((uint32_t)x);
}

static int32_t futrts_ctzz32(int32_t x) {
  return x == 0 ? 32 : __builtin_ctz((uint32_t)x);
}

static int32_t futrts_ctzz64(int64_t x) {
  return x == 0 ? 64 : __builtin_ctzll((uint64_t)x);
}
#endif

static inline float fdiv32(float x, float y) {
  return x / y;
}

static inline float fadd32(float x, float y) {
  return x + y;
}

static inline float fsub32(float x, float y) {
  return x - y;
}

static inline float fmul32(float x, float y) {
  return x * y;
}

static inline bool cmplt32(float x, float y) {
  return x < y;
}

static inline bool cmple32(float x, float y) {
  return x <= y;
}

static inline float sitofp_i8_f32(int8_t x) {
  return (float) x;
}

static inline float sitofp_i16_f32(int16_t x) {
  return (float) x;
}

static inline float sitofp_i32_f32(int32_t x) {
  return (float) x;
}

static inline float sitofp_i64_f32(int64_t x) {
  return (float) x;
}

static inline float uitofp_i8_f32(uint8_t x) {
  return (float) x;
}

static inline float uitofp_i16_f32(uint16_t x) {
  return (float) x;
}

static inline float uitofp_i32_f32(uint32_t x) {
  return (float) x;
}

static inline float uitofp_i64_f32(uint64_t x) {
  return (float) x;
}

static inline int8_t fptosi_f32_i8(float x) {
  return (int8_t) x;
}

static inline int16_t fptosi_f32_i16(float x) {
  return (int16_t) x;
}

static inline int32_t fptosi_f32_i32(float x) {
  return (int32_t) x;
}

static inline int64_t fptosi_f32_i64(float x) {
  return (int64_t) x;
}

static inline uint8_t fptoui_f32_i8(float x) {
  return (uint8_t) x;
}

static inline uint16_t fptoui_f32_i16(float x) {
  return (uint16_t) x;
}

static inline uint32_t fptoui_f32_i32(float x) {
  return (uint32_t) x;
}

static inline uint64_t fptoui_f32_i64(float x) {
  return (uint64_t) x;
}

#ifdef __OPENCL_VERSION__
static inline float fabs32(float x) {
  return fabs(x);
}

static inline float fmax32(float x, float y) {
  return fmax(x, y);
}

static inline float fmin32(float x, float y) {
  return fmin(x, y);
}

static inline float fpow32(float x, float y) {
  return pow(x, y);
}

#else // Not OpenCL, but CUDA or plain C.

static inline float fabs32(float x) {
  return fabsf(x);
}

static inline float fmax32(float x, float y) {
  return fmaxf(x, y);
}

static inline float fmin32(float x, float y) {
  return fminf(x, y);
}

static inline float fpow32(float x, float y) {
  return powf(x, y);
}
#endif

static inline bool futrts_isnan32(float x) {
  return isnan(x);
}

static inline bool futrts_isinf32(float x) {
  return isinf(x);
}

#ifdef __OPENCL_VERSION__
static inline float futrts_log32(float x) {
  return log(x);
}

static inline float futrts_log2_32(float x) {
  return log2(x);
}

static inline float futrts_log10_32(float x) {
  return log10(x);
}

static inline float futrts_sqrt32(float x) {
  return sqrt(x);
}

static inline float futrts_exp32(float x) {
  return exp(x);
}

static inline float futrts_cos32(float x) {
  return cos(x);
}

static inline float futrts_sin32(float x) {
  return sin(x);
}

static inline float futrts_tan32(float x) {
  return tan(x);
}

static inline float futrts_acos32(float x) {
  return acos(x);
}

static inline float futrts_asin32(float x) {
  return asin(x);
}

static inline float futrts_atan32(float x) {
  return atan(x);
}

static inline float futrts_cosh32(float x) {
  return cosh(x);
}

static inline float futrts_sinh32(float x) {
  return sinh(x);
}

static inline float futrts_tanh32(float x) {
  return tanh(x);
}

static inline float futrts_acosh32(float x) {
  return acosh(x);
}

static inline float futrts_asinh32(float x) {
  return asinh(x);
}

static inline float futrts_atanh32(float x) {
  return atanh(x);
}

static inline float futrts_atan2_32(float x, float y) {
  return atan2(x, y);
}

static inline float futrts_hypot32(float x, float y) {
  return hypot(x, y);
}

static inline float futrts_gamma32(float x) {
  return tgamma(x);
}

static inline float futrts_lgamma32(float x) {
  return lgamma(x);
}

static inline float fmod32(float x, float y) {
  return fmod(x, y);
}

static inline float futrts_round32(float x) {
  return rint(x);
}

static inline float futrts_floor32(float x) {
  return floor(x);
}

static inline float futrts_ceil32(float x) {
  return ceil(x);
}

static inline float futrts_lerp32(float v0, float v1, float t) {
  return mix(v0, v1, t);
}

static inline float futrts_mad32(float a, float b, float c) {
  return mad(a, b, c);
}

static inline float futrts_fma32(float a, float b, float c) {
  return fma(a, b, c);
}

#else // Not OpenCL, but CUDA or plain C.

static inline float futrts_log32(float x) {
  return logf(x);
}

static inline float futrts_log2_32(float x) {
  return log2f(x);
}

static inline float futrts_log10_32(float x) {
  return log10f(x);
}

static inline float futrts_sqrt32(float x) {
  return sqrtf(x);
}

static inline float futrts_exp32(float x) {
  return expf(x);
}

static inline float futrts_cos32(float x) {
  return cosf(x);
}

static inline float futrts_sin32(float x) {
  return sinf(x);
}

static inline float futrts_tan32(float x) {
  return tanf(x);
}

static inline float futrts_acos32(float x) {
  return acosf(x);
}

static inline float futrts_asin32(float x) {
  return asinf(x);
}

static inline float futrts_atan32(float x) {
  return atanf(x);
}

static inline float futrts_cosh32(float x) {
  return coshf(x);
}

static inline float futrts_sinh32(float x) {
  return sinhf(x);
}

static inline float futrts_tanh32(float x) {
  return tanhf(x);
}

static inline float futrts_acosh32(float x) {
  return acoshf(x);
}

static inline float futrts_asinh32(float x) {
  return asinhf(x);
}

static inline float futrts_atanh32(float x) {
  return atanhf(x);
}

static inline float futrts_atan2_32(float x, float y) {
  return atan2f(x, y);
}

static inline float futrts_hypot32(float x, float y) {
  return hypotf(x, y);
}

static inline float futrts_gamma32(float x) {
  return tgammaf(x);
}

static inline float futrts_lgamma32(float x) {
  return lgammaf(x);
}

static inline float fmod32(float x, float y) {
  return fmodf(x, y);
}

static inline float futrts_round32(float x) {
  return rintf(x);
}

static inline float futrts_floor32(float x) {
  return floorf(x);
}

static inline float futrts_ceil32(float x) {
  return ceilf(x);
}

static inline float futrts_lerp32(float v0, float v1, float t) {
  return v0 + (v1 - v0) * t;
}

static inline float futrts_mad32(float a, float b, float c) {
  return a * b + c;
}

static inline float futrts_fma32(float a, float b, float c) {
  return fmaf(a, b, c);
}
#endif

static inline int32_t futrts_to_bits32(float x) {
  union {
    float f;
    int32_t t;
  } p;

  p.f = x;
  return p.t;
}

static inline float futrts_from_bits32(int32_t x) {
  union {
    int32_t f;
    float t;
  } p;

  p.f = x;
  return p.t;
}

static inline float fsignum32(float x) {
  return futrts_isnan32(x) ? x : (x > 0) - (x < 0);
}

#ifdef FUTHARK_F64_ENABLED

static inline double fdiv64(double x, double y) {
  return x / y;
}

static inline double fadd64(double x, double y) {
  return x + y;
}

static inline double fsub64(double x, double y) {
  return x - y;
}

static inline double fmul64(double x, double y) {
  return x * y;
}

static inline bool cmplt64(double x, double y) {
  return x < y;
}

static inline bool cmple64(double x, double y) {
  return x <= y;
}

static inline double sitofp_i8_f64(int8_t x) {
  return (double) x;
}

static inline double sitofp_i16_f64(int16_t x) {
  return (double) x;
}

static inline double sitofp_i32_f64(int32_t x) {
  return (double) x;
}

static inline double sitofp_i64_f64(int64_t x) {
  return (double) x;
}

static inline double uitofp_i8_f64(uint8_t x) {
  return (double) x;
}

static inline double uitofp_i16_f64(uint16_t x) {
  return (double) x;
}

static inline double uitofp_i32_f64(uint32_t x) {
  return (double) x;
}

static inline double uitofp_i64_f64(uint64_t x) {
  return (double) x;
}

static inline int8_t fptosi_f64_i8(double x) {
  return (int8_t) x;
}

static inline int16_t fptosi_f64_i16(double x) {
  return (int16_t) x;
}

static inline int32_t fptosi_f64_i32(double x) {
  return (int32_t) x;
}

static inline int64_t fptosi_f64_i64(double x) {
  return (int64_t) x;
}

static inline uint8_t fptoui_f64_i8(double x) {
  return (uint8_t) x;
}

static inline uint16_t fptoui_f64_i16(double x) {
  return (uint16_t) x;
}

static inline uint32_t fptoui_f64_i32(double x) {
  return (uint32_t) x;
}

static inline uint64_t fptoui_f64_i64(double x) {
  return (uint64_t) x;
}

static inline double fabs64(double x) {
  return fabs(x);
}

static inline double fmax64(double x, double y) {
  return fmax(x, y);
}

static inline double fmin64(double x, double y) {
  return fmin(x, y);
}

static inline double fpow64(double x, double y) {
  return pow(x, y);
}

static inline double futrts_log64(double x) {
  return log(x);
}

static inline double futrts_log2_64(double x) {
  return log2(x);
}

static inline double futrts_log10_64(double x) {
  return log10(x);
}

static inline double futrts_sqrt64(double x) {
  return sqrt(x);
}

static inline double futrts_exp64(double x) {
  return exp(x);
}

static inline double futrts_cos64(double x) {
  return cos(x);
}

static inline double futrts_sin64(double x) {
  return sin(x);
}

static inline double futrts_tan64(double x) {
  return tan(x);
}

static inline double futrts_acos64(double x) {
  return acos(x);
}

static inline double futrts_asin64(double x) {
  return asin(x);
}

static inline double futrts_atan64(double x) {
  return atan(x);
}

static inline double futrts_cosh64(double x) {
  return cosh(x);
}

static inline double futrts_sinh64(double x) {
  return sinh(x);
}

static inline double futrts_tanh64(double x) {
  return tanh(x);
}

static inline double futrts_acosh64(double x) {
  return acosh(x);
}

static inline double futrts_asinh64(double x) {
  return asinh(x);
}

static inline double futrts_atanh64(double x) {
  return atanh(x);
}

static inline double futrts_atan2_64(double x, double y) {
  return atan2(x, y);
}

static inline double futrts_hypot64(double x, double y) {
  return hypot(x, y);
}

static inline double futrts_gamma64(double x) {
  return tgamma(x);
}

static inline double futrts_lgamma64(double x) {
  return lgamma(x);
}

static inline double futrts_fma64(double a, double b, double c) {
  return fma(a, b, c);
}

static inline double futrts_round64(double x) {
  return rint(x);
}

static inline double futrts_ceil64(double x) {
  return ceil(x);
}

static inline double futrts_floor64(double x) {
  return floor(x);
}

static inline bool futrts_isnan64(double x) {
  return isnan(x);
}

static inline bool futrts_isinf64(double x) {
  return isinf(x);
}

static inline int64_t futrts_to_bits64(double x) {
  union {
    double f;
    int64_t t;
  } p;

  p.f = x;
  return p.t;
}

static inline double futrts_from_bits64(int64_t x) {
  union {
    int64_t f;
    double t;
  } p;

  p.f = x;
  return p.t;
}

static inline double fmod64(double x, double y) {
  return fmod(x, y);
}

static inline double fsignum64(double x) {
  return futrts_isnan64(x) ? x : (x > 0) - (x < 0);
}

static inline double futrts_lerp64(double v0, double v1, double t) {
#ifdef __OPENCL_VERSION__
  return mix(v0, v1, t);
#else
  return v0 + (v1 - v0) * t;
#endif
}

static inline double futrts_mad64(double a, double b, double c) {
#ifdef __OPENCL_VERSION__
  return mad(a, b, c);
#else
  return a * b + c;
#endif
}

static inline float fpconv_f32_f32(float x) {
  return (float) x;
}

static inline double fpconv_f32_f64(float x) {
  return (double) x;
}

static inline float fpconv_f64_f32(double x) {
  return (float) x;
}

static inline double fpconv_f64_f64(double x) {
  return (double) x;
}

#endif

// End of scalar.h.
// Start of scalar_f16.h.

// Half-precision is emulated if needed (e.g. in straight C) with the
// native type used if possible.  The emulation works by typedef'ing
// 'float' to 'f16', and then implementing all operations on single
// precision.  To cut down on duplication, we use the same code for
// those Futhark functions that require just operators or casts.  The
// in-memory representation for arrays will still be 16 bits even
// under emulation, so the compiler will have to be careful when
// generating reads or writes.

#if !defined(cl_khr_fp16) && !(defined(__CUDA_ARCH__) && __CUDA_ARCH__ >= 600)
#define EMULATE_F16
#endif

#if !defined(EMULATE_F16) && defined(__OPENCL_VERSION__)
#pragma OPENCL EXTENSION cl_khr_fp16 : enable
#endif

#ifdef EMULATE_F16

// Note that the half-precision storage format is still 16 bits - the
// compiler will have to be real careful!
typedef float f16;

#else

#ifdef __CUDA_ARCH__
#include <cuda_fp16.h>
#endif

typedef half f16;

#endif

// Some of these functions convert to single precision because half
// precision versions are not available.

static inline f16 fadd16(f16 x, f16 y) {
  return x + y;
}

static inline f16 fsub16(f16 x, f16 y) {
  return x - y;
}

static inline f16 fmul16(f16 x, f16 y) {
  return x * y;
}

static inline bool cmplt16(f16 x, f16 y) {
  return x < y;
}

static inline bool cmple16(f16 x, f16 y) {
  return x <= y;
}

static inline f16 sitofp_i8_f16(int8_t x) {
  return (f16) x;
}

static inline f16 sitofp_i16_f16(int16_t x) {
  return (f16) x;
}

static inline f16 sitofp_i32_f16(int32_t x) {
  return (f16) x;
}

static inline f16 sitofp_i64_f16(int64_t x) {
  return (f16) x;
}

static inline f16 uitofp_i8_f16(uint8_t x) {
  return (f16) x;
}

static inline f16 uitofp_i16_f16(uint16_t x) {
  return (f16) x;
}

static inline f16 uitofp_i32_f16(uint32_t x) {
  return (f16) x;
}

static inline f16 uitofp_i64_f16(uint64_t x) {
  return (f16) x;
}

static inline int8_t fptosi_f16_i8(f16 x) {
  return (int8_t) (float) x;
}

static inline int16_t fptosi_f16_i16(f16 x) {
  return (int16_t) x;
}

static inline int32_t fptosi_f16_i32(f16 x) {
  return (int32_t) x;
}

static inline int64_t fptosi_f16_i64(f16 x) {
  return (int64_t) x;
}

static inline uint8_t fptoui_f16_i8(f16 x) {
  return (uint8_t) (float) x;
}

static inline uint16_t fptoui_f16_i16(f16 x) {
  return (uint16_t) x;
}

static inline uint32_t fptoui_f16_i32(f16 x) {
  return (uint32_t) x;
}

static inline uint64_t fptoui_f16_i64(f16 x) {
  return (uint64_t) x;
}

#ifndef EMULATE_F16

#ifdef __OPENCL_VERSION__
static inline f16 fabs16(f16 x) {
  return fabs(x);
}

static inline f16 fmax16(f16 x, f16 y) {
  return fmax(x, y);
}

static inline f16 fmin16(f16 x, f16 y) {
  return fmin(x, y);
}

static inline f16 fpow16(f16 x, f16 y) {
  return pow(x, y);
}

#else // Assuming CUDA.

static inline f16 fabs16(f16 x) {
  return fabsf(x);
}

static inline f16 fmax16(f16 x, f16 y) {
  return fmaxf(x, y);
}

static inline f16 fmin16(f16 x, f16 y) {
  return fminf(x, y);
}

static inline f16 fpow16(f16 x, f16 y) {
  return powf(x, y);
}
#endif

static inline bool futrts_isnan16(f16 x) {
  return isnan((float)x);
}

static inline bool futrts_isinf16(f16 x) {
  return isinf((float)x);
}

#ifdef __OPENCL_VERSION__
static inline f16 futrts_log16(f16 x) {
  return log(x);
}

static inline f16 futrts_log2_16(f16 x) {
  return log2(x);
}

static inline f16 futrts_log10_16(f16 x) {
  return log10(x);
}

static inline f16 futrts_sqrt16(f16 x) {
  return sqrt(x);
}

static inline f16 futrts_exp16(f16 x) {
  return exp(x);
}

static inline f16 futrts_cos16(f16 x) {
  return cos(x);
}

static inline f16 futrts_sin16(f16 x) {
  return sin(x);
}

static inline f16 futrts_tan16(f16 x) {
  return tan(x);
}

static inline f16 futrts_acos16(f16 x) {
  return acos(x);
}

static inline f16 futrts_asin16(f16 x) {
  return asin(x);
}

static inline f16 futrts_atan16(f16 x) {
  return atan(x);
}

static inline f16 futrts_cosh16(f16 x) {
  return cosh(x);
}

static inline f16 futrts_sinh16(f16 x) {
  return sinh(x);
}

static inline f16 futrts_tanh16(f16 x) {
  return tanh(x);
}

static inline f16 futrts_acosh16(f16 x) {
  return acosh(x);
}

static inline f16 futrts_asinh16(f16 x) {
  return asinh(x);
}

static inline f16 futrts_atanh16(f16 x) {
  return atanh(x);
}

static inline f16 futrts_atan2_16(f16 x, f16 y) {
  return atan2(x, y);
}

static inline f16 futrts_hypot16(f16 x, f16 y) {
  return hypot(x, y);
}

static inline f16 futrts_gamma16(f16 x) {
  return tgamma(x);
}

static inline f16 futrts_lgamma16(f16 x) {
  return lgamma(x);
}

static inline f16 fmod16(f16 x, f16 y) {
  return fmod(x, y);
}

static inline f16 futrts_round16(f16 x) {
  return rint(x);
}

static inline f16 futrts_floor16(f16 x) {
  return floor(x);
}

static inline f16 futrts_ceil16(f16 x) {
  return ceil(x);
}

static inline f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {
  return mix(v0, v1, t);
}

static inline f16 futrts_mad16(f16 a, f16 b, f16 c) {
  return mad(a, b, c);
}

static inline f16 futrts_fma16(f16 a, f16 b, f16 c) {
  return fma(a, b, c);
}

#else // Assume CUDA.

static inline f16 futrts_log16(f16 x) {
  return hlog(x);
}

static inline f16 futrts_log2_16(f16 x) {
  return hlog2(x);
}

static inline f16 futrts_log10_16(f16 x) {
  return hlog10(x);
}

static inline f16 futrts_sqrt16(f16 x) {
  return hsqrt(x);
}

static inline f16 futrts_exp16(f16 x) {
  return hexp(x);
}

static inline f16 futrts_cos16(f16 x) {
  return hcos(x);
}

static inline f16 futrts_sin16(f16 x) {
  return hsin(x);
}

static inline f16 futrts_tan16(f16 x) {
  return tanf(x);
}

static inline f16 futrts_acos16(f16 x) {
  return acosf(x);
}

static inline f16 futrts_asin16(f16 x) {
  return asinf(x);
}

static inline f16 futrts_atan16(f16 x) {
  return atanf(x);
}

static inline f16 futrts_cosh16(f16 x) {
  return coshf(x);
}

static inline f16 futrts_sinh16(f16 x) {
  return sinhf(x);
}

static inline f16 futrts_tanh16(f16 x) {
  return tanhf(x);
}

static inline f16 futrts_acosh16(f16 x) {
  return acoshf(x);
}

static inline f16 futrts_asinh16(f16 x) {
  return asinhf(x);
}

static inline f16 futrts_atanh16(f16 x) {
  return atanhf(x);
}

static inline f16 futrts_atan2_16(f16 x, f16 y) {
  return atan2f(x, y);
}

static inline f16 futrts_hypot16(f16 x, f16 y) {
  return hypotf(x, y);
}

static inline f16 futrts_gamma16(f16 x) {
  return tgammaf(x);
}

static inline f16 futrts_lgamma16(f16 x) {
  return lgammaf(x);
}

static inline f16 fmod16(f16 x, f16 y) {
  return fmodf(x, y);
}

static inline f16 futrts_round16(f16 x) {
  return rintf(x);
}

static inline f16 futrts_floor16(f16 x) {
  return hfloor(x);
}

static inline f16 futrts_ceil16(f16 x) {
  return hceil(x);
}

static inline f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {
  return v0 + (v1 - v0) * t;
}

static inline f16 futrts_mad16(f16 a, f16 b, f16 c) {
  return a * b + c;
}

static inline f16 futrts_fma16(f16 a, f16 b, f16 c) {
  return fmaf(a, b, c);
}

#endif

// The CUDA __half type cannot be put in unions for some reason, so we
// use bespoke conversion functions instead.
#ifdef __CUDA_ARCH__
static inline int16_t futrts_to_bits16(f16 x) {
  return __half_as_ushort(x);
}
static inline f16 futrts_from_bits16(int16_t x) {
  return __ushort_as_half(x);
}
#else
static inline int16_t futrts_to_bits16(f16 x) {
  union {
    f16 f;
    int16_t t;
  } p;

  p.f = x;
  return p.t;
}

static inline f16 futrts_from_bits16(int16_t x) {
  union {
    int16_t f;
    f16 t;
  } p;

  p.f = x;
  return p.t;
}
#endif

#else // No native f16 - emulate.

static inline f16 fabs16(f16 x) {
  return fabs32(x);
}

static inline f16 fmax16(f16 x, f16 y) {
  return fmax32(x, y);
}

static inline f16 fmin16(f16 x, f16 y) {
  return fmin32(x, y);
}

static inline f16 fpow16(f16 x, f16 y) {
  return fpow32(x, y);
}

static inline bool futrts_isnan16(f16 x) {
  return futrts_isnan32(x);
}

static inline bool futrts_isinf16(f16 x) {
  return futrts_isinf32(x);
}

static inline f16 futrts_log16(f16 x) {
  return futrts_log32(x);
}

static inline f16 futrts_log2_16(f16 x) {
  return futrts_log2_32(x);
}

static inline f16 futrts_log10_16(f16 x) {
  return futrts_log10_32(x);
}

static inline f16 futrts_sqrt16(f16 x) {
  return futrts_sqrt32(x);
}

static inline f16 futrts_exp16(f16 x) {
  return futrts_exp32(x);
}

static inline f16 futrts_cos16(f16 x) {
  return futrts_cos32(x);
}

static inline f16 futrts_sin16(f16 x) {
  return futrts_sin32(x);
}

static inline f16 futrts_tan16(f16 x) {
  return futrts_tan32(x);
}

static inline f16 futrts_acos16(f16 x) {
  return futrts_acos32(x);
}

static inline f16 futrts_asin16(f16 x) {
  return futrts_asin32(x);
}

static inline f16 futrts_atan16(f16 x) {
  return futrts_atan32(x);
}

static inline f16 futrts_cosh16(f16 x) {
  return futrts_cosh32(x);
}

static inline f16 futrts_sinh16(f16 x) {
  return futrts_sinh32(x);
}

static inline f16 futrts_tanh16(f16 x) {
  return futrts_tanh32(x);
}

static inline f16 futrts_acosh16(f16 x) {
  return futrts_acosh32(x);
}

static inline f16 futrts_asinh16(f16 x) {
  return futrts_asinh32(x);
}

static inline f16 futrts_atanh16(f16 x) {
  return futrts_atanh32(x);
}

static inline f16 futrts_atan2_16(f16 x, f16 y) {
  return futrts_atan2_32(x, y);
}

static inline f16 futrts_hypot16(f16 x, f16 y) {
  return futrts_hypot32(x, y);
}

static inline f16 futrts_gamma16(f16 x) {
  return futrts_gamma32(x);
}

static inline f16 futrts_lgamma16(f16 x) {
  return futrts_lgamma32(x);
}

static inline f16 fmod16(f16 x, f16 y) {
  return fmod32(x, y);
}

static inline f16 futrts_round16(f16 x) {
  return futrts_round32(x);
}

static inline f16 futrts_floor16(f16 x) {
  return futrts_floor32(x);
}

static inline f16 futrts_ceil16(f16 x) {
  return futrts_ceil32(x);
}

static inline f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {
  return futrts_lerp32(v0, v1, t);
}

static inline f16 futrts_mad16(f16 a, f16 b, f16 c) {
  return futrts_mad32(a, b, c);
}

static inline f16 futrts_fma16(f16 a, f16 b, f16 c) {
  return futrts_fma32(a, b, c);
}

// Even when we are using an OpenCL that does not support cl_khr_fp16,
// it must still support vload_half for actually creating a
// half-precision number, which can then be efficiently converted to a
// float.  Similarly for vstore_half.
#ifdef __OPENCL_VERSION__

static inline int16_t futrts_to_bits16(f16 x) {
  int16_t y;
  // Violating strict aliasing here.
  vstore_half((float)x, 0, (half*)&y);
  return y;
}

static inline f16 futrts_from_bits16(int16_t x) {
  return (f16)vload_half(0, (half*)&x);
}

#else

static inline int16_t futrts_to_bits16(f16 x) {
  return (int16_t)float2halfbits(x);
}

static inline f16 futrts_from_bits16(int16_t x) {
  return halfbits2float((uint16_t)x);
}

static inline f16 fsignum16(f16 x) {
  return futrts_isnan16(x) ? x : (x > 0) - (x < 0);
}

#endif

#endif

static inline float fpconv_f16_f16(f16 x) {
  return x;
}

static inline float fpconv_f16_f32(f16 x) {
  return x;
}

static inline f16 fpconv_f32_f16(float x) {
  return x;
}

#ifdef FUTHARK_F64_ENABLED

static inline double fpconv_f16_f64(f16 x) {
  return (double) x;
}

static inline f16 fpconv_f64_f16(double x) {
  return (f16) x;
}

#endif


// End of scalar_f16.h.

static int init_constants(struct futhark_context *);
static int free_constants(struct futhark_context *);
struct memblock_device {
    int *references;
    CUdeviceptr mem;
    int64_t size;
    const char *desc;
};
struct memblock {
    int *references;
    unsigned char *mem;
    int64_t size;
    const char *desc;
};
#include <cuda.h>
#include <nvrtc.h>
typedef CUdeviceptr fl_mem_t;
// Start of free_list.h.

// An entry in the free list.  May be invalid, to avoid having to
// deallocate entries as soon as they are removed.  There is also a
// tag, to help with memory reuse.
struct free_list_entry {
  size_t size;
  fl_mem_t mem;
  const char *tag;
  unsigned char valid;
};

struct free_list {
  struct free_list_entry *entries;        // Pointer to entries.
  int capacity;                           // Number of entries.
  int used;                               // Number of valid entries.
};

static void free_list_init(struct free_list *l) {
  l->capacity = 30; // Picked arbitrarily.
  l->used = 0;
  l->entries = (struct free_list_entry*) malloc(sizeof(struct free_list_entry) * l->capacity);
  for (int i = 0; i < l->capacity; i++) {
    l->entries[i].valid = 0;
  }
}

// Remove invalid entries from the free list.
static void free_list_pack(struct free_list *l) {
  int p = 0;
  for (int i = 0; i < l->capacity; i++) {
    if (l->entries[i].valid) {
      l->entries[p] = l->entries[i];
      if (i > p) {
        l->entries[i].valid = 0;
      }
      p++;
    }
  }

  // Now p is the number of used elements.  We don't want it to go
  // less than the default capacity (although in practice it's OK as
  // long as it doesn't become 1).
  if (p < 30) {
    p = 30;
  }
  l->entries = realloc(l->entries, p * sizeof(struct free_list_entry));
  l->capacity = p;
}

static void free_list_destroy(struct free_list *l) {
  assert(l->used == 0);
  free(l->entries);
}

static int free_list_find_invalid(struct free_list *l) {
  int i;
  for (i = 0; i < l->capacity; i++) {
    if (!l->entries[i].valid) {
      break;
    }
  }
  return i;
}

static void free_list_insert(struct free_list *l, size_t size, fl_mem_t mem, const char *tag) {
  int i = free_list_find_invalid(l);

  if (i == l->capacity) {
    // List is full; so we have to grow it.
    int new_capacity = l->capacity * 2 * sizeof(struct free_list_entry);
    l->entries = realloc(l->entries, new_capacity);
    for (int j = 0; j < l->capacity; j++) {
      l->entries[j+l->capacity].valid = 0;
    }
    l->capacity *= 2;
  }

  // Now 'i' points to the first invalid entry.
  l->entries[i].valid = 1;
  l->entries[i].size = size;
  l->entries[i].mem = mem;
  l->entries[i].tag = tag;

  l->used++;
}

// Find and remove a memory block of the indicated tag, or if that
// does not exist, another memory block with exactly the desired size.
// Returns 0 on success.
static int free_list_find(struct free_list *l, size_t size,
                          size_t *size_out, fl_mem_t *mem_out) {
  int size_match = -1;
  int i;
  for (i = 0; i < l->capacity; i++) {
    if (l->entries[i].valid &&
        size <= l->entries[i].size &&
        (size_match < 0 || l->entries[i].size < l->entries[size_match].size)) {
      // If this entry is valid, has sufficient size, and is smaller than the
      // best entry found so far, use this entry.
      size_match = i;
    }
  }

  if (size_match >= 0) {
    l->entries[size_match].valid = 0;
    *size_out = l->entries[size_match].size;
    *mem_out = l->entries[size_match].mem;
    l->used--;
    return 0;
  } else {
    return 1;
  }
}

// Remove the first block in the free list.  Returns 0 if a block was
// removed, and nonzero if the free list was already empty.
static int free_list_first(struct free_list *l, fl_mem_t *mem_out) {
  for (int i = 0; i < l->capacity; i++) {
    if (l->entries[i].valid) {
      l->entries[i].valid = 0;
      *mem_out = l->entries[i].mem;
      l->used--;
      return 0;
    }
  }

  return 1;
}

// End of free_list.h.

// Start of cuda.h.

#define CUDA_SUCCEED_FATAL(x) cuda_api_succeed_fatal(x, #x, __FILE__, __LINE__)
#define CUDA_SUCCEED_NONFATAL(x) cuda_api_succeed_nonfatal(x, #x, __FILE__, __LINE__)
#define NVRTC_SUCCEED_FATAL(x) nvrtc_api_succeed_fatal(x, #x, __FILE__, __LINE__)
#define NVRTC_SUCCEED_NONFATAL(x) nvrtc_api_succeed_nonfatal(x, #x, __FILE__, __LINE__)

#define SUCCEED_OR_RETURN(serror) {               \
    if (serror) {                                 \
      if (!ctx->error) {                          \
        ctx->error = serror;                      \
        return bad;                               \
      } else {                                    \
        free(serror);                             \
      }                                           \
    }                                             \
  }

#define CUDA_SUCCEED_OR_RETURN(e) SUCCEED_OR_RETURN(CUDA_SUCCEED_NONFATAL(e))

// CUDA_SUCCEED_OR_RETURN returns the value of the variable 'bad' in
// scope.  By default, it will be this one.  Create a local variable
// of some other type if needed.  This is a bit of a hack, but it
// saves effort in the code generator.
static const int bad = 1;

static inline void cuda_api_succeed_fatal(CUresult res, const char *call,
    const char *file, int line) {
  if (res != CUDA_SUCCESS) {
    const char *err_str;
    cuGetErrorString(res, &err_str);
    if (err_str == NULL) { err_str = "Unknown"; }
    futhark_panic(-1, "%s:%d: CUDA call\n  %s\nfailed with error code %d (%s)\n",
        file, line, call, res, err_str);
  }
}

static char* cuda_api_succeed_nonfatal(CUresult res, const char *call,
    const char *file, int line) {
  if (res != CUDA_SUCCESS) {
    const char *err_str;
    cuGetErrorString(res, &err_str);
    if (err_str == NULL) { err_str = "Unknown"; }
    return msgprintf("%s:%d: CUDA call\n  %s\nfailed with error code %d (%s)\n",
        file, line, call, res, err_str);
  } else {
    return NULL;
  }
}

static inline void nvrtc_api_succeed_fatal(nvrtcResult res, const char *call,
                                           const char *file, int line) {
  if (res != NVRTC_SUCCESS) {
    const char *err_str = nvrtcGetErrorString(res);
    futhark_panic(-1, "%s:%d: NVRTC call\n  %s\nfailed with error code %d (%s)\n",
        file, line, call, res, err_str);
  }
}

static char* nvrtc_api_succeed_nonfatal(nvrtcResult res, const char *call,
                                        const char *file, int line) {
  if (res != NVRTC_SUCCESS) {
    const char *err_str = nvrtcGetErrorString(res);
    return msgprintf("%s:%d: NVRTC call\n  %s\nfailed with error code %d (%s)\n",
                     file, line, call, res, err_str);
  } else {
    return NULL;
  }
}

struct cuda_config {
  int debugging;
  int logging;
  const char *preferred_device;
  int preferred_device_num;

  const char *dump_program_to;
  const char *load_program_from;

  const char *dump_ptx_to;
  const char *load_ptx_from;

  size_t default_block_size;
  size_t default_grid_size;
  size_t default_tile_size;
  size_t default_reg_tile_size;
  size_t default_threshold;

  int default_block_size_changed;
  int default_grid_size_changed;
  int default_tile_size_changed;

  int num_sizes;
  const char **size_names;
  const char **size_vars;
  int64_t *size_values;
  const char **size_classes;
};

static void cuda_config_init(struct cuda_config *cfg,
                             int num_sizes,
                             const char *size_names[],
                             const char *size_vars[],
                             int64_t *size_values,
                             const char *size_classes[]) {
  cfg->debugging = 0;
  cfg->logging = 0;
  cfg->preferred_device_num = 0;
  cfg->preferred_device = "";
  cfg->dump_program_to = NULL;
  cfg->load_program_from = NULL;

  cfg->dump_ptx_to = NULL;
  cfg->load_ptx_from = NULL;

  cfg->default_block_size = 256;
  cfg->default_grid_size = 0; // Set properly later.
  cfg->default_tile_size = 32;
  cfg->default_reg_tile_size = 2;
  cfg->default_threshold = 32*1024;

  cfg->default_block_size_changed = 0;
  cfg->default_grid_size_changed = 0;
  cfg->default_tile_size_changed = 0;

  cfg->num_sizes = num_sizes;
  cfg->size_names = size_names;
  cfg->size_vars = size_vars;
  cfg->size_values = size_values;
  cfg->size_classes = size_classes;
}

// A record of something that happened.
struct profiling_record {
  cudaEvent_t *events; // Points to two events.
  int *runs;
  int64_t *runtime;
};

struct cuda_context {
  CUdevice dev;
  CUcontext cu_ctx;
  CUmodule module;

  struct cuda_config cfg;

  struct free_list free_list;

  size_t max_block_size;
  size_t max_grid_size;
  size_t max_tile_size;
  size_t max_threshold;
  size_t max_shared_memory;
  size_t max_bespoke;

  size_t lockstep_width;

  struct profiling_record *profiling_records;
  int profiling_records_capacity;
  int profiling_records_used;
};

#define CU_DEV_ATTR(x) (CU_DEVICE_ATTRIBUTE_##x)
#define device_query(dev,attrib) _device_query(dev, CU_DEV_ATTR(attrib))
static int _device_query(CUdevice dev, CUdevice_attribute attrib) {
  int val;
  CUDA_SUCCEED_FATAL(cuDeviceGetAttribute(&val, attrib, dev));
  return val;
}

#define CU_FUN_ATTR(x) (CU_FUNC_ATTRIBUTE_##x)
#define function_query(fn,attrib) _function_query(dev, CU_FUN_ATTR(attrib))
static int _function_query(CUfunction dev, CUfunction_attribute attrib) {
  int val;
  CUDA_SUCCEED_FATAL(cuFuncGetAttribute(&val, attrib, dev));
  return val;
}

static void set_preferred_device(struct cuda_config *cfg, const char *s) {
  int x = 0;
  if (*s == '#') {
    s++;
    while (isdigit(*s)) {
      x = x * 10 + (*s++)-'0';
    }
    // Skip trailing spaces.
    while (isspace(*s)) {
      s++;
    }
  }
  cfg->preferred_device = s;
  cfg->preferred_device_num = x;
}

static int cuda_device_setup(struct cuda_context *ctx) {
  char name[256];
  int count, chosen = -1, best_cc = -1;
  int cc_major_best, cc_minor_best;
  int cc_major, cc_minor;
  CUdevice dev;

  CUDA_SUCCEED_FATAL(cuDeviceGetCount(&count));
  if (count == 0) { return 1; }

  int num_device_matches = 0;

  // XXX: Current device selection policy is to choose the device with the
  // highest compute capability (if no preferred device is set).
  // This should maybe be changed, since greater compute capability is not
  // necessarily an indicator of better performance.
  for (int i = 0; i < count; i++) {
    CUDA_SUCCEED_FATAL(cuDeviceGet(&dev, i));

    cc_major = device_query(dev, COMPUTE_CAPABILITY_MAJOR);
    cc_minor = device_query(dev, COMPUTE_CAPABILITY_MINOR);

    CUDA_SUCCEED_FATAL(cuDeviceGetName(name, sizeof(name) - 1, dev));
    name[sizeof(name) - 1] = 0;

    if (ctx->cfg.debugging) {
      fprintf(stderr, "Device #%d: name=\"%s\", compute capability=%d.%d\n",
          i, name, cc_major, cc_minor);
    }

    if (device_query(dev, COMPUTE_MODE) == CU_COMPUTEMODE_PROHIBITED) {
      if (ctx->cfg.debugging) {
        fprintf(stderr, "Device #%d is compute-prohibited, ignoring\n", i);
      }
      continue;
    }

    if (best_cc == -1 || cc_major > cc_major_best ||
        (cc_major == cc_major_best && cc_minor > cc_minor_best)) {
      best_cc = i;
      cc_major_best = cc_major;
      cc_minor_best = cc_minor;
    }

    if (strstr(name, ctx->cfg.preferred_device) != NULL &&
        num_device_matches++ == ctx->cfg.preferred_device_num) {
      chosen = i;
      break;
    }
  }

  if (chosen == -1) { chosen = best_cc; }
  if (chosen == -1) { return 1; }

  if (ctx->cfg.debugging) {
    fprintf(stderr, "Using device #%d\n", chosen);
  }

  CUDA_SUCCEED_FATAL(cuDeviceGet(&ctx->dev, chosen));
  return 0;
}

static char *concat_fragments(const char *src_fragments[]) {
  size_t src_len = 0;
  const char **p;

  for (p = src_fragments; *p; p++) {
    src_len += strlen(*p);
  }

  char *src = (char*) malloc(src_len + 1);
  size_t n = 0;
  for (p = src_fragments; *p; p++) {
    strcpy(src + n, *p);
    n += strlen(*p);
  }

  return src;
}

static const char *cuda_nvrtc_get_arch(CUdevice dev) {
  struct {
    int major;
    int minor;
    const char *arch_str;
  } static const x[] = {
    { 3, 0, "compute_30" },
    { 3, 2, "compute_32" },
    { 3, 5, "compute_35" },
    { 3, 7, "compute_37" },
    { 5, 0, "compute_50" },
    { 5, 2, "compute_52" },
    { 5, 3, "compute_53" },
    { 6, 0, "compute_60" },
    { 6, 1, "compute_61" },
    { 6, 2, "compute_62" },
    { 7, 0, "compute_70" },
    { 7, 2, "compute_72" },
    { 7, 5, "compute_75" },
    { 8, 0, "compute_80" }
  };

  int major = device_query(dev, COMPUTE_CAPABILITY_MAJOR);
  int minor = device_query(dev, COMPUTE_CAPABILITY_MINOR);

  int chosen = -1;
  for (int i = 0; i < sizeof(x)/sizeof(x[0]); i++) {
    if (x[i].major < major || (x[i].major == major && x[i].minor <= minor)) {
      chosen = i;
    } else {
      break;
    }
  }

  if (chosen == -1) {
    futhark_panic(-1, "Unsupported compute capability %d.%d\n", major, minor);
  }

  if (x[chosen].major != major || x[chosen].minor != minor) {
    fprintf(stderr,
            "Warning: device compute capability is %d.%d, but newest supported by Futhark is %d.%d.\n",
            major, minor, x[chosen].major, x[chosen].minor);
  }

  return x[chosen].arch_str;
}

static char* cuda_nvrtc_build(struct cuda_context *ctx, const char *src,
                              const char *extra_opts[], char **ptx) {
  nvrtcProgram prog;
  char *problem = NULL;

  problem = NVRTC_SUCCEED_NONFATAL(nvrtcCreateProgram(&prog, src, "futhark-cuda", 0, NULL, NULL));

  if (problem) {
    return problem;
  }

  int arch_set = 0, num_extra_opts;

  // nvrtc cannot handle multiple -arch options.  Hence, if one of the
  // extra_opts is -arch, we have to be careful not to do our usual
  // automatic generation.
  for (num_extra_opts = 0; extra_opts[num_extra_opts] != NULL; num_extra_opts++) {
    if (strstr(extra_opts[num_extra_opts], "-arch")
        == extra_opts[num_extra_opts] ||
        strstr(extra_opts[num_extra_opts], "--gpu-architecture")
        == extra_opts[num_extra_opts]) {
      arch_set = 1;
    }
  }

  size_t n_opts, i = 0, i_dyn, n_opts_alloc = 20 + num_extra_opts + ctx->cfg.num_sizes;
  const char **opts = (const char**) malloc(n_opts_alloc * sizeof(const char *));
  if (!arch_set) {
    opts[i++] = "-arch";
    opts[i++] = cuda_nvrtc_get_arch(ctx->dev);
  }
  opts[i++] = "-default-device";
  if (ctx->cfg.debugging) {
    opts[i++] = "-G";
    opts[i++] = "-lineinfo";
  } else {
    opts[i++] = "--disable-warnings";
  }
  i_dyn = i;
  for (size_t j = 0; j < ctx->cfg.num_sizes; j++) {
    opts[i++] = msgprintf("-D%s=%zu", ctx->cfg.size_vars[j],
        ctx->cfg.size_values[j]);
  }
  opts[i++] = msgprintf("-DLOCKSTEP_WIDTH=%zu", ctx->lockstep_width);
  opts[i++] = msgprintf("-DMAX_THREADS_PER_BLOCK=%zu", ctx->max_block_size);

  // Time for the best lines of the code in the entire compiler.
  if (getenv("CUDA_HOME") != NULL) {
    opts[i++] = msgprintf("-I%s/include", getenv("CUDA_HOME"));
  }
  if (getenv("CUDA_ROOT") != NULL) {
    opts[i++] = msgprintf("-I%s/include", getenv("CUDA_ROOT"));
  }
  if (getenv("CUDA_PATH") != NULL) {
    opts[i++] = msgprintf("-I%s/include", getenv("CUDA_PATH"));
  }
  opts[i++] = msgprintf("-I/usr/local/cuda/include");
  opts[i++] = msgprintf("-I/usr/include");

  // It is crucial that the extra_opts are last, so that the free()
  // logic below does not cause problems.
  for (int j = 0; extra_opts[j] != NULL; j++) {
    opts[i++] = extra_opts[j];
  }

  n_opts = i;

  if (ctx->cfg.debugging) {
    fprintf(stderr, "NVRTC compile options:\n");
    for (size_t j = 0; j < n_opts; j++) {
      fprintf(stderr, "\t%s\n", opts[j]);
    }
    fprintf(stderr, "\n");
  }

  nvrtcResult res = nvrtcCompileProgram(prog, n_opts, opts);
  if (res != NVRTC_SUCCESS) {
    size_t log_size;
    if (nvrtcGetProgramLogSize(prog, &log_size) == NVRTC_SUCCESS) {
      char *log = (char*) malloc(log_size);
      if (nvrtcGetProgramLog(prog, log) == NVRTC_SUCCESS) {
        problem = msgprintf("NVRTC compilation failed.\n\n%s\n", log);
      } else {
        problem = msgprintf("Could not retrieve compilation log\n");
      }
      free(log);
    }
    return problem;
  }

  for (i = i_dyn; i < n_opts-num_extra_opts; i++) { free((char *)opts[i]); }
  free(opts);

  size_t ptx_size;
  NVRTC_SUCCEED_FATAL(nvrtcGetPTXSize(prog, &ptx_size));
  *ptx = (char*) malloc(ptx_size);
  NVRTC_SUCCEED_FATAL(nvrtcGetPTX(prog, *ptx));

  NVRTC_SUCCEED_FATAL(nvrtcDestroyProgram(&prog));

  return NULL;
}

static void cuda_size_setup(struct cuda_context *ctx)
{
  if (ctx->cfg.default_block_size > ctx->max_block_size) {
    if (ctx->cfg.default_block_size_changed) {
      fprintf(stderr,
          "Note: Device limits default block size to %zu (down from %zu).\n",
          ctx->max_block_size, ctx->cfg.default_block_size);
    }
    ctx->cfg.default_block_size = ctx->max_block_size;
  }
  if (ctx->cfg.default_grid_size > ctx->max_grid_size) {
    if (ctx->cfg.default_grid_size_changed) {
      fprintf(stderr,
          "Note: Device limits default grid size to %zu (down from %zu).\n",
          ctx->max_grid_size, ctx->cfg.default_grid_size);
    }
    ctx->cfg.default_grid_size = ctx->max_grid_size;
  }
  if (ctx->cfg.default_tile_size > ctx->max_tile_size) {
    if (ctx->cfg.default_tile_size_changed) {
      fprintf(stderr,
          "Note: Device limits default tile size to %zu (down from %zu).\n",
          ctx->max_tile_size, ctx->cfg.default_tile_size);
    }
    ctx->cfg.default_tile_size = ctx->max_tile_size;
  }

  if (!ctx->cfg.default_grid_size_changed) {
    ctx->cfg.default_grid_size =
      (device_query(ctx->dev, MULTIPROCESSOR_COUNT) *
       device_query(ctx->dev, MAX_THREADS_PER_MULTIPROCESSOR))
      / ctx->cfg.default_block_size;
  }

  for (int i = 0; i < ctx->cfg.num_sizes; i++) {
    const char *size_class = ctx->cfg.size_classes[i];
    int64_t *size_value = &ctx->cfg.size_values[i];
    const char* size_name = ctx->cfg.size_names[i];
    int64_t max_value = 0, default_value = 0;

    if (strstr(size_class, "group_size") == size_class) {
      max_value = ctx->max_block_size;
      default_value = ctx->cfg.default_block_size;
    } else if (strstr(size_class, "num_groups") == size_class) {
      max_value = ctx->max_grid_size;
      default_value = ctx->cfg.default_grid_size;
      // XXX: as a quick and dirty hack, use twice as many threads for
      // histograms by default.  We really should just be smarter
      // about sizes somehow.
      if (strstr(size_name, ".seghist_") != NULL) {
        default_value *= 2;
      }
    } else if (strstr(size_class, "tile_size") == size_class) {
      max_value = ctx->max_tile_size;
      default_value = ctx->cfg.default_tile_size;
    } else if (strstr(size_class, "reg_tile_size") == size_class) {
      max_value = 0; // No limit.
      default_value = ctx->cfg.default_reg_tile_size;
    } else if (strstr(size_class, "threshold") == size_class) {
      // Threshold can be as large as it takes.
      default_value = ctx->cfg.default_threshold;
    } else {
      // Bespoke sizes have no limit or default.
    }

    if (*size_value == 0) {
      *size_value = default_value;
    } else if (max_value > 0 && *size_value > max_value) {
      fprintf(stderr, "Note: Device limits %s to %zu (down from %zu)\n",
              size_name, max_value, *size_value);
      *size_value = max_value;
    }
  }
}

static char* cuda_module_setup(struct cuda_context *ctx,
                               const char *src_fragments[],
                               const char *extra_opts[]) {
  char *ptx = NULL, *src = NULL;

  if (ctx->cfg.load_program_from == NULL) {
    src = concat_fragments(src_fragments);
  } else {
    src = slurp_file(ctx->cfg.load_program_from, NULL);
  }

  if (ctx->cfg.load_ptx_from) {
    if (ctx->cfg.load_program_from != NULL) {
      fprintf(stderr,
              "WARNING: Using PTX from %s instead of C code from %s\n",
              ctx->cfg.load_ptx_from, ctx->cfg.load_program_from);
    }
    ptx = slurp_file(ctx->cfg.load_ptx_from, NULL);
  }

  if (ctx->cfg.dump_program_to != NULL) {
    dump_file(ctx->cfg.dump_program_to, src, strlen(src));
  }

  if (ptx == NULL) {
    char* problem = cuda_nvrtc_build(ctx, src, extra_opts, &ptx);
    if (problem != NULL) {
      free(src);
      return problem;
    }
  }

  if (ctx->cfg.dump_ptx_to != NULL) {
    dump_file(ctx->cfg.dump_ptx_to, ptx, strlen(ptx));
  }

  CUDA_SUCCEED_FATAL(cuModuleLoadData(&ctx->module, ptx));

  free(ptx);
  if (src != NULL) {
    free(src);
  }

  return NULL;
}

static char* cuda_setup(struct cuda_context *ctx, const char *src_fragments[], const char *extra_opts[]) {
  CUDA_SUCCEED_FATAL(cuInit(0));

  if (cuda_device_setup(ctx) != 0) {
    futhark_panic(-1, "No suitable CUDA device found.\n");
  }
  CUDA_SUCCEED_FATAL(cuCtxCreate(&ctx->cu_ctx, 0, ctx->dev));

  free_list_init(&ctx->free_list);

  ctx->max_shared_memory = device_query(ctx->dev, MAX_SHARED_MEMORY_PER_BLOCK);
  ctx->max_block_size = device_query(ctx->dev, MAX_THREADS_PER_BLOCK);
  ctx->max_grid_size = device_query(ctx->dev, MAX_GRID_DIM_X);
  ctx->max_tile_size = sqrt(ctx->max_block_size);
  ctx->max_threshold = 0;
  ctx->max_bespoke = 0;
  ctx->lockstep_width = device_query(ctx->dev, WARP_SIZE);

  cuda_size_setup(ctx);
  return cuda_module_setup(ctx, src_fragments, extra_opts);
}

// Count up the runtime all the profiling_records that occured during execution.
// Also clears the buffer of profiling_records.
static cudaError_t cuda_tally_profiling_records(struct cuda_context *ctx) {
  cudaError_t err;
  for (int i = 0; i < ctx->profiling_records_used; i++) {
    struct profiling_record record = ctx->profiling_records[i];

    float ms;
    if ((err = cudaEventElapsedTime(&ms, record.events[0], record.events[1])) != cudaSuccess) {
      return err;
    }

    // CUDA provides milisecond resolution, but we want microseconds.
    *record.runs += 1;
    *record.runtime += ms*1000;

    if ((err = cudaEventDestroy(record.events[0])) != cudaSuccess) {
      return err;
    }
    if ((err = cudaEventDestroy(record.events[1])) != cudaSuccess) {
      return err;
    }

    free(record.events);
  }

  ctx->profiling_records_used = 0;

  return cudaSuccess;
}

// Returns pointer to two events.
static cudaEvent_t* cuda_get_events(struct cuda_context *ctx, int *runs, int64_t *runtime) {
    if (ctx->profiling_records_used == ctx->profiling_records_capacity) {
      ctx->profiling_records_capacity *= 2;
      ctx->profiling_records =
        realloc(ctx->profiling_records,
                ctx->profiling_records_capacity *
                sizeof(struct profiling_record));
    }
    cudaEvent_t *events = calloc(2, sizeof(cudaEvent_t));
    cudaEventCreate(&events[0]);
    cudaEventCreate(&events[1]);
    ctx->profiling_records[ctx->profiling_records_used].events = events;
    ctx->profiling_records[ctx->profiling_records_used].runs = runs;
    ctx->profiling_records[ctx->profiling_records_used].runtime = runtime;
    ctx->profiling_records_used++;
    return events;
}

static CUresult cuda_free_all(struct cuda_context *ctx);

static void cuda_cleanup(struct cuda_context *ctx) {
  CUDA_SUCCEED_FATAL(cuda_free_all(ctx));
  (void)cuda_tally_profiling_records(ctx);
  free(ctx->profiling_records);
  CUDA_SUCCEED_FATAL(cuModuleUnload(ctx->module));
  CUDA_SUCCEED_FATAL(cuCtxDestroy(ctx->cu_ctx));
}

static CUresult cuda_alloc(struct cuda_context *ctx, size_t min_size,
                           const char *tag, CUdeviceptr *mem_out) {
  if (min_size < sizeof(int)) {
    min_size = sizeof(int);
  }

  size_t size;
  if (free_list_find(&ctx->free_list, min_size, &size, mem_out) == 0) {
    if (size >= min_size) {
      return CUDA_SUCCESS;
    } else {
      CUresult res = cuMemFree(*mem_out);
      if (res != CUDA_SUCCESS) {
        return res;
      }
    }
  }

  CUresult res = cuMemAlloc(mem_out, min_size);
  while (res == CUDA_ERROR_OUT_OF_MEMORY) {
    CUdeviceptr mem;
    if (free_list_first(&ctx->free_list, &mem) == 0) {
      res = cuMemFree(mem);
      if (res != CUDA_SUCCESS) {
        return res;
      }
    } else {
      break;
    }
    res = cuMemAlloc(mem_out, min_size);
  }

  return res;
}

static CUresult cuda_free(struct cuda_context *ctx, CUdeviceptr mem,
                          const char *tag) {
  size_t size;
  CUdeviceptr existing_mem;

  // If there is already a block with this tag, then remove it.
  if (free_list_find(&ctx->free_list, -1, &size, &existing_mem) == 0) {
    CUresult res = cuMemFree(existing_mem);
    if (res != CUDA_SUCCESS) {
      return res;
    }
  }

  CUresult res = cuMemGetAddressRange(NULL, &size, mem);
  if (res == CUDA_SUCCESS) {
    free_list_insert(&ctx->free_list, size, mem, tag);
  }

  return res;
}

static CUresult cuda_free_all(struct cuda_context *ctx) {
  CUdeviceptr mem;
  free_list_pack(&ctx->free_list);
  while (free_list_first(&ctx->free_list, &mem) == 0) {
    CUresult res = cuMemFree(mem);
    if (res != CUDA_SUCCESS) {
      return res;
    }
  }

  return CUDA_SUCCESS;
}

// End of cuda.h.

const char *cuda_program[] =
           {"\n#define FUTHARK_CUDA\n#define FUTHARK_F64_ENABLED\n\ntypedef char int8_t;\ntypedef short int16_t;\ntypedef int int32_t;\ntypedef long long int64_t;\ntypedef unsigned char uint8_t;\ntypedef unsigned short uint16_t;\ntypedef unsigned int uint32_t;\ntypedef unsigned long long uint64_t;\ntypedef uint8_t uchar;\ntypedef uint16_t ushort;\ntypedef uint32_t uint;\ntypedef uint64_t ulong;\n#define __kernel extern \"C\" __global__ __launch_bounds__(MAX_THREADS_PER_BLOCK)\n#define __global\n#define __local\n#define __private\n#define __constant\n#define __write_only\n#define __read_only\n\nstatic inline int get_group_id_fn(int block_dim0, int block_dim1, int block_dim2, int d) {\n  switch (d) {\n    case 0: d = block_dim0; break;\n    case 1: d = block_dim1; break;\n    case 2: d = block_dim2; break;\n  }\n  switch (d) {\n    case 0: return blockIdx.x;\n    case 1: return blockIdx.y;\n    case 2: return blockIdx.z;\n    default: return 0;\n  }\n}\n#define get_group_id(d) get_group_id_fn(block_dim0, block_dim1, block_dim2, d)\n\nstatic inline int get_num_groups_fn(int block_dim0, int block_dim1, int block_dim2, int d) {\n  switch (d) {\n    case 0: d = block_dim0; break;\n    case 1: d = block_dim1; break;\n    case 2: d = block_dim2; break;\n  }\n  switch(d) {\n    case 0: return gridDim.x;\n    case 1: return gridDim.y;\n    case 2: return gridDim.z;\n    default: return 0;\n  }\n}\n#define get_num_groups(d) get_num_groups_fn(block_dim0, block_dim1, block_dim2, d)\n\nstatic inline int get_local_id(int d) {\n  switch (d) {\n    case 0: return threadIdx.x;\n    case 1: return threadIdx.y;\n    case 2: return threadIdx.z;\n    default: return 0;\n  }\n}\n\nstatic inline int get_local_size(int d) {\n  switch (d) {\n    case 0: return blockDim.x;\n    case 1: return blockDim.y;\n    case 2: return blockDim.z;\n    default: return 0;\n  }\n}\n\nstatic inline int get_global_id_fn(int block_dim0, int block_dim1, int block_dim2, int d) {\n  return get_group_id(d) * get_local_size(d) + get_local_id(d);\n}\n#define get_global_id(d) get_global_id_fn(block_dim0,",
            " block_dim1, block_dim2, d)\n\nstatic inline int get_global_size(int block_dim0, int block_dim1, int block_dim2, int d) {\n  return get_num_groups(d) * get_local_size(d);\n}\n\n#define CLK_LOCAL_MEM_FENCE 1\n#define CLK_GLOBAL_MEM_FENCE 2\nstatic inline void barrier(int x) {\n  __syncthreads();\n}\nstatic inline void mem_fence_local() {\n  __threadfence_block();\n}\nstatic inline void mem_fence_global() {\n  __threadfence();\n}\n\n#define NAN (0.0/0.0)\n#define INFINITY (1.0/0.0)\nextern volatile __shared__ unsigned char shared_mem[];\n// Start of half.h.\n\n// Conversion functions are from http://half.sourceforge.net/, but\n// translated to C.\n//\n// Copyright (c) 2012-2021 Christian Rau\n//\n// Permission is hereby granted, free of charge, to any person obtaining a copy\n// of this software and associated documentation files (the \"Software\"), to deal\n// in the Software without restriction, including without limitation the rights\n// to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n// copies of the Software, and to permit persons to whom the Software is\n// furnished to do so, subject to the following conditions:\n//\n// The above copyright notice and this permission notice shall be included in\n// all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n// THE SOFTWARE.\n\n#ifndef __OPENCL_VERSION__\n#define __constant\n#endif\n\n__constant static const uint16_t base_table[512] = {\n  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,\n  0x0000, 0x00",
            "00, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,\n  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,\n  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,\n  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,\n  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,\n  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0001, 0x0002, 0x0004, 0x0008, 0x0010, 0x0020, 0x0040, 0x0080, 0x0100,\n  0x0200, 0x0400, 0x0800, 0x0C00, 0x1000, 0x1400, 0x1800, 0x1C00, 0x2000, 0x2400, 0x2800, 0x2C00, 0x3000, 0x3400, 0x3800, 0x3C00,\n  0x4000, 0x4400, 0x4800, 0x4C00, 0x5000, 0x5400, 0x5800, 0x5C00, 0x6000, 0x6400, 0x6800, 0x6C00, 0x7000, 0x7400, 0x7800, 0x7C00,\n  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,\n  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,\n  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,\n  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,\n  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,\n  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,\n  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,\n  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000",
            ", 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,\n  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,\n  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,\n  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,\n  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,\n  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,\n  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8001, 0x8002, 0x8004, 0x8008, 0x8010, 0x8020, 0x8040, 0x8080, 0x8100,\n  0x8200, 0x8400, 0x8800, 0x8C00, 0x9000, 0x9400, 0x9800, 0x9C00, 0xA000, 0xA400, 0xA800, 0xAC00, 0xB000, 0xB400, 0xB800, 0xBC00,\n  0xC000, 0xC400, 0xC800, 0xCC00, 0xD000, 0xD400, 0xD800, 0xDC00, 0xE000, 0xE400, 0xE800, 0xEC00, 0xF000, 0xF400, 0xF800, 0xFC00,\n  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,\n  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,\n  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,\n  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,\n  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,\n  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,\n  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, ",
            "0xFC00, 0xFC00 };\n\n__constant static const unsigned char shift_table[512] = {\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n  13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 13,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n  13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, ",
            "24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 13 };\n\n__constant static const uint32_t mantissa_table[2048] = {\n  0x00000000, 0x33800000, 0x34000000, 0x34400000, 0x34800000, 0x34A00000, 0x34C00000, 0x34E00000, 0x35000000, 0x35100000, 0x35200000, 0x35300000, 0x35400000, 0x35500000, 0x35600000, 0x35700000,\n  0x35800000, 0x35880000, 0x35900000, 0x35980000, 0x35A00000, 0x35A80000, 0x35B00000, 0x35B80000, 0x35C00000, 0x35C80000, 0x35D00000, 0x35D80000, 0x35E00000, 0x35E80000, 0x35F00000, 0x35F80000,\n  0x36000000, 0x36040000, 0x36080000, 0x360C0000, 0x36100000, 0x36140000, 0x36180000, 0x361C0000, 0x36200000, 0x36240000, 0x36280000, 0x362C0000, 0x36300000, 0x36340000, 0x36380000, 0x363C0000,\n  0x36400000, 0x36440000, 0x36480000, 0x364C0000, 0x36500000, 0x36540000, 0x36580000, 0x365C0000, 0x36600000, 0x36640000, 0x36680000, 0x366C0000, 0x36700000, 0x36740000, 0x36780000, 0x367C0000,\n  0x36800000, 0x36820000, 0x36840000, 0x36860000, 0x36880000, 0x368A0000, 0x368C0000, 0x368E0000, 0x36900000, 0x36920000, 0x36940000, 0x36960000, 0x36980000, 0x369A0000, 0x369C0000, 0x369E0000,\n  0x36A00000, 0x36A20000, 0x36A40000, 0x36A60000, 0x36A80000, 0x36AA0000, 0x36AC0000, 0x36AE0000, 0x36B00000, 0x36B20000, 0x36B40000, 0x36B60000, 0x36B80000, 0x36BA0000, 0x36BC0000, 0x36BE0000,\n  0x36C00000, 0x36C20000, 0x36C40000, 0x36C60000, 0x36C80000, 0x36CA0000, 0x36CC0000, 0x36CE0000, 0x36D00000, 0x36D20000, 0x36D40000, 0x36D60000, 0x36D80000, 0x36DA0000, 0x36DC0000, 0x36DE0000,\n  0x36E00000, 0x36E20000, 0x36E40000, 0x36E60000, 0x36E80000, 0x36EA0000, 0x36EC0000, 0x36EE0000, 0x36F00000, 0x36F20000, 0x36F40000, 0x36F60000, 0x36F80000, 0x36FA0000, 0x36FC0000, 0x36FE0000,\n  0x37000000, 0x37010000, 0x37020000, 0x37030000, 0x37040000, 0x37050000, 0x37060000, 0x37070000, 0x37080000, 0x37090000, 0x370A0000, 0x370B0000, 0x370C0000, 0x370D0000, 0x370E0000, 0x370F0000,\n  0x37100000, 0x37110000, 0x3712000",
            "0, 0x37130000, 0x37140000, 0x37150000, 0x37160000, 0x37170000, 0x37180000, 0x37190000, 0x371A0000, 0x371B0000, 0x371C0000, 0x371D0000, 0x371E0000, 0x371F0000,\n  0x37200000, 0x37210000, 0x37220000, 0x37230000, 0x37240000, 0x37250000, 0x37260000, 0x37270000, 0x37280000, 0x37290000, 0x372A0000, 0x372B0000, 0x372C0000, 0x372D0000, 0x372E0000, 0x372F0000,\n  0x37300000, 0x37310000, 0x37320000, 0x37330000, 0x37340000, 0x37350000, 0x37360000, 0x37370000, 0x37380000, 0x37390000, 0x373A0000, 0x373B0000, 0x373C0000, 0x373D0000, 0x373E0000, 0x373F0000,\n  0x37400000, 0x37410000, 0x37420000, 0x37430000, 0x37440000, 0x37450000, 0x37460000, 0x37470000, 0x37480000, 0x37490000, 0x374A0000, 0x374B0000, 0x374C0000, 0x374D0000, 0x374E0000, 0x374F0000,\n  0x37500000, 0x37510000, 0x37520000, 0x37530000, 0x37540000, 0x37550000, 0x37560000, 0x37570000, 0x37580000, 0x37590000, 0x375A0000, 0x375B0000, 0x375C0000, 0x375D0000, 0x375E0000, 0x375F0000,\n  0x37600000, 0x37610000, 0x37620000, 0x37630000, 0x37640000, 0x37650000, 0x37660000, 0x37670000, 0x37680000, 0x37690000, 0x376A0000, 0x376B0000, 0x376C0000, 0x376D0000, 0x376E0000, 0x376F0000,\n  0x37700000, 0x37710000, 0x37720000, 0x37730000, 0x37740000, 0x37750000, 0x37760000, 0x37770000, 0x37780000, 0x37790000, 0x377A0000, 0x377B0000, 0x377C0000, 0x377D0000, 0x377E0000, 0x377F0000,\n  0x37800000, 0x37808000, 0x37810000, 0x37818000, 0x37820000, 0x37828000, 0x37830000, 0x37838000, 0x37840000, 0x37848000, 0x37850000, 0x37858000, 0x37860000, 0x37868000, 0x37870000, 0x37878000,\n  0x37880000, 0x37888000, 0x37890000, 0x37898000, 0x378A0000, 0x378A8000, 0x378B0000, 0x378B8000, 0x378C0000, 0x378C8000, 0x378D0000, 0x378D8000, 0x378E0000, 0x378E8000, 0x378F0000, 0x378F8000,\n  0x37900000, 0x37908000, 0x37910000, 0x37918000, 0x37920000, 0x37928000, 0x37930000, 0x37938000, 0x37940000, 0x37948000, 0x37950000, 0x37958000, 0x37960000, 0x37968000, 0x37970000, 0x37978000,\n  0x37980000, 0x37988000, 0x37990000, 0x37998000, 0x379A0000, 0x379A8000, 0x379B0000, 0x379B800",
            "0, 0x379C0000, 0x379C8000, 0x379D0000, 0x379D8000, 0x379E0000, 0x379E8000, 0x379F0000, 0x379F8000,\n  0x37A00000, 0x37A08000, 0x37A10000, 0x37A18000, 0x37A20000, 0x37A28000, 0x37A30000, 0x37A38000, 0x37A40000, 0x37A48000, 0x37A50000, 0x37A58000, 0x37A60000, 0x37A68000, 0x37A70000, 0x37A78000,\n  0x37A80000, 0x37A88000, 0x37A90000, 0x37A98000, 0x37AA0000, 0x37AA8000, 0x37AB0000, 0x37AB8000, 0x37AC0000, 0x37AC8000, 0x37AD0000, 0x37AD8000, 0x37AE0000, 0x37AE8000, 0x37AF0000, 0x37AF8000,\n  0x37B00000, 0x37B08000, 0x37B10000, 0x37B18000, 0x37B20000, 0x37B28000, 0x37B30000, 0x37B38000, 0x37B40000, 0x37B48000, 0x37B50000, 0x37B58000, 0x37B60000, 0x37B68000, 0x37B70000, 0x37B78000,\n  0x37B80000, 0x37B88000, 0x37B90000, 0x37B98000, 0x37BA0000, 0x37BA8000, 0x37BB0000, 0x37BB8000, 0x37BC0000, 0x37BC8000, 0x37BD0000, 0x37BD8000, 0x37BE0000, 0x37BE8000, 0x37BF0000, 0x37BF8000,\n  0x37C00000, 0x37C08000, 0x37C10000, 0x37C18000, 0x37C20000, 0x37C28000, 0x37C30000, 0x37C38000, 0x37C40000, 0x37C48000, 0x37C50000, 0x37C58000, 0x37C60000, 0x37C68000, 0x37C70000, 0x37C78000,\n  0x37C80000, 0x37C88000, 0x37C90000, 0x37C98000, 0x37CA0000, 0x37CA8000, 0x37CB0000, 0x37CB8000, 0x37CC0000, 0x37CC8000, 0x37CD0000, 0x37CD8000, 0x37CE0000, 0x37CE8000, 0x37CF0000, 0x37CF8000,\n  0x37D00000, 0x37D08000, 0x37D10000, 0x37D18000, 0x37D20000, 0x37D28000, 0x37D30000, 0x37D38000, 0x37D40000, 0x37D48000, 0x37D50000, 0x37D58000, 0x37D60000, 0x37D68000, 0x37D70000, 0x37D78000,\n  0x37D80000, 0x37D88000, 0x37D90000, 0x37D98000, 0x37DA0000, 0x37DA8000, 0x37DB0000, 0x37DB8000, 0x37DC0000, 0x37DC8000, 0x37DD0000, 0x37DD8000, 0x37DE0000, 0x37DE8000, 0x37DF0000, 0x37DF8000,\n  0x37E00000, 0x37E08000, 0x37E10000, 0x37E18000, 0x37E20000, 0x37E28000, 0x37E30000, 0x37E38000, 0x37E40000, 0x37E48000, 0x37E50000, 0x37E58000, 0x37E60000, 0x37E68000, 0x37E70000, 0x37E78000,\n  0x37E80000, 0x37E88000, 0x37E90000, 0x37E98000, 0x37EA0000, 0x37EA8000, 0x37EB0000, 0x37EB8000, 0x37EC0000, 0x37EC8000, 0x37ED0000, 0x37ED8000, 0x37EE000",
            "0, 0x37EE8000, 0x37EF0000, 0x37EF8000,\n  0x37F00000, 0x37F08000, 0x37F10000, 0x37F18000, 0x37F20000, 0x37F28000, 0x37F30000, 0x37F38000, 0x37F40000, 0x37F48000, 0x37F50000, 0x37F58000, 0x37F60000, 0x37F68000, 0x37F70000, 0x37F78000,\n  0x37F80000, 0x37F88000, 0x37F90000, 0x37F98000, 0x37FA0000, 0x37FA8000, 0x37FB0000, 0x37FB8000, 0x37FC0000, 0x37FC8000, 0x37FD0000, 0x37FD8000, 0x37FE0000, 0x37FE8000, 0x37FF0000, 0x37FF8000,\n  0x38000000, 0x38004000, 0x38008000, 0x3800C000, 0x38010000, 0x38014000, 0x38018000, 0x3801C000, 0x38020000, 0x38024000, 0x38028000, 0x3802C000, 0x38030000, 0x38034000, 0x38038000, 0x3803C000,\n  0x38040000, 0x38044000, 0x38048000, 0x3804C000, 0x38050000, 0x38054000, 0x38058000, 0x3805C000, 0x38060000, 0x38064000, 0x38068000, 0x3806C000, 0x38070000, 0x38074000, 0x38078000, 0x3807C000,\n  0x38080000, 0x38084000, 0x38088000, 0x3808C000, 0x38090000, 0x38094000, 0x38098000, 0x3809C000, 0x380A0000, 0x380A4000, 0x380A8000, 0x380AC000, 0x380B0000, 0x380B4000, 0x380B8000, 0x380BC000,\n  0x380C0000, 0x380C4000, 0x380C8000, 0x380CC000, 0x380D0000, 0x380D4000, 0x380D8000, 0x380DC000, 0x380E0000, 0x380E4000, 0x380E8000, 0x380EC000, 0x380F0000, 0x380F4000, 0x380F8000, 0x380FC000,\n  0x38100000, 0x38104000, 0x38108000, 0x3810C000, 0x38110000, 0x38114000, 0x38118000, 0x3811C000, 0x38120000, 0x38124000, 0x38128000, 0x3812C000, 0x38130000, 0x38134000, 0x38138000, 0x3813C000,\n  0x38140000, 0x38144000, 0x38148000, 0x3814C000, 0x38150000, 0x38154000, 0x38158000, 0x3815C000, 0x38160000, 0x38164000, 0x38168000, 0x3816C000, 0x38170000, 0x38174000, 0x38178000, 0x3817C000,\n  0x38180000, 0x38184000, 0x38188000, 0x3818C000, 0x38190000, 0x38194000, 0x38198000, 0x3819C000, 0x381A0000, 0x381A4000, 0x381A8000, 0x381AC000, 0x381B0000, 0x381B4000, 0x381B8000, 0x381BC000,\n  0x381C0000, 0x381C4000, 0x381C8000, 0x381CC000, 0x381D0000, 0x381D4000, 0x381D8000, 0x381DC000, 0x381E0000, 0x381E4000, 0x381E8000, 0x381EC000, 0x381F0000, 0x381F4000, 0x381F8000, 0x381FC000,\n  0x38200000, 0x38204",
            "000, 0x38208000, 0x3820C000, 0x38210000, 0x38214000, 0x38218000, 0x3821C000, 0x38220000, 0x38224000, 0x38228000, 0x3822C000, 0x38230000, 0x38234000, 0x38238000, 0x3823C000,\n  0x38240000, 0x38244000, 0x38248000, 0x3824C000, 0x38250000, 0x38254000, 0x38258000, 0x3825C000, 0x38260000, 0x38264000, 0x38268000, 0x3826C000, 0x38270000, 0x38274000, 0x38278000, 0x3827C000,\n  0x38280000, 0x38284000, 0x38288000, 0x3828C000, 0x38290000, 0x38294000, 0x38298000, 0x3829C000, 0x382A0000, 0x382A4000, 0x382A8000, 0x382AC000, 0x382B0000, 0x382B4000, 0x382B8000, 0x382BC000,\n  0x382C0000, 0x382C4000, 0x382C8000, 0x382CC000, 0x382D0000, 0x382D4000, 0x382D8000, 0x382DC000, 0x382E0000, 0x382E4000, 0x382E8000, 0x382EC000, 0x382F0000, 0x382F4000, 0x382F8000, 0x382FC000,\n  0x38300000, 0x38304000, 0x38308000, 0x3830C000, 0x38310000, 0x38314000, 0x38318000, 0x3831C000, 0x38320000, 0x38324000, 0x38328000, 0x3832C000, 0x38330000, 0x38334000, 0x38338000, 0x3833C000,\n  0x38340000, 0x38344000, 0x38348000, 0x3834C000, 0x38350000, 0x38354000, 0x38358000, 0x3835C000, 0x38360000, 0x38364000, 0x38368000, 0x3836C000, 0x38370000, 0x38374000, 0x38378000, 0x3837C000,\n  0x38380000, 0x38384000, 0x38388000, 0x3838C000, 0x38390000, 0x38394000, 0x38398000, 0x3839C000, 0x383A0000, 0x383A4000, 0x383A8000, 0x383AC000, 0x383B0000, 0x383B4000, 0x383B8000, 0x383BC000,\n  0x383C0000, 0x383C4000, 0x383C8000, 0x383CC000, 0x383D0000, 0x383D4000, 0x383D8000, 0x383DC000, 0x383E0000, 0x383E4000, 0x383E8000, 0x383EC000, 0x383F0000, 0x383F4000, 0x383F8000, 0x383FC000,\n  0x38400000, 0x38404000, 0x38408000, 0x3840C000, 0x38410000, 0x38414000, 0x38418000, 0x3841C000, 0x38420000, 0x38424000, 0x38428000, 0x3842C000, 0x38430000, 0x38434000, 0x38438000, 0x3843C000,\n  0x38440000, 0x38444000, 0x38448000, 0x3844C000, 0x38450000, 0x38454000, 0x38458000, 0x3845C000, 0x38460000, 0x38464000, 0x38468000, 0x3846C000, 0x38470000, 0x38474000, 0x38478000, 0x3847C000,\n  0x38480000, 0x38484000, 0x38488000, 0x3848C000, 0x38490000, 0x38494000, 0x38498",
            "000, 0x3849C000, 0x384A0000, 0x384A4000, 0x384A8000, 0x384AC000, 0x384B0000, 0x384B4000, 0x384B8000, 0x384BC000,\n  0x384C0000, 0x384C4000, 0x384C8000, 0x384CC000, 0x384D0000, 0x384D4000, 0x384D8000, 0x384DC000, 0x384E0000, 0x384E4000, 0x384E8000, 0x384EC000, 0x384F0000, 0x384F4000, 0x384F8000, 0x384FC000,\n  0x38500000, 0x38504000, 0x38508000, 0x3850C000, 0x38510000, 0x38514000, 0x38518000, 0x3851C000, 0x38520000, 0x38524000, 0x38528000, 0x3852C000, 0x38530000, 0x38534000, 0x38538000, 0x3853C000,\n  0x38540000, 0x38544000, 0x38548000, 0x3854C000, 0x38550000, 0x38554000, 0x38558000, 0x3855C000, 0x38560000, 0x38564000, 0x38568000, 0x3856C000, 0x38570000, 0x38574000, 0x38578000, 0x3857C000,\n  0x38580000, 0x38584000, 0x38588000, 0x3858C000, 0x38590000, 0x38594000, 0x38598000, 0x3859C000, 0x385A0000, 0x385A4000, 0x385A8000, 0x385AC000, 0x385B0000, 0x385B4000, 0x385B8000, 0x385BC000,\n  0x385C0000, 0x385C4000, 0x385C8000, 0x385CC000, 0x385D0000, 0x385D4000, 0x385D8000, 0x385DC000, 0x385E0000, 0x385E4000, 0x385E8000, 0x385EC000, 0x385F0000, 0x385F4000, 0x385F8000, 0x385FC000,\n  0x38600000, 0x38604000, 0x38608000, 0x3860C000, 0x38610000, 0x38614000, 0x38618000, 0x3861C000, 0x38620000, 0x38624000, 0x38628000, 0x3862C000, 0x38630000, 0x38634000, 0x38638000, 0x3863C000,\n  0x38640000, 0x38644000, 0x38648000, 0x3864C000, 0x38650000, 0x38654000, 0x38658000, 0x3865C000, 0x38660000, 0x38664000, 0x38668000, 0x3866C000, 0x38670000, 0x38674000, 0x38678000, 0x3867C000,\n  0x38680000, 0x38684000, 0x38688000, 0x3868C000, 0x38690000, 0x38694000, 0x38698000, 0x3869C000, 0x386A0000, 0x386A4000, 0x386A8000, 0x386AC000, 0x386B0000, 0x386B4000, 0x386B8000, 0x386BC000,\n  0x386C0000, 0x386C4000, 0x386C8000, 0x386CC000, 0x386D0000, 0x386D4000, 0x386D8000, 0x386DC000, 0x386E0000, 0x386E4000, 0x386E8000, 0x386EC000, 0x386F0000, 0x386F4000, 0x386F8000, 0x386FC000,\n  0x38700000, 0x38704000, 0x38708000, 0x3870C000, 0x38710000, 0x38714000, 0x38718000, 0x3871C000, 0x38720000, 0x38724000, 0x38728000, 0x3872C",
            "000, 0x38730000, 0x38734000, 0x38738000, 0x3873C000,\n  0x38740000, 0x38744000, 0x38748000, 0x3874C000, 0x38750000, 0x38754000, 0x38758000, 0x3875C000, 0x38760000, 0x38764000, 0x38768000, 0x3876C000, 0x38770000, 0x38774000, 0x38778000, 0x3877C000,\n  0x38780000, 0x38784000, 0x38788000, 0x3878C000, 0x38790000, 0x38794000, 0x38798000, 0x3879C000, 0x387A0000, 0x387A4000, 0x387A8000, 0x387AC000, 0x387B0000, 0x387B4000, 0x387B8000, 0x387BC000,\n  0x387C0000, 0x387C4000, 0x387C8000, 0x387CC000, 0x387D0000, 0x387D4000, 0x387D8000, 0x387DC000, 0x387E0000, 0x387E4000, 0x387E8000, 0x387EC000, 0x387F0000, 0x387F4000, 0x387F8000, 0x387FC000,\n  0x38000000, 0x38002000, 0x38004000, 0x38006000, 0x38008000, 0x3800A000, 0x3800C000, 0x3800E000, 0x38010000, 0x38012000, 0x38014000, 0x38016000, 0x38018000, 0x3801A000, 0x3801C000, 0x3801E000,\n  0x38020000, 0x38022000, 0x38024000, 0x38026000, 0x38028000, 0x3802A000, 0x3802C000, 0x3802E000, 0x38030000, 0x38032000, 0x38034000, 0x38036000, 0x38038000, 0x3803A000, 0x3803C000, 0x3803E000,\n  0x38040000, 0x38042000, 0x38044000, 0x38046000, 0x38048000, 0x3804A000, 0x3804C000, 0x3804E000, 0x38050000, 0x38052000, 0x38054000, 0x38056000, 0x38058000, 0x3805A000, 0x3805C000, 0x3805E000,\n  0x38060000, 0x38062000, 0x38064000, 0x38066000, 0x38068000, 0x3806A000, 0x3806C000, 0x3806E000, 0x38070000, 0x38072000, 0x38074000, 0x38076000, 0x38078000, 0x3807A000, 0x3807C000, 0x3807E000,\n  0x38080000, 0x38082000, 0x38084000, 0x38086000, 0x38088000, 0x3808A000, 0x3808C000, 0x3808E000, 0x38090000, 0x38092000, 0x38094000, 0x38096000, 0x38098000, 0x3809A000, 0x3809C000, 0x3809E000,\n  0x380A0000, 0x380A2000, 0x380A4000, 0x380A6000, 0x380A8000, 0x380AA000, 0x380AC000, 0x380AE000, 0x380B0000, 0x380B2000, 0x380B4000, 0x380B6000, 0x380B8000, 0x380BA000, 0x380BC000, 0x380BE000,\n  0x380C0000, 0x380C2000, 0x380C4000, 0x380C6000, 0x380C8000, 0x380CA000, 0x380CC000, 0x380CE000, 0x380D0000, 0x380D2000, 0x380D4000, 0x380D6000, 0x380D8000, 0x380DA000, 0x380DC000, 0x380DE000,\n  0x380",
            "E0000, 0x380E2000, 0x380E4000, 0x380E6000, 0x380E8000, 0x380EA000, 0x380EC000, 0x380EE000, 0x380F0000, 0x380F2000, 0x380F4000, 0x380F6000, 0x380F8000, 0x380FA000, 0x380FC000, 0x380FE000,\n  0x38100000, 0x38102000, 0x38104000, 0x38106000, 0x38108000, 0x3810A000, 0x3810C000, 0x3810E000, 0x38110000, 0x38112000, 0x38114000, 0x38116000, 0x38118000, 0x3811A000, 0x3811C000, 0x3811E000,\n  0x38120000, 0x38122000, 0x38124000, 0x38126000, 0x38128000, 0x3812A000, 0x3812C000, 0x3812E000, 0x38130000, 0x38132000, 0x38134000, 0x38136000, 0x38138000, 0x3813A000, 0x3813C000, 0x3813E000,\n  0x38140000, 0x38142000, 0x38144000, 0x38146000, 0x38148000, 0x3814A000, 0x3814C000, 0x3814E000, 0x38150000, 0x38152000, 0x38154000, 0x38156000, 0x38158000, 0x3815A000, 0x3815C000, 0x3815E000,\n  0x38160000, 0x38162000, 0x38164000, 0x38166000, 0x38168000, 0x3816A000, 0x3816C000, 0x3816E000, 0x38170000, 0x38172000, 0x38174000, 0x38176000, 0x38178000, 0x3817A000, 0x3817C000, 0x3817E000,\n  0x38180000, 0x38182000, 0x38184000, 0x38186000, 0x38188000, 0x3818A000, 0x3818C000, 0x3818E000, 0x38190000, 0x38192000, 0x38194000, 0x38196000, 0x38198000, 0x3819A000, 0x3819C000, 0x3819E000,\n  0x381A0000, 0x381A2000, 0x381A4000, 0x381A6000, 0x381A8000, 0x381AA000, 0x381AC000, 0x381AE000, 0x381B0000, 0x381B2000, 0x381B4000, 0x381B6000, 0x381B8000, 0x381BA000, 0x381BC000, 0x381BE000,\n  0x381C0000, 0x381C2000, 0x381C4000, 0x381C6000, 0x381C8000, 0x381CA000, 0x381CC000, 0x381CE000, 0x381D0000, 0x381D2000, 0x381D4000, 0x381D6000, 0x381D8000, 0x381DA000, 0x381DC000, 0x381DE000,\n  0x381E0000, 0x381E2000, 0x381E4000, 0x381E6000, 0x381E8000, 0x381EA000, 0x381EC000, 0x381EE000, 0x381F0000, 0x381F2000, 0x381F4000, 0x381F6000, 0x381F8000, 0x381FA000, 0x381FC000, 0x381FE000,\n  0x38200000, 0x38202000, 0x38204000, 0x38206000, 0x38208000, 0x3820A000, 0x3820C000, 0x3820E000, 0x38210000, 0x38212000, 0x38214000, 0x38216000, 0x38218000, 0x3821A000, 0x3821C000, 0x3821E000,\n  0x38220000, 0x38222000, 0x38224000, 0x38226000, 0x38228000, 0x382",
            "2A000, 0x3822C000, 0x3822E000, 0x38230000, 0x38232000, 0x38234000, 0x38236000, 0x38238000, 0x3823A000, 0x3823C000, 0x3823E000,\n  0x38240000, 0x38242000, 0x38244000, 0x38246000, 0x38248000, 0x3824A000, 0x3824C000, 0x3824E000, 0x38250000, 0x38252000, 0x38254000, 0x38256000, 0x38258000, 0x3825A000, 0x3825C000, 0x3825E000,\n  0x38260000, 0x38262000, 0x38264000, 0x38266000, 0x38268000, 0x3826A000, 0x3826C000, 0x3826E000, 0x38270000, 0x38272000, 0x38274000, 0x38276000, 0x38278000, 0x3827A000, 0x3827C000, 0x3827E000,\n  0x38280000, 0x38282000, 0x38284000, 0x38286000, 0x38288000, 0x3828A000, 0x3828C000, 0x3828E000, 0x38290000, 0x38292000, 0x38294000, 0x38296000, 0x38298000, 0x3829A000, 0x3829C000, 0x3829E000,\n  0x382A0000, 0x382A2000, 0x382A4000, 0x382A6000, 0x382A8000, 0x382AA000, 0x382AC000, 0x382AE000, 0x382B0000, 0x382B2000, 0x382B4000, 0x382B6000, 0x382B8000, 0x382BA000, 0x382BC000, 0x382BE000,\n  0x382C0000, 0x382C2000, 0x382C4000, 0x382C6000, 0x382C8000, 0x382CA000, 0x382CC000, 0x382CE000, 0x382D0000, 0x382D2000, 0x382D4000, 0x382D6000, 0x382D8000, 0x382DA000, 0x382DC000, 0x382DE000,\n  0x382E0000, 0x382E2000, 0x382E4000, 0x382E6000, 0x382E8000, 0x382EA000, 0x382EC000, 0x382EE000, 0x382F0000, 0x382F2000, 0x382F4000, 0x382F6000, 0x382F8000, 0x382FA000, 0x382FC000, 0x382FE000,\n  0x38300000, 0x38302000, 0x38304000, 0x38306000, 0x38308000, 0x3830A000, 0x3830C000, 0x3830E000, 0x38310000, 0x38312000, 0x38314000, 0x38316000, 0x38318000, 0x3831A000, 0x3831C000, 0x3831E000,\n  0x38320000, 0x38322000, 0x38324000, 0x38326000, 0x38328000, 0x3832A000, 0x3832C000, 0x3832E000, 0x38330000, 0x38332000, 0x38334000, 0x38336000, 0x38338000, 0x3833A000, 0x3833C000, 0x3833E000,\n  0x38340000, 0x38342000, 0x38344000, 0x38346000, 0x38348000, 0x3834A000, 0x3834C000, 0x3834E000, 0x38350000, 0x38352000, 0x38354000, 0x38356000, 0x38358000, 0x3835A000, 0x3835C000, 0x3835E000,\n  0x38360000, 0x38362000, 0x38364000, 0x38366000, 0x38368000, 0x3836A000, 0x3836C000, 0x3836E000, 0x38370000, 0x38372000, 0x383",
            "74000, 0x38376000, 0x38378000, 0x3837A000, 0x3837C000, 0x3837E000,\n  0x38380000, 0x38382000, 0x38384000, 0x38386000, 0x38388000, 0x3838A000, 0x3838C000, 0x3838E000, 0x38390000, 0x38392000, 0x38394000, 0x38396000, 0x38398000, 0x3839A000, 0x3839C000, 0x3839E000,\n  0x383A0000, 0x383A2000, 0x383A4000, 0x383A6000, 0x383A8000, 0x383AA000, 0x383AC000, 0x383AE000, 0x383B0000, 0x383B2000, 0x383B4000, 0x383B6000, 0x383B8000, 0x383BA000, 0x383BC000, 0x383BE000,\n  0x383C0000, 0x383C2000, 0x383C4000, 0x383C6000, 0x383C8000, 0x383CA000, 0x383CC000, 0x383CE000, 0x383D0000, 0x383D2000, 0x383D4000, 0x383D6000, 0x383D8000, 0x383DA000, 0x383DC000, 0x383DE000,\n  0x383E0000, 0x383E2000, 0x383E4000, 0x383E6000, 0x383E8000, 0x383EA000, 0x383EC000, 0x383EE000, 0x383F0000, 0x383F2000, 0x383F4000, 0x383F6000, 0x383F8000, 0x383FA000, 0x383FC000, 0x383FE000,\n  0x38400000, 0x38402000, 0x38404000, 0x38406000, 0x38408000, 0x3840A000, 0x3840C000, 0x3840E000, 0x38410000, 0x38412000, 0x38414000, 0x38416000, 0x38418000, 0x3841A000, 0x3841C000, 0x3841E000,\n  0x38420000, 0x38422000, 0x38424000, 0x38426000, 0x38428000, 0x3842A000, 0x3842C000, 0x3842E000, 0x38430000, 0x38432000, 0x38434000, 0x38436000, 0x38438000, 0x3843A000, 0x3843C000, 0x3843E000,\n  0x38440000, 0x38442000, 0x38444000, 0x38446000, 0x38448000, 0x3844A000, 0x3844C000, 0x3844E000, 0x38450000, 0x38452000, 0x38454000, 0x38456000, 0x38458000, 0x3845A000, 0x3845C000, 0x3845E000,\n  0x38460000, 0x38462000, 0x38464000, 0x38466000, 0x38468000, 0x3846A000, 0x3846C000, 0x3846E000, 0x38470000, 0x38472000, 0x38474000, 0x38476000, 0x38478000, 0x3847A000, 0x3847C000, 0x3847E000,\n  0x38480000, 0x38482000, 0x38484000, 0x38486000, 0x38488000, 0x3848A000, 0x3848C000, 0x3848E000, 0x38490000, 0x38492000, 0x38494000, 0x38496000, 0x38498000, 0x3849A000, 0x3849C000, 0x3849E000,\n  0x384A0000, 0x384A2000, 0x384A4000, 0x384A6000, 0x384A8000, 0x384AA000, 0x384AC000, 0x384AE000, 0x384B0000, 0x384B2000, 0x384B4000, 0x384B6000, 0x384B8000, 0x384BA000, 0x384BC000, 0x384",
            "BE000,\n  0x384C0000, 0x384C2000, 0x384C4000, 0x384C6000, 0x384C8000, 0x384CA000, 0x384CC000, 0x384CE000, 0x384D0000, 0x384D2000, 0x384D4000, 0x384D6000, 0x384D8000, 0x384DA000, 0x384DC000, 0x384DE000,\n  0x384E0000, 0x384E2000, 0x384E4000, 0x384E6000, 0x384E8000, 0x384EA000, 0x384EC000, 0x384EE000, 0x384F0000, 0x384F2000, 0x384F4000, 0x384F6000, 0x384F8000, 0x384FA000, 0x384FC000, 0x384FE000,\n  0x38500000, 0x38502000, 0x38504000, 0x38506000, 0x38508000, 0x3850A000, 0x3850C000, 0x3850E000, 0x38510000, 0x38512000, 0x38514000, 0x38516000, 0x38518000, 0x3851A000, 0x3851C000, 0x3851E000,\n  0x38520000, 0x38522000, 0x38524000, 0x38526000, 0x38528000, 0x3852A000, 0x3852C000, 0x3852E000, 0x38530000, 0x38532000, 0x38534000, 0x38536000, 0x38538000, 0x3853A000, 0x3853C000, 0x3853E000,\n  0x38540000, 0x38542000, 0x38544000, 0x38546000, 0x38548000, 0x3854A000, 0x3854C000, 0x3854E000, 0x38550000, 0x38552000, 0x38554000, 0x38556000, 0x38558000, 0x3855A000, 0x3855C000, 0x3855E000,\n  0x38560000, 0x38562000, 0x38564000, 0x38566000, 0x38568000, 0x3856A000, 0x3856C000, 0x3856E000, 0x38570000, 0x38572000, 0x38574000, 0x38576000, 0x38578000, 0x3857A000, 0x3857C000, 0x3857E000,\n  0x38580000, 0x38582000, 0x38584000, 0x38586000, 0x38588000, 0x3858A000, 0x3858C000, 0x3858E000, 0x38590000, 0x38592000, 0x38594000, 0x38596000, 0x38598000, 0x3859A000, 0x3859C000, 0x3859E000,\n  0x385A0000, 0x385A2000, 0x385A4000, 0x385A6000, 0x385A8000, 0x385AA000, 0x385AC000, 0x385AE000, 0x385B0000, 0x385B2000, 0x385B4000, 0x385B6000, 0x385B8000, 0x385BA000, 0x385BC000, 0x385BE000,\n  0x385C0000, 0x385C2000, 0x385C4000, 0x385C6000, 0x385C8000, 0x385CA000, 0x385CC000, 0x385CE000, 0x385D0000, 0x385D2000, 0x385D4000, 0x385D6000, 0x385D8000, 0x385DA000, 0x385DC000, 0x385DE000,\n  0x385E0000, 0x385E2000, 0x385E4000, 0x385E6000, 0x385E8000, 0x385EA000, 0x385EC000, 0x385EE000, 0x385F0000, 0x385F2000, 0x385F4000, 0x385F6000, 0x385F8000, 0x385FA000, 0x385FC000, 0x385FE000,\n  0x38600000, 0x38602000, 0x38604000, 0x38606000, 0x3",
            "8608000, 0x3860A000, 0x3860C000, 0x3860E000, 0x38610000, 0x38612000, 0x38614000, 0x38616000, 0x38618000, 0x3861A000, 0x3861C000, 0x3861E000,\n  0x38620000, 0x38622000, 0x38624000, 0x38626000, 0x38628000, 0x3862A000, 0x3862C000, 0x3862E000, 0x38630000, 0x38632000, 0x38634000, 0x38636000, 0x38638000, 0x3863A000, 0x3863C000, 0x3863E000,\n  0x38640000, 0x38642000, 0x38644000, 0x38646000, 0x38648000, 0x3864A000, 0x3864C000, 0x3864E000, 0x38650000, 0x38652000, 0x38654000, 0x38656000, 0x38658000, 0x3865A000, 0x3865C000, 0x3865E000,\n  0x38660000, 0x38662000, 0x38664000, 0x38666000, 0x38668000, 0x3866A000, 0x3866C000, 0x3866E000, 0x38670000, 0x38672000, 0x38674000, 0x38676000, 0x38678000, 0x3867A000, 0x3867C000, 0x3867E000,\n  0x38680000, 0x38682000, 0x38684000, 0x38686000, 0x38688000, 0x3868A000, 0x3868C000, 0x3868E000, 0x38690000, 0x38692000, 0x38694000, 0x38696000, 0x38698000, 0x3869A000, 0x3869C000, 0x3869E000,\n  0x386A0000, 0x386A2000, 0x386A4000, 0x386A6000, 0x386A8000, 0x386AA000, 0x386AC000, 0x386AE000, 0x386B0000, 0x386B2000, 0x386B4000, 0x386B6000, 0x386B8000, 0x386BA000, 0x386BC000, 0x386BE000,\n  0x386C0000, 0x386C2000, 0x386C4000, 0x386C6000, 0x386C8000, 0x386CA000, 0x386CC000, 0x386CE000, 0x386D0000, 0x386D2000, 0x386D4000, 0x386D6000, 0x386D8000, 0x386DA000, 0x386DC000, 0x386DE000,\n  0x386E0000, 0x386E2000, 0x386E4000, 0x386E6000, 0x386E8000, 0x386EA000, 0x386EC000, 0x386EE000, 0x386F0000, 0x386F2000, 0x386F4000, 0x386F6000, 0x386F8000, 0x386FA000, 0x386FC000, 0x386FE000,\n  0x38700000, 0x38702000, 0x38704000, 0x38706000, 0x38708000, 0x3870A000, 0x3870C000, 0x3870E000, 0x38710000, 0x38712000, 0x38714000, 0x38716000, 0x38718000, 0x3871A000, 0x3871C000, 0x3871E000,\n  0x38720000, 0x38722000, 0x38724000, 0x38726000, 0x38728000, 0x3872A000, 0x3872C000, 0x3872E000, 0x38730000, 0x38732000, 0x38734000, 0x38736000, 0x38738000, 0x3873A000, 0x3873C000, 0x3873E000,\n  0x38740000, 0x38742000, 0x38744000, 0x38746000, 0x38748000, 0x3874A000, 0x3874C000, 0x3874E000, 0x38750000, 0x3",
            "8752000, 0x38754000, 0x38756000, 0x38758000, 0x3875A000, 0x3875C000, 0x3875E000,\n  0x38760000, 0x38762000, 0x38764000, 0x38766000, 0x38768000, 0x3876A000, 0x3876C000, 0x3876E000, 0x38770000, 0x38772000, 0x38774000, 0x38776000, 0x38778000, 0x3877A000, 0x3877C000, 0x3877E000,\n  0x38780000, 0x38782000, 0x38784000, 0x38786000, 0x38788000, 0x3878A000, 0x3878C000, 0x3878E000, 0x38790000, 0x38792000, 0x38794000, 0x38796000, 0x38798000, 0x3879A000, 0x3879C000, 0x3879E000,\n  0x387A0000, 0x387A2000, 0x387A4000, 0x387A6000, 0x387A8000, 0x387AA000, 0x387AC000, 0x387AE000, 0x387B0000, 0x387B2000, 0x387B4000, 0x387B6000, 0x387B8000, 0x387BA000, 0x387BC000, 0x387BE000,\n  0x387C0000, 0x387C2000, 0x387C4000, 0x387C6000, 0x387C8000, 0x387CA000, 0x387CC000, 0x387CE000, 0x387D0000, 0x387D2000, 0x387D4000, 0x387D6000, 0x387D8000, 0x387DA000, 0x387DC000, 0x387DE000,\n  0x387E0000, 0x387E2000, 0x387E4000, 0x387E6000, 0x387E8000, 0x387EA000, 0x387EC000, 0x387EE000, 0x387F0000, 0x387F2000, 0x387F4000, 0x387F6000, 0x387F8000, 0x387FA000, 0x387FC000, 0x387FE000 };\n__constant static const uint32_t exponent_table[64] = {\n  0x00000000, 0x00800000, 0x01000000, 0x01800000, 0x02000000, 0x02800000, 0x03000000, 0x03800000, 0x04000000, 0x04800000, 0x05000000, 0x05800000, 0x06000000, 0x06800000, 0x07000000, 0x07800000,\n  0x08000000, 0x08800000, 0x09000000, 0x09800000, 0x0A000000, 0x0A800000, 0x0B000000, 0x0B800000, 0x0C000000, 0x0C800000, 0x0D000000, 0x0D800000, 0x0E000000, 0x0E800000, 0x0F000000, 0x47800000,\n  0x80000000, 0x80800000, 0x81000000, 0x81800000, 0x82000000, 0x82800000, 0x83000000, 0x83800000, 0x84000000, 0x84800000, 0x85000000, 0x85800000, 0x86000000, 0x86800000, 0x87000000, 0x87800000,\n  0x88000000, 0x88800000, 0x89000000, 0x89800000, 0x8A000000, 0x8A800000, 0x8B000000, 0x8B800000, 0x8C000000, 0x8C800000, 0x8D000000, 0x8D800000, 0x8E000000, 0x8E800000, 0x8F000000, 0xC7800000 };\n__constant static const unsigned short offset_table[64] = {\n  0, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, ",
            "1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024,\n  0, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024 };\n\nstatic uint16_t float2halfbits(float value) {\n  union { float x; uint32_t y; } u;\n  u.x = value;\n  uint32_t bits = u.y;\n\n  uint16_t hbits = base_table[bits>>23] + (uint16_t)((bits&0x7FFFFF)>>shift_table[bits>>23]);;\n\n  return hbits;\n}\n\nstatic float halfbits2float(uint16_t value) {\n  uint32_t bits = mantissa_table[offset_table[value>>10]+(value&0x3FF)] + exponent_table[value>>10];\n\n  union { uint32_t x; float y; } u;\n  u.x = bits;\n  return u.y;\n}\n\n// End of half.h.\n// Start of scalar.h.\n\n// Implementation of the primitive scalar operations.  Very\n// repetitive.  This code is inserted directly into both CUDA and\n// OpenCL programs, as well as the CPU code, so it has some #ifdefs to\n// work everywhere.  Some operations are defined as macros because\n// this allows us to use them as constant expressions in things like\n// array sizes and static initialisers.\n\n// Some of the #ifdefs are because OpenCL uses type-generic functions\n// for some operations (e.g. sqrt), while C and CUDA sensibly use\n// distinct functions for different precisions (e.g. sqrtf() and\n// sqrt()).  This is quite annoying.  Due to C's unfortunate casting\n// rules, it is also really easy to accidentally implement\n// floating-point functions in the wrong precision, so be careful.\n\n// Double-precision definitions are only included if the preprocessor\n// macro FUTHARK_F64_ENABLED is set.\n\nstatic inline uint8_t add8(uint8_t x, uint8_t y) {\n  return x + y;\n}\n\nstatic inline uint16_t add16(uint16_t x, uint16_t y) {\n  return x + y;\n}\n\nstatic inline uint32_t add32(uint32_t x, uint32_t y) {\n  return x + y;\n}\n\nstatic inline uint64_t add64(uint64_t x, uint64_t y) {\n  return x + y;\n}\n\nstati",
            "c inline uint8_t sub8(uint8_t x, uint8_t y) {\n  return x - y;\n}\n\nstatic inline uint16_t sub16(uint16_t x, uint16_t y) {\n  return x - y;\n}\n\nstatic inline uint32_t sub32(uint32_t x, uint32_t y) {\n  return x - y;\n}\n\nstatic inline uint64_t sub64(uint64_t x, uint64_t y) {\n  return x - y;\n}\n\nstatic inline uint8_t mul8(uint8_t x, uint8_t y) {\n  return x * y;\n}\n\nstatic inline uint16_t mul16(uint16_t x, uint16_t y) {\n  return x * y;\n}\n\nstatic inline uint32_t mul32(uint32_t x, uint32_t y) {\n  return x * y;\n}\n\nstatic inline uint64_t mul64(uint64_t x, uint64_t y) {\n  return x * y;\n}\n\nstatic inline uint8_t udiv8(uint8_t x, uint8_t y) {\n  return x / y;\n}\n\nstatic inline uint16_t udiv16(uint16_t x, uint16_t y) {\n  return x / y;\n}\n\nstatic inline uint32_t udiv32(uint32_t x, uint32_t y) {\n  return x / y;\n}\n\nstatic inline uint64_t udiv64(uint64_t x, uint64_t y) {\n  return x / y;\n}\n\nstatic inline uint8_t udiv_up8(uint8_t x, uint8_t y) {\n  return (x + y - 1) / y;\n}\n\nstatic inline uint16_t udiv_up16(uint16_t x, uint16_t y) {\n  return (x + y - 1) / y;\n}\n\nstatic inline uint32_t udiv_up32(uint32_t x, uint32_t y) {\n  return (x + y - 1) / y;\n}\n\nstatic inline uint64_t udiv_up64(uint64_t x, uint64_t y) {\n  return (x + y - 1) / y;\n}\n\nstatic inline uint8_t umod8(uint8_t x, uint8_t y) {\n  return x % y;\n}\n\nstatic inline uint16_t umod16(uint16_t x, uint16_t y) {\n  return x % y;\n}\n\nstatic inline uint32_t umod32(uint32_t x, uint32_t y) {\n  return x % y;\n}\n\nstatic inline uint64_t umod64(uint64_t x, uint64_t y) {\n  return x % y;\n}\n\nstatic inline uint8_t udiv_safe8(uint8_t x, uint8_t y) {\n  return y == 0 ? 0 : x / y;\n}\n\nstatic inline uint16_t udiv_safe16(uint16_t x, uint16_t y) {\n  return y == 0 ? 0 : x / y;\n}\n\nstatic inline uint32_t udiv_safe32(uint32_t x, uint32_t y) {\n  return y == 0 ? 0 : x / y;\n}\n\nstatic inline uint64_t udiv_safe64(uint64_t x, uint64_t y) {\n  return y == 0 ? 0 : x / y;\n}\n\nstatic inline uint8_t udiv_up_safe8(uint8_t x, uint8_t y) {\n  return y == 0 ? 0 : (x + y - 1) / y;\n}\n\nstatic inli",
            "ne uint16_t udiv_up_safe16(uint16_t x, uint16_t y) {\n  return y == 0 ? 0 : (x + y - 1) / y;\n}\n\nstatic inline uint32_t udiv_up_safe32(uint32_t x, uint32_t y) {\n  return y == 0 ? 0 : (x + y - 1) / y;\n}\n\nstatic inline uint64_t udiv_up_safe64(uint64_t x, uint64_t y) {\n  return y == 0 ? 0 : (x + y - 1) / y;\n}\n\nstatic inline uint8_t umod_safe8(uint8_t x, uint8_t y) {\n  return y == 0 ? 0 : x % y;\n}\n\nstatic inline uint16_t umod_safe16(uint16_t x, uint16_t y) {\n  return y == 0 ? 0 : x % y;\n}\n\nstatic inline uint32_t umod_safe32(uint32_t x, uint32_t y) {\n  return y == 0 ? 0 : x % y;\n}\n\nstatic inline uint64_t umod_safe64(uint64_t x, uint64_t y) {\n  return y == 0 ? 0 : x % y;\n}\n\nstatic inline int8_t sdiv8(int8_t x, int8_t y) {\n  int8_t q = x / y;\n  int8_t r = x % y;\n\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nstatic inline int16_t sdiv16(int16_t x, int16_t y) {\n  int16_t q = x / y;\n  int16_t r = x % y;\n\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nstatic inline int32_t sdiv32(int32_t x, int32_t y) {\n  int32_t q = x / y;\n  int32_t r = x % y;\n\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nstatic inline int64_t sdiv64(int64_t x, int64_t y) {\n  int64_t q = x / y;\n  int64_t r = x % y;\n\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nstatic inline int8_t sdiv_up8(int8_t x, int8_t y) {\n  return sdiv8(x + y - 1, y);\n}\n\nstatic inline int16_t sdiv_up16(int16_t x, int16_t y) {\n  return sdiv16(x + y - 1, y);\n}\n\nstatic inline int32_t sdiv_up32(int32_t x, int32_t y) {\n  return sdiv32(x + y - 1, y);\n}\n\nstatic inline int64_t sdiv_up64(int64_t x, int64_t y) {\n  return sdiv64(x + y - 1, y);\n}\n\nstatic inline int8_t smod8(int8_t x, int8_t y) {\n  int8_t r = x % y;\n\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nstatic inline int16_t smod16(int16_t x, int16_t y) {\n  int16_t r = x % y;\n\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nstatic inline int32_t smod32(int32_t x, int32_t y) {\n  int32_t r = x % y;\n\n  return",
            " r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nstatic inline int64_t smod64(int64_t x, int64_t y) {\n  int64_t r = x % y;\n\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nstatic inline int8_t sdiv_safe8(int8_t x, int8_t y) {\n  return y == 0 ? 0 : sdiv8(x, y);\n}\n\nstatic inline int16_t sdiv_safe16(int16_t x, int16_t y) {\n  return y == 0 ? 0 : sdiv16(x, y);\n}\n\nstatic inline int32_t sdiv_safe32(int32_t x, int32_t y) {\n  return y == 0 ? 0 : sdiv32(x, y);\n}\n\nstatic inline int64_t sdiv_safe64(int64_t x, int64_t y) {\n  return y == 0 ? 0 : sdiv64(x, y);\n}\n\nstatic inline int8_t sdiv_up_safe8(int8_t x, int8_t y) {\n  return sdiv_safe8(x + y - 1, y);\n}\n\nstatic inline int16_t sdiv_up_safe16(int16_t x, int16_t y) {\n  return sdiv_safe16(x + y - 1, y);\n}\n\nstatic inline int32_t sdiv_up_safe32(int32_t x, int32_t y) {\n  return sdiv_safe32(x + y - 1, y);\n}\n\nstatic inline int64_t sdiv_up_safe64(int64_t x, int64_t y) {\n  return sdiv_safe64(x + y - 1, y);\n}\n\nstatic inline int8_t smod_safe8(int8_t x, int8_t y) {\n  return y == 0 ? 0 : smod8(x, y);\n}\n\nstatic inline int16_t smod_safe16(int16_t x, int16_t y) {\n  return y == 0 ? 0 : smod16(x, y);\n}\n\nstatic inline int32_t smod_safe32(int32_t x, int32_t y) {\n  return y == 0 ? 0 : smod32(x, y);\n}\n\nstatic inline int64_t smod_safe64(int64_t x, int64_t y) {\n  return y == 0 ? 0 : smod64(x, y);\n}\n\nstatic inline int8_t squot8(int8_t x, int8_t y) {\n  return x / y;\n}\n\nstatic inline int16_t squot16(int16_t x, int16_t y) {\n  return x / y;\n}\n\nstatic inline int32_t squot32(int32_t x, int32_t y) {\n  return x / y;\n}\n\nstatic inline int64_t squot64(int64_t x, int64_t y) {\n  return x / y;\n}\n\nstatic inline int8_t srem8(int8_t x, int8_t y) {\n  return x % y;\n}\n\nstatic inline int16_t srem16(int16_t x, int16_t y) {\n  return x % y;\n}\n\nstatic inline int32_t srem32(int32_t x, int32_t y) {\n  return x % y;\n}\n\nstatic inline int64_t srem64(int64_t x, int64_t y) {\n  return x % y;\n}\n\nstatic inline int8_t squot_safe8(int8_t x, int8_t y)",
            " {\n  return y == 0 ? 0 : x / y;\n}\n\nstatic inline int16_t squot_safe16(int16_t x, int16_t y) {\n  return y == 0 ? 0 : x / y;\n}\n\nstatic inline int32_t squot_safe32(int32_t x, int32_t y) {\n  return y == 0 ? 0 : x / y;\n}\n\nstatic inline int64_t squot_safe64(int64_t x, int64_t y) {\n  return y == 0 ? 0 : x / y;\n}\n\nstatic inline int8_t srem_safe8(int8_t x, int8_t y) {\n  return y == 0 ? 0 : x % y;\n}\n\nstatic inline int16_t srem_safe16(int16_t x, int16_t y) {\n  return y == 0 ? 0 : x % y;\n}\n\nstatic inline int32_t srem_safe32(int32_t x, int32_t y) {\n  return y == 0 ? 0 : x % y;\n}\n\nstatic inline int64_t srem_safe64(int64_t x, int64_t y) {\n  return y == 0 ? 0 : x % y;\n}\n\nstatic inline int8_t smin8(int8_t x, int8_t y) {\n  return x < y ? x : y;\n}\n\nstatic inline int16_t smin16(int16_t x, int16_t y) {\n  return x < y ? x : y;\n}\n\nstatic inline int32_t smin32(int32_t x, int32_t y) {\n  return x < y ? x : y;\n}\n\nstatic inline int64_t smin64(int64_t x, int64_t y) {\n  return x < y ? x : y;\n}\n\nstatic inline uint8_t umin8(uint8_t x, uint8_t y) {\n  return x < y ? x : y;\n}\n\nstatic inline uint16_t umin16(uint16_t x, uint16_t y) {\n  return x < y ? x : y;\n}\n\nstatic inline uint32_t umin32(uint32_t x, uint32_t y) {\n  return x < y ? x : y;\n}\n\nstatic inline uint64_t umin64(uint64_t x, uint64_t y) {\n  return x < y ? x : y;\n}\n\nstatic inline int8_t smax8(int8_t x, int8_t y) {\n  return x < y ? y : x;\n}\n\nstatic inline int16_t smax16(int16_t x, int16_t y) {\n  return x < y ? y : x;\n}\n\nstatic inline int32_t smax32(int32_t x, int32_t y) {\n  return x < y ? y : x;\n}\n\nstatic inline int64_t smax64(int64_t x, int64_t y) {\n  return x < y ? y : x;\n}\n\nstatic inline uint8_t umax8(uint8_t x, uint8_t y) {\n  return x < y ? y : x;\n}\n\nstatic inline uint16_t umax16(uint16_t x, uint16_t y) {\n  return x < y ? y : x;\n}\n\nstatic inline uint32_t umax32(uint32_t x, uint32_t y) {\n  return x < y ? y : x;\n}\n\nstatic inline uint64_t umax64(uint64_t x, uint64_t y) {\n  return x < y ? y : x;\n}\n\nstatic inline uint8_t shl8(uint8_t x, uint8_t y)",
            " {\n  return (uint8_t)(x << y);\n}\n\nstatic inline uint16_t shl16(uint16_t x, uint16_t y) {\n  return (uint16_t)(x << y);\n}\n\nstatic inline uint32_t shl32(uint32_t x, uint32_t y) {\n  return x << y;\n}\n\nstatic inline uint64_t shl64(uint64_t x, uint64_t y) {\n  return x << y;\n}\n\nstatic inline uint8_t lshr8(uint8_t x, uint8_t y) {\n  return x >> y;\n}\n\nstatic inline uint16_t lshr16(uint16_t x, uint16_t y) {\n  return x >> y;\n}\n\nstatic inline uint32_t lshr32(uint32_t x, uint32_t y) {\n  return x >> y;\n}\n\nstatic inline uint64_t lshr64(uint64_t x, uint64_t y) {\n  return x >> y;\n}\n\nstatic inline int8_t ashr8(int8_t x, int8_t y) {\n  return x >> y;\n}\n\nstatic inline int16_t ashr16(int16_t x, int16_t y) {\n  return x >> y;\n}\n\nstatic inline int32_t ashr32(int32_t x, int32_t y) {\n  return x >> y;\n}\n\nstatic inline int64_t ashr64(int64_t x, int64_t y) {\n  return x >> y;\n}\n\nstatic inline uint8_t and8(uint8_t x, uint8_t y) {\n  return x & y;\n}\n\nstatic inline uint16_t and16(uint16_t x, uint16_t y) {\n  return x & y;\n}\n\nstatic inline uint32_t and32(uint32_t x, uint32_t y) {\n  return x & y;\n}\n\nstatic inline uint64_t and64(uint64_t x, uint64_t y) {\n  return x & y;\n}\n\nstatic inline uint8_t or8(uint8_t x, uint8_t y) {\n  return x | y;\n}\n\nstatic inline uint16_t or16(uint16_t x, uint16_t y) {\n  return x | y;\n}\n\nstatic inline uint32_t or32(uint32_t x, uint32_t y) {\n  return x | y;\n}\n\nstatic inline uint64_t or64(uint64_t x, uint64_t y) {\n  return x | y;\n}\n\nstatic inline uint8_t xor8(uint8_t x, uint8_t y) {\n  return x ^ y;\n}\n\nstatic inline uint16_t xor16(uint16_t x, uint16_t y) {\n  return x ^ y;\n}\n\nstatic inline uint32_t xor32(uint32_t x, uint32_t y) {\n  return x ^ y;\n}\n\nstatic inline uint64_t xor64(uint64_t x, uint64_t y) {\n  return x ^ y;\n}\n\nstatic inline bool ult8(uint8_t x, uint8_t y) {\n  return x < y;\n}\n\nstatic inline bool ult16(uint16_t x, uint16_t y) {\n  return x < y;\n}\n\nstatic inline bool ult32(uint32_t x, uint32_t y) {\n  return x < y;\n}\n\nstatic inline bool ult64(uint64_t x, uint64_t y) {\n  return x ",
            "< y;\n}\n\nstatic inline bool ule8(uint8_t x, uint8_t y) {\n  return x <= y;\n}\n\nstatic inline bool ule16(uint16_t x, uint16_t y) {\n  return x <= y;\n}\n\nstatic inline bool ule32(uint32_t x, uint32_t y) {\n  return x <= y;\n}\n\nstatic inline bool ule64(uint64_t x, uint64_t y) {\n  return x <= y;\n}\n\nstatic inline bool slt8(int8_t x, int8_t y) {\n  return x < y;\n}\n\nstatic inline bool slt16(int16_t x, int16_t y) {\n  return x < y;\n}\n\nstatic inline bool slt32(int32_t x, int32_t y) {\n  return x < y;\n}\n\nstatic inline bool slt64(int64_t x, int64_t y) {\n  return x < y;\n}\n\nstatic inline bool sle8(int8_t x, int8_t y) {\n  return x <= y;\n}\n\nstatic inline bool sle16(int16_t x, int16_t y) {\n  return x <= y;\n}\n\nstatic inline bool sle32(int32_t x, int32_t y) {\n  return x <= y;\n}\n\nstatic inline bool sle64(int64_t x, int64_t y) {\n  return x <= y;\n}\n\nstatic inline uint8_t pow8(uint8_t x, uint8_t y) {\n  uint8_t res = 1, rem = y;\n\n  while (rem != 0) {\n    if (rem & 1)\n      res *= x;\n    rem >>= 1;\n    x *= x;\n  }\n  return res;\n}\n\nstatic inline uint16_t pow16(uint16_t x, uint16_t y) {\n  uint16_t res = 1, rem = y;\n\n  while (rem != 0) {\n    if (rem & 1)\n      res *= x;\n    rem >>= 1;\n    x *= x;\n  }\n  return res;\n}\n\nstatic inline uint32_t pow32(uint32_t x, uint32_t y) {\n  uint32_t res = 1, rem = y;\n\n  while (rem != 0) {\n    if (rem & 1)\n      res *= x;\n    rem >>= 1;\n    x *= x;\n  }\n  return res;\n}\n\nstatic inline uint64_t pow64(uint64_t x, uint64_t y) {\n  uint64_t res = 1, rem = y;\n\n  while (rem != 0) {\n    if (rem & 1)\n      res *= x;\n    rem >>= 1;\n    x *= x;\n  }\n  return res;\n}\n\nstatic inline bool itob_i8_bool(int8_t x) {\n  return x;\n}\n\nstatic inline bool itob_i16_bool(int16_t x) {\n  return x;\n}\n\nstatic inline bool itob_i32_bool(int32_t x) {\n  return x;\n}\n\nstatic inline bool itob_i64_bool(int64_t x) {\n  return x;\n}\n\nstatic inline int8_t btoi_bool_i8(bool x) {\n  return x;\n}\n\nstatic inline int16_t btoi_bool_i16(bool x) {\n  return x;\n}\n\nstatic inline int32_t btoi_bool_i32(bool x) {\n  return x;\n}\n\nsta",
            "tic inline int64_t btoi_bool_i64(bool x) {\n  return x;\n}\n\n#define sext_i8_i8(x) ((int8_t) (int8_t) (x))\n#define sext_i8_i16(x) ((int16_t) (int8_t) (x))\n#define sext_i8_i32(x) ((int32_t) (int8_t) (x))\n#define sext_i8_i64(x) ((int64_t) (int8_t) (x))\n#define sext_i16_i8(x) ((int8_t) (int16_t) (x))\n#define sext_i16_i16(x) ((int16_t) (int16_t) (x))\n#define sext_i16_i32(x) ((int32_t) (int16_t) (x))\n#define sext_i16_i64(x) ((int64_t) (int16_t) (x))\n#define sext_i32_i8(x) ((int8_t) (int32_t) (x))\n#define sext_i32_i16(x) ((int16_t) (int32_t) (x))\n#define sext_i32_i32(x) ((int32_t) (int32_t) (x))\n#define sext_i32_i64(x) ((int64_t) (int32_t) (x))\n#define sext_i64_i8(x) ((int8_t) (int64_t) (x))\n#define sext_i64_i16(x) ((int16_t) (int64_t) (x))\n#define sext_i64_i32(x) ((int32_t) (int64_t) (x))\n#define sext_i64_i64(x) ((int64_t) (int64_t) (x))\n#define zext_i8_i8(x) ((int8_t) (uint8_t) (x))\n#define zext_i8_i16(x) ((int16_t) (uint8_t) (x))\n#define zext_i8_i32(x) ((int32_t) (uint8_t) (x))\n#define zext_i8_i64(x) ((int64_t) (uint8_t) (x))\n#define zext_i16_i8(x) ((int8_t) (uint16_t) (x))\n#define zext_i16_i16(x) ((int16_t) (uint16_t) (x))\n#define zext_i16_i32(x) ((int32_t) (uint16_t) (x))\n#define zext_i16_i64(x) ((int64_t) (uint16_t) (x))\n#define zext_i32_i8(x) ((int8_t) (uint32_t) (x))\n#define zext_i32_i16(x) ((int16_t) (uint32_t) (x))\n#define zext_i32_i32(x) ((int32_t) (uint32_t) (x))\n#define zext_i32_i64(x) ((int64_t) (uint32_t) (x))\n#define zext_i64_i8(x) ((int8_t) (uint64_t) (x))\n#define zext_i64_i16(x) ((int16_t) (uint64_t) (x))\n#define zext_i64_i32(x) ((int32_t) (uint64_t) (x))\n#define zext_i64_i64(x) ((int64_t) (uint64_t) (x))\n\nstatic int8_t abs8(int8_t x) {\n  return (int8_t)abs(x);\n}\n\nstatic int16_t abs16(int16_t x) {\n  return (int16_t)abs(x);\n}\n\nstatic int32_t abs32(int32_t x) {\n  return abs(x);\n}\n\nstatic int64_t abs64(int64_t x) {\n#if defined(__OPENCL_VERSION__)\n  return abs(x);\n#else\n  return llabs(x);\n#endif\n}\n\n#if defined(__OPENCL_VERSION__)\nstatic int32_t futrts_popc8(int",
            "8_t x) {\n  return popcount(x);\n}\n\nstatic int32_t futrts_popc16(int16_t x) {\n  return popcount(x);\n}\n\nstatic int32_t futrts_popc32(int32_t x) {\n  return popcount(x);\n}\n\nstatic int32_t futrts_popc64(int64_t x) {\n  return popcount(x);\n}\n#elif defined(__CUDA_ARCH__)\n\nstatic int32_t futrts_popc8(int8_t x) {\n  return __popc(zext_i8_i32(x));\n}\n\nstatic int32_t futrts_popc16(int16_t x) {\n  return __popc(zext_i16_i32(x));\n}\n\nstatic int32_t futrts_popc32(int32_t x) {\n  return __popc(x);\n}\n\nstatic int32_t futrts_popc64(int64_t x) {\n  return __popcll(x);\n}\n\n#else // Not OpenCL or CUDA, but plain C.\n\nstatic int32_t futrts_popc8(uint8_t x) {\n  int c = 0;\n  for (; x; ++c) { x &= x - 1; }\n  return c;\n}\n\nstatic int32_t futrts_popc16(uint16_t x) {\n  int c = 0;\n  for (; x; ++c) { x &= x - 1; }\n  return c;\n}\n\nstatic int32_t futrts_popc32(uint32_t x) {\n  int c = 0;\n  for (; x; ++c) { x &= x - 1; }\n  return c;\n}\n\nstatic int32_t futrts_popc64(uint64_t x) {\n  int c = 0;\n  for (; x; ++c) { x &= x - 1; }\n  return c;\n}\n#endif\n\n#if defined(__OPENCL_VERSION__)\nstatic uint8_t futrts_mul_hi8(uint8_t a, uint8_t b) {\n  return mul_hi(a, b);\n}\n\nstatic uint16_t futrts_mul_hi16(uint16_t a, uint16_t b) {\n  return mul_hi(a, b);\n}\n\nstatic uint32_t futrts_mul_hi32(uint32_t a, uint32_t b) {\n  return mul_hi(a, b);\n}\n\nstatic uint64_t futrts_mul_hi64(uint64_t a, uint64_t b) {\n  return mul_hi(a, b);\n}\n\n#elif defined(__CUDA_ARCH__)\n\nstatic uint8_t futrts_mul_hi8(uint8_t a, uint8_t b) {\n  uint16_t aa = a;\n  uint16_t bb = b;\n\n  return aa * bb >> 8;\n}\n\nstatic uint16_t futrts_mul_hi16(uint16_t a, uint16_t b) {\n  uint32_t aa = a;\n  uint32_t bb = b;\n\n  return aa * bb >> 16;\n}\n\nstatic uint32_t futrts_mul_hi32(uint32_t a, uint32_t b) {\n  return mulhi(a, b);\n}\n\nstatic uint64_t futrts_mul_hi64(uint64_t a, uint64_t b) {\n  return mul64hi(a, b);\n}\n\n#else // Not OpenCL or CUDA, but plain C.\n\nstatic uint8_t futrts_mul_hi8(uint8_t a, uint8_t b) {\n  uint16_t aa = a;\n  uint16_t bb = b;\n\n  return aa * bb >> 8;\n}\n\nstatic uint16_t fu",
            "trts_mul_hi16(uint16_t a, uint16_t b) {\n  uint32_t aa = a;\n  uint32_t bb = b;\n\n  return aa * bb >> 16;\n}\n\nstatic uint32_t futrts_mul_hi32(uint32_t a, uint32_t b) {\n  uint64_t aa = a;\n  uint64_t bb = b;\n\n  return aa * bb >> 32;\n}\n\nstatic uint64_t futrts_mul_hi64(uint64_t a, uint64_t b) {\n  __uint128_t aa = a;\n  __uint128_t bb = b;\n\n  return aa * bb >> 64;\n}\n#endif\n\n#if defined(__OPENCL_VERSION__)\nstatic uint8_t futrts_mad_hi8(uint8_t a, uint8_t b, uint8_t c) {\n  return mad_hi(a, b, c);\n}\n\nstatic uint16_t futrts_mad_hi16(uint16_t a, uint16_t b, uint16_t c) {\n  return mad_hi(a, b, c);\n}\n\nstatic uint32_t futrts_mad_hi32(uint32_t a, uint32_t b, uint32_t c) {\n  return mad_hi(a, b, c);\n}\n\nstatic uint64_t futrts_mad_hi64(uint64_t a, uint64_t b, uint64_t c) {\n  return mad_hi(a, b, c);\n}\n\n#else // Not OpenCL\n\nstatic uint8_t futrts_mad_hi8(uint8_t a, uint8_t b, uint8_t c) {\n  return futrts_mul_hi8(a, b) + c;\n}\n\nstatic uint16_t futrts_mad_hi16(uint16_t a, uint16_t b, uint16_t c) {\n  return futrts_mul_hi16(a, b) + c;\n}\n\nstatic uint32_t futrts_mad_hi32(uint32_t a, uint32_t b, uint32_t c) {\n  return futrts_mul_hi32(a, b) + c;\n}\n\nstatic uint64_t futrts_mad_hi64(uint64_t a, uint64_t b, uint64_t c) {\n  return futrts_mul_hi64(a, b) + c;\n}\n#endif\n\n#if defined(__OPENCL_VERSION__)\nstatic int32_t futrts_clzz8(int8_t x) {\n  return clz(x);\n}\n\nstatic int32_t futrts_clzz16(int16_t x) {\n  return clz(x);\n}\n\nstatic int32_t futrts_clzz32(int32_t x) {\n  return clz(x);\n}\n\nstatic int32_t futrts_clzz64(int64_t x) {\n  return clz(x);\n}\n\n#elif defined(__CUDA_ARCH__)\n\nstatic int32_t futrts_clzz8(int8_t x) {\n  return __clz(zext_i8_i32(x)) - 24;\n}\n\nstatic int32_t futrts_clzz16(int16_t x) {\n  return __clz(zext_i16_i32(x)) - 16;\n}\n\nstatic int32_t futrts_clzz32(int32_t x) {\n  return __clz(x);\n}\n\nstatic int32_t futrts_clzz64(int64_t x) {\n  return __clzll(x);\n}\n\n#else // Not OpenCL or CUDA, but plain C.\n\nstatic int32_t futrts_clzz8(int8_t x) {\n  return x == 0 ? 8 : __builtin_clz((uint32_t)zext_i8_i32(x)) - 24;\n",
            "}\n\nstatic int32_t futrts_clzz16(int16_t x) {\n  return x == 0 ? 16 : __builtin_clz((uint32_t)zext_i16_i32(x)) - 16;\n}\n\nstatic int32_t futrts_clzz32(int32_t x) {\n  return x == 0 ? 32 : __builtin_clz((uint32_t)x);\n}\n\nstatic int32_t futrts_clzz64(int64_t x) {\n  return x == 0 ? 64 : __builtin_clzll((uint64_t)x);\n}\n#endif\n\n#if defined(__OPENCL_VERSION__)\nstatic int32_t futrts_ctzz8(int8_t x) {\n  int i = 0;\n  for (; i < 8 && (x & 1) == 0; i++, x >>= 1)\n    ;\n  return i;\n}\n\nstatic int32_t futrts_ctzz16(int16_t x) {\n  int i = 0;\n  for (; i < 16 && (x & 1) == 0; i++, x >>= 1)\n    ;\n  return i;\n}\n\nstatic int32_t futrts_ctzz32(int32_t x) {\n  int i = 0;\n  for (; i < 32 && (x & 1) == 0; i++, x >>= 1)\n    ;\n  return i;\n}\n\nstatic int32_t futrts_ctzz64(int64_t x) {\n  int i = 0;\n  for (; i < 64 && (x & 1) == 0; i++, x >>= 1)\n    ;\n  return i;\n}\n\n#elif defined(__CUDA_ARCH__)\n\nstatic int32_t futrts_ctzz8(int8_t x) {\n  int y = __ffs(x);\n  return y == 0 ? 8 : y - 1;\n}\n\nstatic int32_t futrts_ctzz16(int16_t x) {\n  int y = __ffs(x);\n  return y == 0 ? 16 : y - 1;\n}\n\nstatic int32_t futrts_ctzz32(int32_t x) {\n  int y = __ffs(x);\n  return y == 0 ? 32 : y - 1;\n}\n\nstatic int32_t futrts_ctzz64(int64_t x) {\n  int y = __ffsll(x);\n  return y == 0 ? 64 : y - 1;\n}\n\n#else // Not OpenCL or CUDA, but plain C.\n\nstatic int32_t futrts_ctzz8(int8_t x) {\n  return x == 0 ? 8 : __builtin_ctz((uint32_t)x);\n}\n\nstatic int32_t futrts_ctzz16(int16_t x) {\n  return x == 0 ? 16 : __builtin_ctz((uint32_t)x);\n}\n\nstatic int32_t futrts_ctzz32(int32_t x) {\n  return x == 0 ? 32 : __builtin_ctz((uint32_t)x);\n}\n\nstatic int32_t futrts_ctzz64(int64_t x) {\n  return x == 0 ? 64 : __builtin_ctzll((uint64_t)x);\n}\n#endif\n\nstatic inline float fdiv32(float x, float y) {\n  return x / y;\n}\n\nstatic inline float fadd32(float x, float y) {\n  return x + y;\n}\n\nstatic inline float fsub32(float x, float y) {\n  return x - y;\n}\n\nstatic inline float fmul32(float x, float y) {\n  return x * y;\n}\n\nstatic inline bool cmplt32(float x, float y) {\n  retur",
            "n x < y;\n}\n\nstatic inline bool cmple32(float x, float y) {\n  return x <= y;\n}\n\nstatic inline float sitofp_i8_f32(int8_t x) {\n  return (float) x;\n}\n\nstatic inline float sitofp_i16_f32(int16_t x) {\n  return (float) x;\n}\n\nstatic inline float sitofp_i32_f32(int32_t x) {\n  return (float) x;\n}\n\nstatic inline float sitofp_i64_f32(int64_t x) {\n  return (float) x;\n}\n\nstatic inline float uitofp_i8_f32(uint8_t x) {\n  return (float) x;\n}\n\nstatic inline float uitofp_i16_f32(uint16_t x) {\n  return (float) x;\n}\n\nstatic inline float uitofp_i32_f32(uint32_t x) {\n  return (float) x;\n}\n\nstatic inline float uitofp_i64_f32(uint64_t x) {\n  return (float) x;\n}\n\nstatic inline int8_t fptosi_f32_i8(float x) {\n  return (int8_t) x;\n}\n\nstatic inline int16_t fptosi_f32_i16(float x) {\n  return (int16_t) x;\n}\n\nstatic inline int32_t fptosi_f32_i32(float x) {\n  return (int32_t) x;\n}\n\nstatic inline int64_t fptosi_f32_i64(float x) {\n  return (int64_t) x;\n}\n\nstatic inline uint8_t fptoui_f32_i8(float x) {\n  return (uint8_t) x;\n}\n\nstatic inline uint16_t fptoui_f32_i16(float x) {\n  return (uint16_t) x;\n}\n\nstatic inline uint32_t fptoui_f32_i32(float x) {\n  return (uint32_t) x;\n}\n\nstatic inline uint64_t fptoui_f32_i64(float x) {\n  return (uint64_t) x;\n}\n\n#ifdef __OPENCL_VERSION__\nstatic inline float fabs32(float x) {\n  return fabs(x);\n}\n\nstatic inline float fmax32(float x, float y) {\n  return fmax(x, y);\n}\n\nstatic inline float fmin32(float x, float y) {\n  return fmin(x, y);\n}\n\nstatic inline float fpow32(float x, float y) {\n  return pow(x, y);\n}\n\n#else // Not OpenCL, but CUDA or plain C.\n\nstatic inline float fabs32(float x) {\n  return fabsf(x);\n}\n\nstatic inline float fmax32(float x, float y) {\n  return fmaxf(x, y);\n}\n\nstatic inline float fmin32(float x, float y) {\n  return fminf(x, y);\n}\n\nstatic inline float fpow32(float x, float y) {\n  return powf(x, y);\n}\n#endif\n\nstatic inline bool futrts_isnan32(float x) {\n  return isnan(x);\n}\n\nstatic inline bool futrts_isinf32(float x) {\n  return isinf(x);\n}\n\n#ifdef __OP",
            "ENCL_VERSION__\nstatic inline float futrts_log32(float x) {\n  return log(x);\n}\n\nstatic inline float futrts_log2_32(float x) {\n  return log2(x);\n}\n\nstatic inline float futrts_log10_32(float x) {\n  return log10(x);\n}\n\nstatic inline float futrts_sqrt32(float x) {\n  return sqrt(x);\n}\n\nstatic inline float futrts_exp32(float x) {\n  return exp(x);\n}\n\nstatic inline float futrts_cos32(float x) {\n  return cos(x);\n}\n\nstatic inline float futrts_sin32(float x) {\n  return sin(x);\n}\n\nstatic inline float futrts_tan32(float x) {\n  return tan(x);\n}\n\nstatic inline float futrts_acos32(float x) {\n  return acos(x);\n}\n\nstatic inline float futrts_asin32(float x) {\n  return asin(x);\n}\n\nstatic inline float futrts_atan32(float x) {\n  return atan(x);\n}\n\nstatic inline float futrts_cosh32(float x) {\n  return cosh(x);\n}\n\nstatic inline float futrts_sinh32(float x) {\n  return sinh(x);\n}\n\nstatic inline float futrts_tanh32(float x) {\n  return tanh(x);\n}\n\nstatic inline float futrts_acosh32(float x) {\n  return acosh(x);\n}\n\nstatic inline float futrts_asinh32(float x) {\n  return asinh(x);\n}\n\nstatic inline float futrts_atanh32(float x) {\n  return atanh(x);\n}\n\nstatic inline float futrts_atan2_32(float x, float y) {\n  return atan2(x, y);\n}\n\nstatic inline float futrts_hypot32(float x, float y) {\n  return hypot(x, y);\n}\n\nstatic inline float futrts_gamma32(float x) {\n  return tgamma(x);\n}\n\nstatic inline float futrts_lgamma32(float x) {\n  return lgamma(x);\n}\n\nstatic inline float fmod32(float x, float y) {\n  return fmod(x, y);\n}\n\nstatic inline float futrts_round32(float x) {\n  return rint(x);\n}\n\nstatic inline float futrts_floor32(float x) {\n  return floor(x);\n}\n\nstatic inline float futrts_ceil32(float x) {\n  return ceil(x);\n}\n\nstatic inline float futrts_lerp32(float v0, float v1, float t) {\n  return mix(v0, v1, t);\n}\n\nstatic inline float futrts_mad32(float a, float b, float c) {\n  return mad(a, b, c);\n}\n\nstatic inline float futrts_fma32(float a, float b, float c) {\n  return fma(a, b, c);\n}\n\n#else // Not OpenCL, b",
            "ut CUDA or plain C.\n\nstatic inline float futrts_log32(float x) {\n  return logf(x);\n}\n\nstatic inline float futrts_log2_32(float x) {\n  return log2f(x);\n}\n\nstatic inline float futrts_log10_32(float x) {\n  return log10f(x);\n}\n\nstatic inline float futrts_sqrt32(float x) {\n  return sqrtf(x);\n}\n\nstatic inline float futrts_exp32(float x) {\n  return expf(x);\n}\n\nstatic inline float futrts_cos32(float x) {\n  return cosf(x);\n}\n\nstatic inline float futrts_sin32(float x) {\n  return sinf(x);\n}\n\nstatic inline float futrts_tan32(float x) {\n  return tanf(x);\n}\n\nstatic inline float futrts_acos32(float x) {\n  return acosf(x);\n}\n\nstatic inline float futrts_asin32(float x) {\n  return asinf(x);\n}\n\nstatic inline float futrts_atan32(float x) {\n  return atanf(x);\n}\n\nstatic inline float futrts_cosh32(float x) {\n  return coshf(x);\n}\n\nstatic inline float futrts_sinh32(float x) {\n  return sinhf(x);\n}\n\nstatic inline float futrts_tanh32(float x) {\n  return tanhf(x);\n}\n\nstatic inline float futrts_acosh32(float x) {\n  return acoshf(x);\n}\n\nstatic inline float futrts_asinh32(float x) {\n  return asinhf(x);\n}\n\nstatic inline float futrts_atanh32(float x) {\n  return atanhf(x);\n}\n\nstatic inline float futrts_atan2_32(float x, float y) {\n  return atan2f(x, y);\n}\n\nstatic inline float futrts_hypot32(float x, float y) {\n  return hypotf(x, y);\n}\n\nstatic inline float futrts_gamma32(float x) {\n  return tgammaf(x);\n}\n\nstatic inline float futrts_lgamma32(float x) {\n  return lgammaf(x);\n}\n\nstatic inline float fmod32(float x, float y) {\n  return fmodf(x, y);\n}\n\nstatic inline float futrts_round32(float x) {\n  return rintf(x);\n}\n\nstatic inline float futrts_floor32(float x) {\n  return floorf(x);\n}\n\nstatic inline float futrts_ceil32(float x) {\n  return ceilf(x);\n}\n\nstatic inline float futrts_lerp32(float v0, float v1, float t) {\n  return v0 + (v1 - v0) * t;\n}\n\nstatic inline float futrts_mad32(float a, float b, float c) {\n  return a * b + c;\n}\n\nstatic inline float futrts_fma32(float a, float b, float c) {\n  return fmaf(a,",
            " b, c);\n}\n#endif\n\nstatic inline int32_t futrts_to_bits32(float x) {\n  union {\n    float f;\n    int32_t t;\n  } p;\n\n  p.f = x;\n  return p.t;\n}\n\nstatic inline float futrts_from_bits32(int32_t x) {\n  union {\n    int32_t f;\n    float t;\n  } p;\n\n  p.f = x;\n  return p.t;\n}\n\nstatic inline float fsignum32(float x) {\n  return futrts_isnan32(x) ? x : (x > 0) - (x < 0);\n}\n\n#ifdef FUTHARK_F64_ENABLED\n\nstatic inline double fdiv64(double x, double y) {\n  return x / y;\n}\n\nstatic inline double fadd64(double x, double y) {\n  return x + y;\n}\n\nstatic inline double fsub64(double x, double y) {\n  return x - y;\n}\n\nstatic inline double fmul64(double x, double y) {\n  return x * y;\n}\n\nstatic inline bool cmplt64(double x, double y) {\n  return x < y;\n}\n\nstatic inline bool cmple64(double x, double y) {\n  return x <= y;\n}\n\nstatic inline double sitofp_i8_f64(int8_t x) {\n  return (double) x;\n}\n\nstatic inline double sitofp_i16_f64(int16_t x) {\n  return (double) x;\n}\n\nstatic inline double sitofp_i32_f64(int32_t x) {\n  return (double) x;\n}\n\nstatic inline double sitofp_i64_f64(int64_t x) {\n  return (double) x;\n}\n\nstatic inline double uitofp_i8_f64(uint8_t x) {\n  return (double) x;\n}\n\nstatic inline double uitofp_i16_f64(uint16_t x) {\n  return (double) x;\n}\n\nstatic inline double uitofp_i32_f64(uint32_t x) {\n  return (double) x;\n}\n\nstatic inline double uitofp_i64_f64(uint64_t x) {\n  return (double) x;\n}\n\nstatic inline int8_t fptosi_f64_i8(double x) {\n  return (int8_t) x;\n}\n\nstatic inline int16_t fptosi_f64_i16(double x) {\n  return (int16_t) x;\n}\n\nstatic inline int32_t fptosi_f64_i32(double x) {\n  return (int32_t) x;\n}\n\nstatic inline int64_t fptosi_f64_i64(double x) {\n  return (int64_t) x;\n}\n\nstatic inline uint8_t fptoui_f64_i8(double x) {\n  return (uint8_t) x;\n}\n\nstatic inline uint16_t fptoui_f64_i16(double x) {\n  return (uint16_t) x;\n}\n\nstatic inline uint32_t fptoui_f64_i32(double x) {\n  return (uint32_t) x;\n}\n\nstatic inline uint64_t fptoui_f64_i64(double x) {\n  return (uint64_t) x;\n}\n\nstatic inline dou",
            "ble fabs64(double x) {\n  return fabs(x);\n}\n\nstatic inline double fmax64(double x, double y) {\n  return fmax(x, y);\n}\n\nstatic inline double fmin64(double x, double y) {\n  return fmin(x, y);\n}\n\nstatic inline double fpow64(double x, double y) {\n  return pow(x, y);\n}\n\nstatic inline double futrts_log64(double x) {\n  return log(x);\n}\n\nstatic inline double futrts_log2_64(double x) {\n  return log2(x);\n}\n\nstatic inline double futrts_log10_64(double x) {\n  return log10(x);\n}\n\nstatic inline double futrts_sqrt64(double x) {\n  return sqrt(x);\n}\n\nstatic inline double futrts_exp64(double x) {\n  return exp(x);\n}\n\nstatic inline double futrts_cos64(double x) {\n  return cos(x);\n}\n\nstatic inline double futrts_sin64(double x) {\n  return sin(x);\n}\n\nstatic inline double futrts_tan64(double x) {\n  return tan(x);\n}\n\nstatic inline double futrts_acos64(double x) {\n  return acos(x);\n}\n\nstatic inline double futrts_asin64(double x) {\n  return asin(x);\n}\n\nstatic inline double futrts_atan64(double x) {\n  return atan(x);\n}\n\nstatic inline double futrts_cosh64(double x) {\n  return cosh(x);\n}\n\nstatic inline double futrts_sinh64(double x) {\n  return sinh(x);\n}\n\nstatic inline double futrts_tanh64(double x) {\n  return tanh(x);\n}\n\nstatic inline double futrts_acosh64(double x) {\n  return acosh(x);\n}\n\nstatic inline double futrts_asinh64(double x) {\n  return asinh(x);\n}\n\nstatic inline double futrts_atanh64(double x) {\n  return atanh(x);\n}\n\nstatic inline double futrts_atan2_64(double x, double y) {\n  return atan2(x, y);\n}\n\nstatic inline double futrts_hypot64(double x, double y) {\n  return hypot(x, y);\n}\n\nstatic inline double futrts_gamma64(double x) {\n  return tgamma(x);\n}\n\nstatic inline double futrts_lgamma64(double x) {\n  return lgamma(x);\n}\n\nstatic inline double futrts_fma64(double a, double b, double c) {\n  return fma(a, b, c);\n}\n\nstatic inline double futrts_round64(double x) {\n  return rint(x);\n}\n\nstatic inline double futrts_ceil64(double x) {\n  return ceil(x);\n}\n\nstatic inline double futrts_floor64(doub",
            "le x) {\n  return floor(x);\n}\n\nstatic inline bool futrts_isnan64(double x) {\n  return isnan(x);\n}\n\nstatic inline bool futrts_isinf64(double x) {\n  return isinf(x);\n}\n\nstatic inline int64_t futrts_to_bits64(double x) {\n  union {\n    double f;\n    int64_t t;\n  } p;\n\n  p.f = x;\n  return p.t;\n}\n\nstatic inline double futrts_from_bits64(int64_t x) {\n  union {\n    int64_t f;\n    double t;\n  } p;\n\n  p.f = x;\n  return p.t;\n}\n\nstatic inline double fmod64(double x, double y) {\n  return fmod(x, y);\n}\n\nstatic inline double fsignum64(double x) {\n  return futrts_isnan64(x) ? x : (x > 0) - (x < 0);\n}\n\nstatic inline double futrts_lerp64(double v0, double v1, double t) {\n#ifdef __OPENCL_VERSION__\n  return mix(v0, v1, t);\n#else\n  return v0 + (v1 - v0) * t;\n#endif\n}\n\nstatic inline double futrts_mad64(double a, double b, double c) {\n#ifdef __OPENCL_VERSION__\n  return mad(a, b, c);\n#else\n  return a * b + c;\n#endif\n}\n\nstatic inline float fpconv_f32_f32(float x) {\n  return (float) x;\n}\n\nstatic inline double fpconv_f32_f64(float x) {\n  return (double) x;\n}\n\nstatic inline float fpconv_f64_f32(double x) {\n  return (float) x;\n}\n\nstatic inline double fpconv_f64_f64(double x) {\n  return (double) x;\n}\n\n#endif\n\n// End of scalar.h.\n// Start of scalar_f16.h.\n\n// Half-precision is emulated if needed (e.g. in straight C) with the\n// native type used if possible.  The emulation works by typedef'ing\n// 'float' to 'f16', and then implementing all operations on single\n// precision.  To cut down on duplication, we use the same code for\n// those Futhark functions that require just operators or casts.  The\n// in-memory representation for arrays will still be 16 bits even\n// under emulation, so the compiler will have to be careful when\n// generating reads or writes.\n\n#if !defined(cl_khr_fp16) && !(defined(__CUDA_ARCH__) && __CUDA_ARCH__ >= 600)\n#define EMULATE_F16\n#endif\n\n#if !defined(EMULATE_F16) && defined(__OPENCL_VERSION__)\n#pragma OPENCL EXTENSION cl_khr_fp16 : enable\n#endif\n\n#ifdef EMULATE_F16\n\n// Note t",
            "hat the half-precision storage format is still 16 bits - the\n// compiler will have to be real careful!\ntypedef float f16;\n\n#else\n\n#ifdef __CUDA_ARCH__\n#include <cuda_fp16.h>\n#endif\n\ntypedef half f16;\n\n#endif\n\n// Some of these functions convert to single precision because half\n// precision versions are not available.\n\nstatic inline f16 fadd16(f16 x, f16 y) {\n  return x + y;\n}\n\nstatic inline f16 fsub16(f16 x, f16 y) {\n  return x - y;\n}\n\nstatic inline f16 fmul16(f16 x, f16 y) {\n  return x * y;\n}\n\nstatic inline bool cmplt16(f16 x, f16 y) {\n  return x < y;\n}\n\nstatic inline bool cmple16(f16 x, f16 y) {\n  return x <= y;\n}\n\nstatic inline f16 sitofp_i8_f16(int8_t x) {\n  return (f16) x;\n}\n\nstatic inline f16 sitofp_i16_f16(int16_t x) {\n  return (f16) x;\n}\n\nstatic inline f16 sitofp_i32_f16(int32_t x) {\n  return (f16) x;\n}\n\nstatic inline f16 sitofp_i64_f16(int64_t x) {\n  return (f16) x;\n}\n\nstatic inline f16 uitofp_i8_f16(uint8_t x) {\n  return (f16) x;\n}\n\nstatic inline f16 uitofp_i16_f16(uint16_t x) {\n  return (f16) x;\n}\n\nstatic inline f16 uitofp_i32_f16(uint32_t x) {\n  return (f16) x;\n}\n\nstatic inline f16 uitofp_i64_f16(uint64_t x) {\n  return (f16) x;\n}\n\nstatic inline int8_t fptosi_f16_i8(f16 x) {\n  return (int8_t) (float) x;\n}\n\nstatic inline int16_t fptosi_f16_i16(f16 x) {\n  return (int16_t) x;\n}\n\nstatic inline int32_t fptosi_f16_i32(f16 x) {\n  return (int32_t) x;\n}\n\nstatic inline int64_t fptosi_f16_i64(f16 x) {\n  return (int64_t) x;\n}\n\nstatic inline uint8_t fptoui_f16_i8(f16 x) {\n  return (uint8_t) (float) x;\n}\n\nstatic inline uint16_t fptoui_f16_i16(f16 x) {\n  return (uint16_t) x;\n}\n\nstatic inline uint32_t fptoui_f16_i32(f16 x) {\n  return (uint32_t) x;\n}\n\nstatic inline uint64_t fptoui_f16_i64(f16 x) {\n  return (uint64_t) x;\n}\n\n#ifndef EMULATE_F16\n\n#ifdef __OPENCL_VERSION__\nstatic inline f16 fabs16(f16 x) {\n  return fabs(x);\n}\n\nstatic inline f16 fmax16(f16 x, f16 y) {\n  return fmax(x, y);\n}\n\nstatic inline f16 fmin16(f16 x, f16 y) {\n  return fmin(x, y);\n}\n\nstatic inline f16 fpow",
            "16(f16 x, f16 y) {\n  return pow(x, y);\n}\n\n#else // Assuming CUDA.\n\nstatic inline f16 fabs16(f16 x) {\n  return fabsf(x);\n}\n\nstatic inline f16 fmax16(f16 x, f16 y) {\n  return fmaxf(x, y);\n}\n\nstatic inline f16 fmin16(f16 x, f16 y) {\n  return fminf(x, y);\n}\n\nstatic inline f16 fpow16(f16 x, f16 y) {\n  return powf(x, y);\n}\n#endif\n\nstatic inline bool futrts_isnan16(f16 x) {\n  return isnan((float)x);\n}\n\nstatic inline bool futrts_isinf16(f16 x) {\n  return isinf((float)x);\n}\n\n#ifdef __OPENCL_VERSION__\nstatic inline f16 futrts_log16(f16 x) {\n  return log(x);\n}\n\nstatic inline f16 futrts_log2_16(f16 x) {\n  return log2(x);\n}\n\nstatic inline f16 futrts_log10_16(f16 x) {\n  return log10(x);\n}\n\nstatic inline f16 futrts_sqrt16(f16 x) {\n  return sqrt(x);\n}\n\nstatic inline f16 futrts_exp16(f16 x) {\n  return exp(x);\n}\n\nstatic inline f16 futrts_cos16(f16 x) {\n  return cos(x);\n}\n\nstatic inline f16 futrts_sin16(f16 x) {\n  return sin(x);\n}\n\nstatic inline f16 futrts_tan16(f16 x) {\n  return tan(x);\n}\n\nstatic inline f16 futrts_acos16(f16 x) {\n  return acos(x);\n}\n\nstatic inline f16 futrts_asin16(f16 x) {\n  return asin(x);\n}\n\nstatic inline f16 futrts_atan16(f16 x) {\n  return atan(x);\n}\n\nstatic inline f16 futrts_cosh16(f16 x) {\n  return cosh(x);\n}\n\nstatic inline f16 futrts_sinh16(f16 x) {\n  return sinh(x);\n}\n\nstatic inline f16 futrts_tanh16(f16 x) {\n  return tanh(x);\n}\n\nstatic inline f16 futrts_acosh16(f16 x) {\n  return acosh(x);\n}\n\nstatic inline f16 futrts_asinh16(f16 x) {\n  return asinh(x);\n}\n\nstatic inline f16 futrts_atanh16(f16 x) {\n  return atanh(x);\n}\n\nstatic inline f16 futrts_atan2_16(f16 x, f16 y) {\n  return atan2(x, y);\n}\n\nstatic inline f16 futrts_hypot16(f16 x, f16 y) {\n  return hypot(x, y);\n}\n\nstatic inline f16 futrts_gamma16(f16 x) {\n  return tgamma(x);\n}\n\nstatic inline f16 futrts_lgamma16(f16 x) {\n  return lgamma(x);\n}\n\nstatic inline f16 fmod16(f16 x, f16 y) {\n  return fmod(x, y);\n}\n\nstatic inline f16 futrts_round16(f16 x) {\n  return rint(x);\n}\n\nstatic inline f16 futrts_floor16(f16 x) {",
            "\n  return floor(x);\n}\n\nstatic inline f16 futrts_ceil16(f16 x) {\n  return ceil(x);\n}\n\nstatic inline f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {\n  return mix(v0, v1, t);\n}\n\nstatic inline f16 futrts_mad16(f16 a, f16 b, f16 c) {\n  return mad(a, b, c);\n}\n\nstatic inline f16 futrts_fma16(f16 a, f16 b, f16 c) {\n  return fma(a, b, c);\n}\n\n#else // Assume CUDA.\n\nstatic inline f16 futrts_log16(f16 x) {\n  return hlog(x);\n}\n\nstatic inline f16 futrts_log2_16(f16 x) {\n  return hlog2(x);\n}\n\nstatic inline f16 futrts_log10_16(f16 x) {\n  return hlog10(x);\n}\n\nstatic inline f16 futrts_sqrt16(f16 x) {\n  return hsqrt(x);\n}\n\nstatic inline f16 futrts_exp16(f16 x) {\n  return hexp(x);\n}\n\nstatic inline f16 futrts_cos16(f16 x) {\n  return hcos(x);\n}\n\nstatic inline f16 futrts_sin16(f16 x) {\n  return hsin(x);\n}\n\nstatic inline f16 futrts_tan16(f16 x) {\n  return tanf(x);\n}\n\nstatic inline f16 futrts_acos16(f16 x) {\n  return acosf(x);\n}\n\nstatic inline f16 futrts_asin16(f16 x) {\n  return asinf(x);\n}\n\nstatic inline f16 futrts_atan16(f16 x) {\n  return atanf(x);\n}\n\nstatic inline f16 futrts_cosh16(f16 x) {\n  return coshf(x);\n}\n\nstatic inline f16 futrts_sinh16(f16 x) {\n  return sinhf(x);\n}\n\nstatic inline f16 futrts_tanh16(f16 x) {\n  return tanhf(x);\n}\n\nstatic inline f16 futrts_acosh16(f16 x) {\n  return acoshf(x);\n}\n\nstatic inline f16 futrts_asinh16(f16 x) {\n  return asinhf(x);\n}\n\nstatic inline f16 futrts_atanh16(f16 x) {\n  return atanhf(x);\n}\n\nstatic inline f16 futrts_atan2_16(f16 x, f16 y) {\n  return atan2f(x, y);\n}\n\nstatic inline f16 futrts_hypot16(f16 x, f16 y) {\n  return hypotf(x, y);\n}\n\nstatic inline f16 futrts_gamma16(f16 x) {\n  return tgammaf(x);\n}\n\nstatic inline f16 futrts_lgamma16(f16 x) {\n  return lgammaf(x);\n}\n\nstatic inline f16 fmod16(f16 x, f16 y) {\n  return fmodf(x, y);\n}\n\nstatic inline f16 futrts_round16(f16 x) {\n  return rintf(x);\n}\n\nstatic inline f16 futrts_floor16(f16 x) {\n  return hfloor(x);\n}\n\nstatic inline f16 futrts_ceil16(f16 x) {\n  return hceil(x);\n}\n\nstatic inline f16 futrts_lerp16(f1",
            "6 v0, f16 v1, f16 t) {\n  return v0 + (v1 - v0) * t;\n}\n\nstatic inline f16 futrts_mad16(f16 a, f16 b, f16 c) {\n  return a * b + c;\n}\n\nstatic inline f16 futrts_fma16(f16 a, f16 b, f16 c) {\n  return fmaf(a, b, c);\n}\n\n#endif\n\n// The CUDA __half type cannot be put in unions for some reason, so we\n// use bespoke conversion functions instead.\n#ifdef __CUDA_ARCH__\nstatic inline int16_t futrts_to_bits16(f16 x) {\n  return __half_as_ushort(x);\n}\nstatic inline f16 futrts_from_bits16(int16_t x) {\n  return __ushort_as_half(x);\n}\n#else\nstatic inline int16_t futrts_to_bits16(f16 x) {\n  union {\n    f16 f;\n    int16_t t;\n  } p;\n\n  p.f = x;\n  return p.t;\n}\n\nstatic inline f16 futrts_from_bits16(int16_t x) {\n  union {\n    int16_t f;\n    f16 t;\n  } p;\n\n  p.f = x;\n  return p.t;\n}\n#endif\n\n#else // No native f16 - emulate.\n\nstatic inline f16 fabs16(f16 x) {\n  return fabs32(x);\n}\n\nstatic inline f16 fmax16(f16 x, f16 y) {\n  return fmax32(x, y);\n}\n\nstatic inline f16 fmin16(f16 x, f16 y) {\n  return fmin32(x, y);\n}\n\nstatic inline f16 fpow16(f16 x, f16 y) {\n  return fpow32(x, y);\n}\n\nstatic inline bool futrts_isnan16(f16 x) {\n  return futrts_isnan32(x);\n}\n\nstatic inline bool futrts_isinf16(f16 x) {\n  return futrts_isinf32(x);\n}\n\nstatic inline f16 futrts_log16(f16 x) {\n  return futrts_log32(x);\n}\n\nstatic inline f16 futrts_log2_16(f16 x) {\n  return futrts_log2_32(x);\n}\n\nstatic inline f16 futrts_log10_16(f16 x) {\n  return futrts_log10_32(x);\n}\n\nstatic inline f16 futrts_sqrt16(f16 x) {\n  return futrts_sqrt32(x);\n}\n\nstatic inline f16 futrts_exp16(f16 x) {\n  return futrts_exp32(x);\n}\n\nstatic inline f16 futrts_cos16(f16 x) {\n  return futrts_cos32(x);\n}\n\nstatic inline f16 futrts_sin16(f16 x) {\n  return futrts_sin32(x);\n}\n\nstatic inline f16 futrts_tan16(f16 x) {\n  return futrts_tan32(x);\n}\n\nstatic inline f16 futrts_acos16(f16 x) {\n  return futrts_acos32(x);\n}\n\nstatic inline f16 futrts_asin16(f16 x) {\n  return futrts_asin32(x);\n}\n\nstatic inline f16 futrts_atan16(f16 x) {\n  return futrts_atan32(x);\n}\n\nstatic ",
            "inline f16 futrts_cosh16(f16 x) {\n  return futrts_cosh32(x);\n}\n\nstatic inline f16 futrts_sinh16(f16 x) {\n  return futrts_sinh32(x);\n}\n\nstatic inline f16 futrts_tanh16(f16 x) {\n  return futrts_tanh32(x);\n}\n\nstatic inline f16 futrts_acosh16(f16 x) {\n  return futrts_acosh32(x);\n}\n\nstatic inline f16 futrts_asinh16(f16 x) {\n  return futrts_asinh32(x);\n}\n\nstatic inline f16 futrts_atanh16(f16 x) {\n  return futrts_atanh32(x);\n}\n\nstatic inline f16 futrts_atan2_16(f16 x, f16 y) {\n  return futrts_atan2_32(x, y);\n}\n\nstatic inline f16 futrts_hypot16(f16 x, f16 y) {\n  return futrts_hypot32(x, y);\n}\n\nstatic inline f16 futrts_gamma16(f16 x) {\n  return futrts_gamma32(x);\n}\n\nstatic inline f16 futrts_lgamma16(f16 x) {\n  return futrts_lgamma32(x);\n}\n\nstatic inline f16 fmod16(f16 x, f16 y) {\n  return fmod32(x, y);\n}\n\nstatic inline f16 futrts_round16(f16 x) {\n  return futrts_round32(x);\n}\n\nstatic inline f16 futrts_floor16(f16 x) {\n  return futrts_floor32(x);\n}\n\nstatic inline f16 futrts_ceil16(f16 x) {\n  return futrts_ceil32(x);\n}\n\nstatic inline f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {\n  return futrts_lerp32(v0, v1, t);\n}\n\nstatic inline f16 futrts_mad16(f16 a, f16 b, f16 c) {\n  return futrts_mad32(a, b, c);\n}\n\nstatic inline f16 futrts_fma16(f16 a, f16 b, f16 c) {\n  return futrts_fma32(a, b, c);\n}\n\n// Even when we are using an OpenCL that does not support cl_khr_fp16,\n// it must still support vload_half for actually creating a\n// half-precision number, which can then be efficiently converted to a\n// float.  Similarly for vstore_half.\n#ifdef __OPENCL_VERSION__\n\nstatic inline int16_t futrts_to_bits16(f16 x) {\n  int16_t y;\n  // Violating strict aliasing here.\n  vstore_half((float)x, 0, (half*)&y);\n  return y;\n}\n\nstatic inline f16 futrts_from_bits16(int16_t x) {\n  return (f16)vload_half(0, (half*)&x);\n}\n\n#else\n\nstatic inline int16_t futrts_to_bits16(f16 x) {\n  return (int16_t)float2halfbits(x);\n}\n\nstatic inline f16 futrts_from_bits16(int16_t x) {\n  return halfbits2float((uint16_t)x);\n}\n\nstat",
            "ic inline f16 fsignum16(f16 x) {\n  return futrts_isnan16(x) ? x : (x > 0) - (x < 0);\n}\n\n#endif\n\n#endif\n\nstatic inline float fpconv_f16_f16(f16 x) {\n  return x;\n}\n\nstatic inline float fpconv_f16_f32(f16 x) {\n  return x;\n}\n\nstatic inline f16 fpconv_f32_f16(float x) {\n  return x;\n}\n\n#ifdef FUTHARK_F64_ENABLED\n\nstatic inline double fpconv_f16_f64(f16 x) {\n  return (double) x;\n}\n\nstatic inline f16 fpconv_f64_f16(double x) {\n  return (f16) x;\n}\n\n#endif\n\n\n// End of scalar_f16.h.\n// Start of atomics.h\n\ninline int32_t atomic_xchg_i32_global(volatile __global int32_t *p, int32_t x) {\n#ifdef FUTHARK_CUDA\n  return atomicExch((int32_t*)p, x);\n#else\n  return atomic_xor(p, x);\n#endif\n}\n\ninline int32_t atomic_xchg_i32_local(volatile __local int32_t *p, int32_t x) {\n#ifdef FUTHARK_CUDA\n  return atomicExch((int32_t*)p, x);\n#else\n  return atomic_xor(p, x);\n#endif\n}\n\ninline int32_t atomic_cmpxchg_i32_global(volatile __global int32_t *p,\n                                         int32_t cmp, int32_t val) {\n#ifdef FUTHARK_CUDA\n  return atomicCAS((int32_t*)p, cmp, val);\n#else\n  return atomic_cmpxchg(p, cmp, val);\n#endif\n}\n\ninline int32_t atomic_cmpxchg_i32_local(volatile __local int32_t *p,\n                                        int32_t cmp, int32_t val) {\n#ifdef FUTHARK_CUDA\n  return atomicCAS((int32_t*)p, cmp, val);\n#else\n  return atomic_cmpxchg(p, cmp, val);\n#endif\n}\n\ninline int32_t atomic_add_i32_global(volatile __global int32_t *p, int32_t x) {\n#ifdef FUTHARK_CUDA\n  return atomicAdd((int32_t*)p, x);\n#else\n  return atomic_add(p, x);\n#endif\n}\n\ninline int32_t atomic_add_i32_local(volatile __local int32_t *p, int32_t x) {\n#ifdef FUTHARK_CUDA\n  return atomicAdd((int32_t*)p, x);\n#else\n  return atomic_add(p, x);\n#endif\n}\n\ninline float atomic_fadd_f32_global(volatile __global float *p, float x) {\n#ifdef FUTHARK_CUDA\n  return atomicAdd((float*)p, x);\n#else\n  union { int32_t i; float f; } old;\n  union { int32_t i; float f; } assumed;\n  old.f = *p;\n  do {\n    assumed.f = old.f;\n    old.f = old.",
            "f + x;\n    old.i = atomic_cmpxchg_i32_global((volatile __global int32_t*)p, assumed.i, old.i);\n  } while (assumed.i != old.i);\n  return old.f;\n#endif\n}\n\ninline float atomic_fadd_f32_local(volatile __local float *p, float x) {\n#ifdef FUTHARK_CUDA\n  return atomicAdd((float*)p, x);\n#else\n  union { int32_t i; float f; } old;\n  union { int32_t i; float f; } assumed;\n  old.f = *p;\n  do {\n    assumed.f = old.f;\n    old.f = old.f + x;\n    old.i = atomic_cmpxchg_i32_local((volatile __local int32_t*)p, assumed.i, old.i);\n  } while (assumed.i != old.i);\n  return old.f;\n#endif\n}\n\ninline int32_t atomic_smax_i32_global(volatile __global int32_t *p, int32_t x) {\n#ifdef FUTHARK_CUDA\n  return atomicMax((int32_t*)p, x);\n#else\n  return atomic_max(p, x);\n#endif\n}\n\ninline int32_t atomic_smax_i32_local(volatile __local int32_t *p, int32_t x) {\n#ifdef FUTHARK_CUDA\n  return atomicMax((int32_t*)p, x);\n#else\n  return atomic_max(p, x);\n#endif\n}\n\ninline int32_t atomic_smin_i32_global(volatile __global int32_t *p, int32_t x) {\n#ifdef FUTHARK_CUDA\n  return atomicMin((int32_t*)p, x);\n#else\n  return atomic_min(p, x);\n#endif\n}\n\ninline int32_t atomic_smin_i32_local(volatile __local int32_t *p, int32_t x) {\n#ifdef FUTHARK_CUDA\n  return atomicMin((int32_t*)p, x);\n#else\n  return atomic_min(p, x);\n#endif\n}\n\ninline uint32_t atomic_umax_i32_global(volatile __global uint32_t *p, uint32_t x) {\n#ifdef FUTHARK_CUDA\n  return atomicMax((uint32_t*)p, x);\n#else\n  return atomic_max(p, x);\n#endif\n}\n\ninline uint32_t atomic_umax_i32_local(volatile __local uint32_t *p, uint32_t x) {\n#ifdef FUTHARK_CUDA\n  return atomicMax((uint32_t*)p, x);\n#else\n  return atomic_max(p, x);\n#endif\n}\n\ninline uint32_t atomic_umin_i32_global(volatile __global uint32_t *p, uint32_t x) {\n#ifdef FUTHARK_CUDA\n  return atomicMin((uint32_t*)p, x);\n#else\n  return atomic_min(p, x);\n#endif\n}\n\ninline uint32_t atomic_umin_i32_local(volatile __local uint32_t *p, uint32_t x) {\n#ifdef FUTHARK_CUDA\n  return atomicMin((uint32_t*)p, x);\n#else\n  return atomi",
            "c_min(p, x);\n#endif\n}\n\ninline int32_t atomic_and_i32_global(volatile __global int32_t *p, int32_t x) {\n#ifdef FUTHARK_CUDA\n  return atomicAnd((int32_t*)p, x);\n#else\n  return atomic_and(p, x);\n#endif\n}\n\ninline int32_t atomic_and_i32_local(volatile __local int32_t *p, int32_t x) {\n#ifdef FUTHARK_CUDA\n  return atomicAnd((int32_t*)p, x);\n#else\n  return atomic_and(p, x);\n#endif\n}\n\ninline int32_t atomic_or_i32_global(volatile __global int32_t *p, int32_t x) {\n#ifdef FUTHARK_CUDA\n  return atomicOr((int32_t*)p, x);\n#else\n  return atomic_or(p, x);\n#endif\n}\n\ninline int32_t atomic_or_i32_local(volatile __local int32_t *p, int32_t x) {\n#ifdef FUTHARK_CUDA\n  return atomicOr((int32_t*)p, x);\n#else\n  return atomic_or(p, x);\n#endif\n}\n\ninline int32_t atomic_xor_i32_global(volatile __global int32_t *p, int32_t x) {\n#ifdef FUTHARK_CUDA\n  return atomicXor((int32_t*)p, x);\n#else\n  return atomic_xor(p, x);\n#endif\n}\n\ninline int32_t atomic_xor_i32_local(volatile __local int32_t *p, int32_t x) {\n#ifdef FUTHARK_CUDA\n  return atomicXor((int32_t*)p, x);\n#else\n  return atomic_xor(p, x);\n#endif\n}\n\n// Start of 64 bit atomics\n\ninline int64_t atomic_xchg_i64_global(volatile __global int64_t *p, int64_t x) {\n#ifdef FUTHARK_CUDA\n  return atomicExch((uint64_t*)p, x);\n#else\n  return atom_xor(p, x);\n#endif\n}\n\ninline int64_t atomic_xchg_i64_local(volatile __local int64_t *p, int64_t x) {\n#ifdef FUTHARK_CUDA\n  return atomicExch((uint64_t*)p, x);\n#else\n  return atom_xor(p, x);\n#endif\n}\n\ninline int64_t atomic_cmpxchg_i64_global(volatile __global int64_t *p,\n                                         int64_t cmp, int64_t val) {\n#ifdef FUTHARK_CUDA\n  return atomicCAS((uint64_t*)p, cmp, val);\n#else\n  return atom_cmpxchg(p, cmp, val);\n#endif\n}\n\ninline int64_t atomic_cmpxchg_i64_local(volatile __local int64_t *p,\n                                        int64_t cmp, int64_t val) {\n#ifdef FUTHARK_CUDA\n  return atomicCAS((uint64_t*)p, cmp, val);\n#else\n  return atom_cmpxchg(p, cmp, val);\n#endif\n}\n\ninline int64_t atomi",
            "c_add_i64_global(volatile __global int64_t *p, int64_t x) {\n#ifdef FUTHARK_CUDA\n  return atomicAdd((uint64_t*)p, x);\n#else\n  return atom_add(p, x);\n#endif\n}\n\ninline int64_t atomic_add_i64_local(volatile __local int64_t *p, int64_t x) {\n#ifdef FUTHARK_CUDA\n  return atomicAdd((uint64_t*)p, x);\n#else\n  return atom_add(p, x);\n#endif\n}\n\n#ifdef FUTHARK_F64_ENABLED\n\ninline double atomic_fadd_f64_global(volatile __global double *p, double x) {\n#if defined(FUTHARK_CUDA) && __CUDA_ARCH__ >= 600\n  return atomicAdd((double*)p, x);\n#else\n  union { int64_t i; double f; } old;\n  union { int64_t i; double f; } assumed;\n  old.f = *p;\n  do {\n    assumed.f = old.f;\n    old.f = old.f + x;\n    old.i = atomic_cmpxchg_i64_global((volatile __global int64_t*)p, assumed.i, old.i);\n  } while (assumed.i != old.i);\n  return old.f;\n#endif\n}\n\ninline double atomic_fadd_f64_local(volatile __local double *p, double x) {\n#if defined(FUTHARK_CUDA) && __CUDA_ARCH__ >= 600\n  return atomicAdd((double*)p, x);\n#else\n  union { int64_t i; double f; } old;\n  union { int64_t i; double f; } assumed;\n  old.f = *p;\n  do {\n    assumed.f = old.f;\n    old.f = old.f + x;\n    old.i = atomic_cmpxchg_i64_local((volatile __local int64_t*)p, assumed.i, old.i);\n  } while (assumed.i != old.i);\n  return old.f;\n#endif\n}\n\n#endif\n\ninline int64_t atomic_smax_i64_global(volatile __global int64_t *p, int64_t x) {\n#ifdef FUTHARK_CUDA\n  return atomicMax((int64_t*)p, x);\n#else\n  return atom_max(p, x);\n#endif\n}\n\ninline int64_t atomic_smax_i64_local(volatile __local int64_t *p, int64_t x) {\n#ifdef FUTHARK_CUDA\n  return atomicMax((int64_t*)p, x);\n#else\n  return atom_max(p, x);\n#endif\n}\n\ninline int64_t atomic_smin_i64_global(volatile __global int64_t *p, int64_t x) {\n#ifdef FUTHARK_CUDA\n  return atomicMin((int64_t*)p, x);\n#else\n  return atom_min(p, x);\n#endif\n}\n\ninline int64_t atomic_smin_i64_local(volatile __local int64_t *p, int64_t x) {\n#ifdef FUTHARK_CUDA\n  return atomicMin((int64_t*)p, x);\n#else\n  return atom_min(p, x);\n#endif\n}\n\nin",
            "line uint64_t atomic_umax_i64_global(volatile __global uint64_t *p, uint64_t x) {\n#ifdef FUTHARK_CUDA\n  return atomicMax((uint64_t*)p, x);\n#else\n  return atom_max(p, x);\n#endif\n}\n\ninline uint64_t atomic_umax_i64_local(volatile __local uint64_t *p, uint64_t x) {\n#ifdef FUTHARK_CUDA\n  return atomicMax((uint64_t*)p, x);\n#else\n  return atom_max(p, x);\n#endif\n}\n\ninline uint64_t atomic_umin_i64_global(volatile __global uint64_t *p, uint64_t x) {\n#ifdef FUTHARK_CUDA\n  return atomicMin((uint64_t*)p, x);\n#else\n  return atom_min(p, x);\n#endif\n}\n\ninline uint64_t atomic_umin_i64_local(volatile __local uint64_t *p, uint64_t x) {\n#ifdef FUTHARK_CUDA\n  return atomicMin((uint64_t*)p, x);\n#else\n  return atom_min(p, x);\n#endif\n}\n\ninline int64_t atomic_and_i64_global(volatile __global int64_t *p, int64_t x) {\n#ifdef FUTHARK_CUDA\n  return atomicAnd((int64_t*)p, x);\n#else\n  return atom_and(p, x);\n#endif\n}\n\ninline int64_t atomic_and_i64_local(volatile __local int64_t *p, int64_t x) {\n#ifdef FUTHARK_CUDA\n  return atomicAnd((int64_t*)p, x);\n#else\n  return atom_and(p, x);\n#endif\n}\n\ninline int64_t atomic_or_i64_global(volatile __global int64_t *p, int64_t x) {\n#ifdef FUTHARK_CUDA\n  return atomicOr((int64_t*)p, x);\n#else\n  return atom_or(p, x);\n#endif\n}\n\ninline int64_t atomic_or_i64_local(volatile __local int64_t *p, int64_t x) {\n#ifdef FUTHARK_CUDA\n  return atomicOr((int64_t*)p, x);\n#else\n  return atom_or(p, x);\n#endif\n}\n\ninline int64_t atomic_xor_i64_global(volatile __global int64_t *p, int64_t x) {\n#ifdef FUTHARK_CUDA\n  return atomicXor((int64_t*)p, x);\n#else\n  return atom_xor(p, x);\n#endif\n}\n\ninline int64_t atomic_xor_i64_local(volatile __local int64_t *p, int64_t x) {\n#ifdef FUTHARK_CUDA\n  return atomicXor((int64_t*)p, x);\n#else\n  return atom_xor(p, x);\n#endif\n}\n\n// End of atomics.h\n\n\n\n__kernel void bicubicInterpolationImagezisegmap_16062(__global\n                                                      int *global_failure,\n                                                      int64_t n_145",
            "07,\n                                                      int64_t newSizzeY_14508,\n                                                      float ratioy_14519,\n                                                      __global\n                                                      unsigned char *mem_16729)\n{\n    #define segmap_group_sizze_16057 (bicubicInterpolationImagezisegmap_group_sizze_15770)\n    \n    const int block_dim0 = 0;\n    const int block_dim1 = 1;\n    const int block_dim2 = 2;\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t global_tid_16832;\n    int32_t local_tid_16833;\n    int64_t group_sizze_16836;\n    int32_t wave_sizze_16835;\n    int32_t group_tid_16834;\n    \n    global_tid_16832 = get_global_id(0);\n    local_tid_16833 = get_local_id(0);\n    group_sizze_16836 = get_local_size(0);\n    wave_sizze_16835 = LOCKSTEP_WIDTH;\n    group_tid_16834 = get_group_id(0);\n    \n    int32_t phys_tid_16062 = global_tid_16832;\n    int64_t global_tid_16837 = sext_i32_i64(group_tid_16834) *\n            segmap_group_sizze_16057 + sext_i32_i64(local_tid_16833);\n    int64_t slice_16838 = newSizzeY_14508;\n    int64_t slice_16839 = n_14507 * slice_16838;\n    int64_t gtid_16060 = squot64(global_tid_16837, slice_16838);\n    int64_t remnant_16840 = global_tid_16837 - gtid_16060 * slice_16838;\n    int64_t gtid_16061 = remnant_16840;\n    int64_t remnant_16841 = remnant_16840 - gtid_16061;\n    \n    if (slt64(gtid_16060, n_14507) && slt64(gtid_16061, newSizzeY_14508)) {\n        float i64_res_16064 = sitofp_i64_f32(gtid_16061);\n        float yMappingToOrigin_16065 = ratioy_14519 * i64_res_16064;\n        float floor_res_16066;\n        \n        floor_res_16066 = futrts_floor32(yMappingToOrigin_16065);\n        \n        int64_t f32_res_16067 = fptosi_f32_i64(floor_res_16066);\n        \n        ((__global int64_t *) mem_16729)[gtid_16060 * newSizzeY_14508 +\n                                         gtid_16061] = f32_res_16067;\n    }\n    \n  error_0:\n    return;\n    #undef segmap",
            "_group_sizze_16057\n}\n__kernel void bicubicInterpolationImagezisegmap_16083(__global\n                                                      int *global_failure,\n                                                      int64_t n_14507,\n                                                      int64_t newSizzeY_14508,\n                                                      int64_t newSizzeX_14509,\n                                                      float ratiox_14516,\n                                                      __global\n                                                      unsigned char *mem_16735)\n{\n    #define segmap_group_sizze_16077 (bicubicInterpolationImagezisegmap_group_sizze_15696)\n    \n    const int block_dim0 = 0;\n    const int block_dim1 = 1;\n    const int block_dim2 = 2;\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t global_tid_16842;\n    int32_t local_tid_16843;\n    int64_t group_sizze_16846;\n    int32_t wave_sizze_16845;\n    int32_t group_tid_16844;\n    \n    global_tid_16842 = get_global_id(0);\n    local_tid_16843 = get_local_id(0);\n    group_sizze_16846 = get_local_size(0);\n    wave_sizze_16845 = LOCKSTEP_WIDTH;\n    group_tid_16844 = get_group_id(0);\n    \n    int32_t phys_tid_16083 = global_tid_16842;\n    int64_t global_tid_16847 = sext_i32_i64(group_tid_16844) *\n            segmap_group_sizze_16077 + sext_i32_i64(local_tid_16843);\n    int64_t slice_16848 = newSizzeX_14509;\n    int64_t slice_16849 = newSizzeY_14508 * slice_16848;\n    int64_t slice_16850 = n_14507 * slice_16849;\n    int64_t gtid_16080 = squot64(global_tid_16847, slice_16849);\n    int64_t remnant_16851 = global_tid_16847 - gtid_16080 * slice_16849;\n    int64_t gtid_16081 = squot64(remnant_16851, slice_16848);\n    int64_t remnant_16852 = remnant_16851 - gtid_16081 * slice_16848;\n    int64_t gtid_16082 = remnant_16852;\n    int64_t remnant_16853 = remnant_16852 - gtid_16082;\n    \n    if ((slt64(gtid_16080, n_14507) && slt64(gtid_16081, newSizzeY_14508)) &&\n        slt64",
            "(gtid_16082, newSizzeX_14509)) {\n        float i64_res_16085 = sitofp_i64_f32(gtid_16082);\n        float xMappingToOrigin_16086 = ratiox_14516 * i64_res_16085;\n        float floor_res_16087;\n        \n        floor_res_16087 = futrts_floor32(xMappingToOrigin_16086);\n        \n        int64_t f32_res_16088 = fptosi_f32_i64(floor_res_16087);\n        \n        ((__global int64_t *) mem_16735)[gtid_16080 * (newSizzeX_14509 *\n                                                       newSizzeY_14508) +\n                                         gtid_16081 * newSizzeX_14509 +\n                                         gtid_16082] = f32_res_16088;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_group_sizze_16077\n}\n__kernel void bicubicInterpolationImagezisegmap_16106(__global\n                                                      int *global_failure,\n                                                      int failure_is_an_option,\n                                                      __global\n                                                      int64_t *global_failure_args,\n                                                      int64_t h_14505,\n                                                      int64_t w_14506,\n                                                      int64_t n_14507,\n                                                      int64_t newSizzeY_14508,\n                                                      int64_t newSizzeX_14509,\n                                                      int64_t clip_arg_14529,\n                                                      int64_t clip_arg_14530,\n                                                      __global\n                                                      unsigned char *input_mem_16683,\n                                                      __global\n                                                      unsigned char *mem_16729,\n                                                      __global\n                                           ",
            "           unsigned char *mem_16735,\n                                                      __global\n                                                      unsigned char *mem_16742)\n{\n    #define segmap_group_sizze_16099 (bicubicInterpolationImagezisegmap_group_sizze_15623)\n    \n    const int block_dim0 = 0;\n    const int block_dim1 = 1;\n    const int block_dim2 = 2;\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t global_tid_16854;\n    int32_t local_tid_16855;\n    int64_t group_sizze_16858;\n    int32_t wave_sizze_16857;\n    int32_t group_tid_16856;\n    \n    global_tid_16854 = get_global_id(0);\n    local_tid_16855 = get_local_id(0);\n    group_sizze_16858 = get_local_size(0);\n    wave_sizze_16857 = LOCKSTEP_WIDTH;\n    group_tid_16856 = get_group_id(0);\n    \n    int32_t phys_tid_16106 = global_tid_16854;\n    int64_t global_tid_16859 = sext_i32_i64(group_tid_16856) *\n            segmap_group_sizze_16099 + sext_i32_i64(local_tid_16855);\n    int64_t slice_16860 = (int64_t) 16;\n    int64_t slice_16861 = newSizzeX_14509 * slice_16860;\n    int64_t slice_16862 = newSizzeY_14508 * slice_16861;\n    int64_t slice_16863 = n_14507 * slice_16862;\n    int64_t gtid_16102 = squot64(global_tid_16859, slice_16862);\n    int64_t remnant_16864 = global_tid_16859 - gtid_16102 * slice_16862;\n    int64_t gtid_16103 = squot64(remnant_16864, slice_16861);\n    int64_t remnant_16865 = remnant_16864 - gtid_16103 * slice_16861;\n    int64_t gtid_16104 = squot64(remnant_16865, slice_16860);\n    int64_t remnant_16866 = remnant_16865 - gtid_16104 * slice_16860;\n    int64_t gtid_16105 = remnant_16866;\n    int64_t remnant_16867 = remnant_16866 - gtid_16105;\n    \n    if (((slt64(gtid_16102, n_14507) && slt64(gtid_16103, newSizzeY_14508)) &&\n         slt64(gtid_16104, newSizzeX_14509)) && slt64(gtid_16105,\n                                                      (int64_t) 16)) {\n        int64_t f32_res_16108;\n        \n        f32_res_16108 = ((__global int64_t *) mem_16729)[gtid_16102 *\n    ",
            "                                                     newSizzeY_14508 +\n                                                         gtid_16103];\n        \n        int64_t f32_res_16109;\n        \n        f32_res_16109 = ((__global int64_t *) mem_16735)[gtid_16102 *\n                                                         (newSizzeX_14509 *\n                                                          newSizzeY_14508) +\n                                                         gtid_16103 *\n                                                         newSizzeX_14509 +\n                                                         gtid_16104];\n        \n        int64_t ndatay_16111 = sdiv64(gtid_16105, (int64_t) 4);\n        int64_t ndatax_16112 = smod64(gtid_16105, (int64_t) 4);\n        int64_t y_16113 = sub64(ndatay_16111, (int64_t) 1);\n        int64_t clip_arg_16114 = add64(f32_res_16108, y_16113);\n        int64_t max_res_16115 = smax64((int64_t) 0, clip_arg_16114);\n        int64_t min_res_16116 = smin64(clip_arg_14529, max_res_16115);\n        bool x_16117 = sle64((int64_t) 0, min_res_16116);\n        bool y_16118 = slt64(min_res_16116, h_14505);\n        bool bounds_check_16119 = x_16117 && y_16118;\n        int64_t y_16120 = sub64(ndatax_16112, (int64_t) 1);\n        int64_t clip_arg_16121 = add64(f32_res_16109, y_16120);\n        int64_t max_res_16122 = smax64((int64_t) 0, clip_arg_16121);\n        int64_t min_res_16123 = smin64(clip_arg_14530, max_res_16122);\n        bool x_16124 = sle64((int64_t) 0, min_res_16123);\n        bool y_16125 = slt64(min_res_16123, w_14506);\n        bool bounds_check_16126 = x_16124 && y_16125;\n        bool index_ok_16127 = bounds_check_16119 && bounds_check_16126;\n        bool index_certs_16128;\n        \n        if (!index_ok_16127) {\n            {\n                if (atomic_cmpxchg_i32_global(global_failure, -1, 1) == -1) {\n                    global_failure_args[0] = (int64_t) min_res_16116;\n                    global_failure_args[1] = (int64_t) min_res_16123;",
            "\n                    global_failure_args[2] = (int64_t) h_14505;\n                    global_failure_args[3] = (int64_t) w_14506;\n                    ;\n                }\n                return;\n            }\n        }\n        \n        float defunc_0_f_res_16129;\n        \n        defunc_0_f_res_16129 = ((__global\n                                 float *) input_mem_16683)[min_res_16116 *\n                                                           (n_14507 * w_14506) +\n                                                           min_res_16123 *\n                                                           n_14507 +\n                                                           gtid_16102];\n        ((__global float *) mem_16742)[gtid_16102 * ((int64_t) 16 *\n                                                     newSizzeX_14509 *\n                                                     newSizzeY_14508) +\n                                       gtid_16103 * ((int64_t) 16 *\n                                                     newSizzeX_14509) +\n                                       gtid_16104 * (int64_t) 16 + gtid_16105] =\n            defunc_0_f_res_16129;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_group_sizze_16099\n}\n__kernel void bicubicInterpolationImagezisegmap_16146(__global\n                                                      int *global_failure,\n                                                      int64_t n_14507,\n                                                      int64_t newSizzeY_14508,\n                                                      float ratioy_14519,\n                                                      __global\n                                                      unsigned char *mem_16747)\n{\n    #define segmap_group_sizze_16140 (bicubicInterpolationImagezisegmap_group_sizze_15437)\n    \n    const int block_dim0 = 0;\n    const int block_dim1 = 1;\n    const int block_dim2 = 2;\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t global_tid_16868",
            ";\n    int32_t local_tid_16869;\n    int64_t group_sizze_16872;\n    int32_t wave_sizze_16871;\n    int32_t group_tid_16870;\n    \n    global_tid_16868 = get_global_id(0);\n    local_tid_16869 = get_local_id(0);\n    group_sizze_16872 = get_local_size(0);\n    wave_sizze_16871 = LOCKSTEP_WIDTH;\n    group_tid_16870 = get_group_id(0);\n    \n    int32_t phys_tid_16146 = global_tid_16868;\n    int64_t global_tid_16873 = sext_i32_i64(group_tid_16870) *\n            segmap_group_sizze_16140 + sext_i32_i64(local_tid_16869);\n    int64_t slice_16874 = newSizzeY_14508;\n    int64_t slice_16875 = n_14507 * slice_16874;\n    int64_t gtid_16144 = squot64(global_tid_16873, slice_16874);\n    int64_t remnant_16876 = global_tid_16873 - gtid_16144 * slice_16874;\n    int64_t gtid_16145 = remnant_16876;\n    int64_t remnant_16877 = remnant_16876 - gtid_16145;\n    \n    if (slt64(gtid_16144, n_14507) && slt64(gtid_16145, newSizzeY_14508)) {\n        float i64_res_16148 = sitofp_i64_f32(gtid_16145);\n        float yMappingToOrigin_16149 = ratioy_14519 * i64_res_16148;\n        float floor_res_16150;\n        \n        floor_res_16150 = futrts_floor32(yMappingToOrigin_16149);\n        \n        float yMappingToOriginFrac_16151 = yMappingToOrigin_16149 -\n              floor_res_16150;\n        \n        ((__global float *) mem_16747)[gtid_16144 * newSizzeY_14508 +\n                                       gtid_16145] = yMappingToOriginFrac_16151;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_group_sizze_16140\n}\n__kernel void bicubicInterpolationImagezisegmap_16170(__global\n                                                      int *global_failure,\n                                                      int64_t n_14507,\n                                                      int64_t newSizzeY_14508,\n                                                      int64_t newSizzeX_14509,\n                                                      float ratiox_14516,\n                                                      __global\n    ",
            "                                                  unsigned char *mem_16753)\n{\n    #define segmap_group_sizze_16163 (bicubicInterpolationImagezisegmap_group_sizze_15313)\n    \n    const int block_dim0 = 0;\n    const int block_dim1 = 1;\n    const int block_dim2 = 2;\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t global_tid_16878;\n    int32_t local_tid_16879;\n    int64_t group_sizze_16882;\n    int32_t wave_sizze_16881;\n    int32_t group_tid_16880;\n    \n    global_tid_16878 = get_global_id(0);\n    local_tid_16879 = get_local_id(0);\n    group_sizze_16882 = get_local_size(0);\n    wave_sizze_16881 = LOCKSTEP_WIDTH;\n    group_tid_16880 = get_group_id(0);\n    \n    int32_t phys_tid_16170 = global_tid_16878;\n    int64_t global_tid_16883 = sext_i32_i64(group_tid_16880) *\n            segmap_group_sizze_16163 + sext_i32_i64(local_tid_16879);\n    int64_t slice_16884 = newSizzeX_14509;\n    int64_t slice_16885 = newSizzeY_14508 * slice_16884;\n    int64_t slice_16886 = n_14507 * slice_16885;\n    int64_t gtid_16167 = squot64(global_tid_16883, slice_16885);\n    int64_t remnant_16887 = global_tid_16883 - gtid_16167 * slice_16885;\n    int64_t gtid_16168 = squot64(remnant_16887, slice_16884);\n    int64_t remnant_16888 = remnant_16887 - gtid_16168 * slice_16884;\n    int64_t gtid_16169 = remnant_16888;\n    int64_t remnant_16889 = remnant_16888 - gtid_16169;\n    \n    if ((slt64(gtid_16167, n_14507) && slt64(gtid_16168, newSizzeY_14508)) &&\n        slt64(gtid_16169, newSizzeX_14509)) {\n        float i64_res_16174 = sitofp_i64_f32(gtid_16169);\n        float xMappingToOrigin_16175 = ratiox_14516 * i64_res_16174;\n        float floor_res_16176;\n        \n        floor_res_16176 = futrts_floor32(xMappingToOrigin_16175);\n        \n        float xMappingToOriginFrac_16177 = xMappingToOrigin_16175 -\n              floor_res_16176;\n        \n        ((__global float *) mem_16753)[gtid_16167 * (newSizzeX_14509 *\n                                                     newSizzeY_14508) +\n   ",
            "                                    gtid_16168 * newSizzeX_14509 +\n                                       gtid_16169] = xMappingToOriginFrac_16177;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_group_sizze_16163\n}\n__kernel void bicubicInterpolationImagezisegmap_16200(__global\n                                                      int *global_failure,\n                                                      int64_t n_14507,\n                                                      int64_t newSizzeY_14508,\n                                                      int64_t newSizzeX_14509,\n                                                      __global\n                                                      unsigned char *mem_16742,\n                                                      __global\n                                                      unsigned char *mem_16753,\n                                                      __global\n                                                      unsigned char *mem_16760)\n{\n    #define segmap_group_sizze_16193 (bicubicInterpolationImagezisegmap_group_sizze_15228)\n    \n    const int block_dim0 = 0;\n    const int block_dim1 = 1;\n    const int block_dim2 = 2;\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t global_tid_16890;\n    int32_t local_tid_16891;\n    int64_t group_sizze_16894;\n    int32_t wave_sizze_16893;\n    int32_t group_tid_16892;\n    \n    global_tid_16890 = get_global_id(0);\n    local_tid_16891 = get_local_id(0);\n    group_sizze_16894 = get_local_size(0);\n    wave_sizze_16893 = LOCKSTEP_WIDTH;\n    group_tid_16892 = get_group_id(0);\n    \n    int32_t phys_tid_16200 = global_tid_16890;\n    int64_t global_tid_16895 = sext_i32_i64(group_tid_16892) *\n            segmap_group_sizze_16193 + sext_i32_i64(local_tid_16891);\n    int64_t slice_16896 = (int64_t) 4;\n    int64_t slice_16897 = newSizzeX_14509 * slice_16896;\n    int64_t slice_16898 = newSizzeY_14508 * slice_16897;\n    int64_t slice_16899 = n_14507 * slice_16898",
            ";\n    int64_t gtid_16196 = squot64(global_tid_16895, slice_16898);\n    int64_t remnant_16900 = global_tid_16895 - gtid_16196 * slice_16898;\n    int64_t gtid_16197 = squot64(remnant_16900, slice_16897);\n    int64_t remnant_16901 = remnant_16900 - gtid_16197 * slice_16897;\n    int64_t gtid_16198 = squot64(remnant_16901, slice_16896);\n    int64_t remnant_16902 = remnant_16901 - gtid_16198 * slice_16896;\n    int64_t gtid_16199 = remnant_16902;\n    int64_t remnant_16903 = remnant_16902 - gtid_16199;\n    \n    if (((slt64(gtid_16196, n_14507) && slt64(gtid_16197, newSizzeY_14508)) &&\n         slt64(gtid_16198, newSizzeX_14509)) && slt64(gtid_16199,\n                                                      (int64_t) 4)) {\n        float xMappingToOriginFrac_16204;\n        \n        xMappingToOriginFrac_16204 = ((__global float *) mem_16753)[gtid_16196 *\n                                                                    (newSizzeX_14509 *\n                                                                     newSizzeY_14508) +\n                                                                    gtid_16197 *\n                                                                    newSizzeX_14509 +\n                                                                    gtid_16198];\n        \n        int64_t binop_x_16211 = (int64_t) 4 * gtid_16199;\n        int64_t new_index_16212 = (int64_t) 3 + binop_x_16211;\n        float x_16213;\n        \n        x_16213 = ((__global float *) mem_16742)[gtid_16196 * ((int64_t) 16 *\n                                                               newSizzeX_14509 *\n                                                               newSizzeY_14508) +\n                                                 gtid_16197 * ((int64_t) 16 *\n                                                               newSizzeX_14509) +\n                                                 gtid_16198 * (int64_t) 16 +\n                                                 new_index_16212];\n        \n        i",
            "nt64_t new_index_16214 = (int64_t) 2 + binop_x_16211;\n        float y_16215;\n        \n        y_16215 = ((__global float *) mem_16742)[gtid_16196 * ((int64_t) 16 *\n                                                               newSizzeX_14509 *\n                                                               newSizzeY_14508) +\n                                                 gtid_16197 * ((int64_t) 16 *\n                                                               newSizzeX_14509) +\n                                                 gtid_16198 * (int64_t) 16 +\n                                                 new_index_16214];\n        \n        float x_16216 = x_16213 - y_16215;\n        float x_16217;\n        \n        x_16217 = ((__global float *) mem_16742)[gtid_16196 * ((int64_t) 16 *\n                                                               newSizzeX_14509 *\n                                                               newSizzeY_14508) +\n                                                 gtid_16197 * ((int64_t) 16 *\n                                                               newSizzeX_14509) +\n                                                 gtid_16198 * (int64_t) 16 +\n                                                 binop_x_16211];\n        \n        int64_t new_index_16218 = (int64_t) 1 + binop_x_16211;\n        float y_16219;\n        \n        y_16219 = ((__global float *) mem_16742)[gtid_16196 * ((int64_t) 16 *\n                                                               newSizzeX_14509 *\n                                                               newSizzeY_14508) +\n                                                 gtid_16197 * ((int64_t) 16 *\n                                                               newSizzeX_14509) +\n                                                 gtid_16198 * (int64_t) 16 +\n                                                 new_index_16218];\n        \n        float y_16220 = x_16217 - y_16219;\n        float a_16221 = x_16216 - y_16220",
            ";\n        float b_16222 = y_16220 - a_16221;\n        float c_16223 = y_16215 - x_16217;\n        float y_16224 = xMappingToOriginFrac_16204 * a_16221;\n        float y_16225 = b_16222 + y_16224;\n        float y_16226 = xMappingToOriginFrac_16204 * y_16225;\n        float y_16227 = c_16223 + y_16226;\n        float y_16228 = xMappingToOriginFrac_16204 * y_16227;\n        float cubicPolate_res_16229 = y_16219 + y_16228;\n        \n        ((__global float *) mem_16760)[gtid_16196 * ((int64_t) 4 *\n                                                     newSizzeX_14509 *\n                                                     newSizzeY_14508) +\n                                       gtid_16197 * ((int64_t) 4 *\n                                                     newSizzeX_14509) +\n                                       gtid_16198 * (int64_t) 4 + gtid_16199] =\n            cubicPolate_res_16229;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_group_sizze_16193\n}\n__kernel void bicubicInterpolationImagezisegmap_16240(__global\n                                                      int *global_failure,\n                                                      int64_t n_14507,\n                                                      int64_t newSizzeY_14508,\n                                                      int64_t newSizzeX_14509,\n                                                      __global\n                                                      unsigned char *mem_16747,\n                                                      __global\n                                                      unsigned char *mem_16760,\n                                                      __global\n                                                      unsigned char *mem_16766)\n{\n    #define segmap_group_sizze_16234 (bicubicInterpolationImagezisegmap_group_sizze_15175)\n    \n    const int block_dim0 = 0;\n    const int block_dim1 = 1;\n    const int block_dim2 = 2;\n    \n    if (*global_failure >= 0)\n        return;\n   ",
            " \n    int32_t global_tid_16904;\n    int32_t local_tid_16905;\n    int64_t group_sizze_16908;\n    int32_t wave_sizze_16907;\n    int32_t group_tid_16906;\n    \n    global_tid_16904 = get_global_id(0);\n    local_tid_16905 = get_local_id(0);\n    group_sizze_16908 = get_local_size(0);\n    wave_sizze_16907 = LOCKSTEP_WIDTH;\n    group_tid_16906 = get_group_id(0);\n    \n    int32_t phys_tid_16240 = global_tid_16904;\n    int64_t global_tid_16909 = sext_i32_i64(group_tid_16906) *\n            segmap_group_sizze_16234 + sext_i32_i64(local_tid_16905);\n    int64_t slice_16910 = newSizzeX_14509;\n    int64_t slice_16911 = newSizzeY_14508 * slice_16910;\n    int64_t slice_16912 = n_14507 * slice_16911;\n    int64_t gtid_16237 = squot64(global_tid_16909, slice_16911);\n    int64_t remnant_16913 = global_tid_16909 - gtid_16237 * slice_16911;\n    int64_t gtid_16238 = squot64(remnant_16913, slice_16910);\n    int64_t remnant_16914 = remnant_16913 - gtid_16238 * slice_16910;\n    int64_t gtid_16239 = remnant_16914;\n    int64_t remnant_16915 = remnant_16914 - gtid_16239;\n    \n    if ((slt64(gtid_16237, n_14507) && slt64(gtid_16238, newSizzeY_14508)) &&\n        slt64(gtid_16239, newSizzeX_14509)) {\n        float yMappingToOriginFrac_16241;\n        \n        yMappingToOriginFrac_16241 = ((__global float *) mem_16747)[gtid_16237 *\n                                                                    newSizzeY_14508 +\n                                                                    gtid_16238];\n        \n        float x_16243;\n        \n        x_16243 = ((__global float *) mem_16760)[gtid_16237 * ((int64_t) 4 *\n                                                               newSizzeX_14509 *\n                                                               newSizzeY_14508) +\n                                                 gtid_16238 * ((int64_t) 4 *\n                                                               newSizzeX_14509) +\n                                                 gtid_16239 * (int64_t) 4 +",
            "\n                                                 (int64_t) 3];\n        \n        float y_16244;\n        \n        y_16244 = ((__global float *) mem_16760)[gtid_16237 * ((int64_t) 4 *\n                                                               newSizzeX_14509 *\n                                                               newSizzeY_14508) +\n                                                 gtid_16238 * ((int64_t) 4 *\n                                                               newSizzeX_14509) +\n                                                 gtid_16239 * (int64_t) 4 +\n                                                 (int64_t) 2];\n        \n        float x_16245 = x_16243 - y_16244;\n        float x_16246;\n        \n        x_16246 = ((__global float *) mem_16760)[gtid_16237 * ((int64_t) 4 *\n                                                               newSizzeX_14509 *\n                                                               newSizzeY_14508) +\n                                                 gtid_16238 * ((int64_t) 4 *\n                                                               newSizzeX_14509) +\n                                                 gtid_16239 * (int64_t) 4];\n        \n        float y_16247;\n        \n        y_16247 = ((__global float *) mem_16760)[gtid_16237 * ((int64_t) 4 *\n                                                               newSizzeX_14509 *\n                                                               newSizzeY_14508) +\n                                                 gtid_16238 * ((int64_t) 4 *\n                                                               newSizzeX_14509) +\n                                                 gtid_16239 * (int64_t) 4 +\n                                                 (int64_t) 1];\n        \n        float y_16248 = x_16246 - y_16247;\n        float a_16249 = x_16245 - y_16248;\n        float b_16250 = y_16248 - a_16249;\n        float c_16251 = y_16244 - x_16246;\n        float y_16252 = yMappingToOrig",
            "inFrac_16241 * a_16249;\n        float y_16253 = b_16250 + y_16252;\n        float y_16254 = yMappingToOriginFrac_16241 * y_16253;\n        float y_16255 = c_16251 + y_16254;\n        float y_16256 = yMappingToOriginFrac_16241 * y_16255;\n        float cubicPolate_res_16257 = y_16247 + y_16256;\n        float max_res_16258 = fmax32(0.0F, cubicPolate_res_16257);\n        float min_res_16259 = fmin32(1.0F, max_res_16258);\n        \n        ((__global float *) mem_16766)[gtid_16237 * (newSizzeX_14509 *\n                                                     newSizzeY_14508) +\n                                       gtid_16238 * newSizzeX_14509 +\n                                       gtid_16239] = min_res_16259;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_group_sizze_16234\n}\n__kernel void bicubicInterpolationImagezisegmap_16442(__global\n                                                      int *global_failure,\n                                                      int64_t n_14507,\n                                                      int64_t newSizzeY_14508,\n                                                      int64_t newSizzeX_14509,\n                                                      __global\n                                                      unsigned char *mem_16771,\n                                                      __global\n                                                      unsigned char *mem_16777)\n{\n    #define segmap_group_sizze_16436 (bicubicInterpolationImagezisegmap_group_sizze_16293)\n    \n    const int block_dim0 = 0;\n    const int block_dim1 = 1;\n    const int block_dim2 = 2;\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t global_tid_16917;\n    int32_t local_tid_16918;\n    int64_t group_sizze_16921;\n    int32_t wave_sizze_16920;\n    int32_t group_tid_16919;\n    \n    global_tid_16917 = get_global_id(0);\n    local_tid_16918 = get_local_id(0);\n    group_sizze_16921 = get_local_size(0);\n    wave_sizze_16920 = LOCKSTEP_WIDTH;\n    grou",
            "p_tid_16919 = get_group_id(0);\n    \n    int32_t phys_tid_16442 = global_tid_16917;\n    int64_t global_tid_16922 = sext_i32_i64(group_tid_16919) *\n            segmap_group_sizze_16436 + sext_i32_i64(local_tid_16918);\n    int64_t slice_16923 = n_14507;\n    int64_t slice_16924 = newSizzeX_14509 * slice_16923;\n    int64_t slice_16925 = newSizzeY_14508 * slice_16924;\n    int64_t gtid_16439 = squot64(global_tid_16922, slice_16924);\n    int64_t remnant_16926 = global_tid_16922 - gtid_16439 * slice_16924;\n    int64_t gtid_16440 = squot64(remnant_16926, slice_16923);\n    int64_t remnant_16927 = remnant_16926 - gtid_16440 * slice_16923;\n    int64_t gtid_16441 = remnant_16927;\n    int64_t remnant_16928 = remnant_16927 - gtid_16441;\n    \n    if ((slt64(gtid_16439, newSizzeY_14508) && slt64(gtid_16440,\n                                                     newSizzeX_14509)) &&\n        slt64(gtid_16441, n_14507)) {\n        float defunc_0_f_res_16454;\n        \n        defunc_0_f_res_16454 = ((__global float *) mem_16771)[gtid_16439 *\n                                                              (n_14507 *\n                                                               newSizzeX_14509) +\n                                                              gtid_16440 *\n                                                              n_14507 +\n                                                              gtid_16441];\n        ((__global float *) mem_16777)[gtid_16439 * (n_14507 *\n                                                     newSizzeX_14509) +\n                                       gtid_16440 * n_14507 + gtid_16441] =\n            defunc_0_f_res_16454;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_group_sizze_16436\n}\n__kernel void bicubicInterpolationImagezisegmap_intragroup_14985(__global\n                                                                 int *global_failure,\n                                                                 int failure_is_an_option,\n                      ",
            "                                           __global\n                                                                 int64_t *global_failure_args,\n                                                                 uint color_16783_backing_offset_0,\n                                                                 uint color_16782_backing_offset_1,\n                                                                 uint color_16781_backing_offset_2,\n                                                                 uint color_16780_backing_offset_3,\n                                                                 int64_t h_14505,\n                                                                 int64_t w_14506,\n                                                                 int64_t n_14507,\n                                                                 int64_t newSizzeY_14508,\n                                                                 int64_t newSizzeX_14509,\n                                                                 float ratiox_14516,\n                                                                 float ratioy_14519,\n                                                                 int64_t clip_arg_14529,\n                                                                 int64_t clip_arg_14530,\n                                                                 int64_t computed_group_sizze_14778,\n                                                                 __global\n                                                                 unsigned char *input_mem_16683,\n                                                                 __global\n                                                                 unsigned char *mem_16724)\n{\n    const int block_dim0 = 0;\n    const int block_dim1 = 1;\n    const int block_dim2 = 2;\n    volatile unsigned char *color_16783_backing_3 =\n                           &shared_mem[color_16783_backing_offset_0];\n    volatile unsigned char *",
            "color_16782_backing_2 =\n                           &shared_mem[color_16782_backing_offset_1];\n    volatile unsigned char *color_16781_backing_1 =\n                           &shared_mem[color_16781_backing_offset_2];\n    volatile unsigned char *color_16780_backing_0 =\n                           &shared_mem[color_16780_backing_offset_3];\n    volatile __local bool local_failure;\n    \n    if (failure_is_an_option) {\n        int failed = *global_failure >= 0;\n        \n        if (failed)\n            return;\n    }\n    local_failure = false;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    \n    int32_t global_tid_16796;\n    int32_t local_tid_16797;\n    int64_t group_sizze_16800;\n    int32_t wave_sizze_16799;\n    int32_t group_tid_16798;\n    \n    global_tid_16796 = get_global_id(0);\n    local_tid_16797 = get_local_id(0);\n    group_sizze_16800 = get_local_size(0);\n    wave_sizze_16799 = LOCKSTEP_WIDTH;\n    group_tid_16798 = get_group_id(0);\n    \n    int32_t phys_tid_14985 = group_tid_16798;\n    int64_t slice_16802 = newSizzeY_14508;\n    int64_t ltid_pre_16801 = sext_i32_i64(local_tid_16797);\n    int64_t remnant_16803 = sext_i32_i64(local_tid_16797) - ltid_pre_16801;\n    int64_t slice_16806 = newSizzeX_14509;\n    int64_t slice_16807 = newSizzeY_14508 * slice_16806;\n    int64_t ltid_pre_16804 = squot64(sext_i32_i64(local_tid_16797),\n                                     slice_16806);\n    int64_t remnant_16808 = sext_i32_i64(local_tid_16797) - ltid_pre_16804 *\n            slice_16806;\n    int64_t ltid_pre_16805 = remnant_16808;\n    int64_t remnant_16809 = remnant_16808 - ltid_pre_16805;\n    int64_t slice_16813 = (int64_t) 4;\n    int64_t slice_16814 = newSizzeX_14509 * slice_16813;\n    int64_t slice_16815 = newSizzeY_14508 * slice_16814;\n    int64_t ltid_pre_16810 = squot64(sext_i32_i64(local_tid_16797),\n                                     slice_16814);\n    int64_t remnant_16816 = sext_i32_i64(local_tid_16797) - ltid_pre_16810 *\n            slice_16814;\n    int64_t ltid_pre_16811 = squot64",
            "(remnant_16816, slice_16813);\n    int64_t remnant_16817 = remnant_16816 - ltid_pre_16811 * slice_16813;\n    int64_t ltid_pre_16812 = remnant_16817;\n    int64_t remnant_16818 = remnant_16817 - ltid_pre_16812;\n    int64_t slice_16822 = (int64_t) 16;\n    int64_t slice_16823 = newSizzeX_14509 * slice_16822;\n    int64_t slice_16824 = newSizzeY_14508 * slice_16823;\n    int64_t ltid_pre_16819 = squot64(sext_i32_i64(local_tid_16797),\n                                     slice_16823);\n    int64_t remnant_16825 = sext_i32_i64(local_tid_16797) - ltid_pre_16819 *\n            slice_16823;\n    int64_t ltid_pre_16820 = squot64(remnant_16825, slice_16822);\n    int64_t remnant_16826 = remnant_16825 - ltid_pre_16820 * slice_16822;\n    int64_t ltid_pre_16821 = remnant_16826;\n    int64_t remnant_16827 = remnant_16826 - ltid_pre_16821;\n    int64_t slice_16828 = n_14507;\n    int64_t gtid_14984 = sext_i32_i64(group_tid_16798);\n    int64_t remnant_16829 = sext_i32_i64(group_tid_16798) - gtid_14984;\n    __local unsigned char *color_16780;\n    \n    color_16780 = (__local unsigned char *) color_16780_backing_0;\n    \n    __local unsigned char *color_16781;\n    \n    color_16781 = (__local unsigned char *) color_16781_backing_1;\n    \n    __local unsigned char *color_16782;\n    \n    color_16782 = (__local unsigned char *) color_16782_backing_2;\n    \n    __local unsigned char *color_16783;\n    \n    color_16783 = (__local unsigned char *) color_16783_backing_3;\n    \n    int64_t gtid_15012 = sext_i32_i64(sext_i64_i32(ltid_pre_16801));\n    int32_t phys_tid_15013 = local_tid_16797;\n    \n    if (slt64(gtid_15012, newSizzeY_14508)) {\n        float i64_res_15015 = sitofp_i64_f32(gtid_15012);\n        float yMappingToOrigin_15016 = ratioy_14519 * i64_res_15015;\n        float floor_res_15017;\n        \n        floor_res_15017 = futrts_floor32(yMappingToOrigin_15016);\n        \n        int64_t f32_res_15018 = fptosi_f32_i64(floor_res_15017);\n        \n        ((__local int64_t *) color_16781)[gtid_15012] = f32_",
            "res_15018;\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    \n    int64_t gtid_15020 = sext_i32_i64(sext_i64_i32(ltid_pre_16804));\n    int64_t gtid_15021 = sext_i32_i64(sext_i64_i32(ltid_pre_16805));\n    int32_t phys_tid_15022 = local_tid_16797;\n    \n    if (slt64(gtid_15020, newSizzeY_14508) && slt64(gtid_15021,\n                                                    newSizzeX_14509)) {\n        float i64_res_15024 = sitofp_i64_f32(gtid_15021);\n        float xMappingToOrigin_15025 = ratiox_14516 * i64_res_15024;\n        float floor_res_15026;\n        \n        floor_res_15026 = futrts_floor32(xMappingToOrigin_15025);\n        \n        int64_t f32_res_15027 = fptosi_f32_i64(floor_res_15026);\n        \n        ((__local int64_t *) color_16780)[gtid_15020 * newSizzeX_14509 +\n                                          gtid_15021] = f32_res_15027;\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    \n    int64_t gtid_15029 = sext_i32_i64(sext_i64_i32(ltid_pre_16819));\n    int64_t gtid_15030 = sext_i32_i64(sext_i64_i32(ltid_pre_16820));\n    int64_t gtid_15031 = sext_i32_i64(sext_i64_i32(ltid_pre_16821));\n    int32_t phys_tid_15032 = local_tid_16797;\n    \n    if ((slt64(gtid_15029, newSizzeY_14508) && slt64(gtid_15030,\n                                                     newSizzeX_14509)) &&\n        slt64(gtid_15031, (int64_t) 16)) {\n        int64_t f32_res_15033;\n        \n        f32_res_15033 = ((__local int64_t *) color_16781)[gtid_15029];\n        \n        int64_t f32_res_15034;\n        \n        f32_res_15034 = ((__local int64_t *) color_16780)[gtid_15029 *\n                                                          newSizzeX_14509 +\n                                                          gtid_15030];\n        \n        int64_t ndatay_15036 = sdiv64(gtid_15031, (int64_t) 4);\n        int64_t ndatax_15037 = smod64(gtid_15031, (int64_t) 4);\n        int64_t y_15038 = sub64(ndatay_15036, (int64_t) 1);\n        int64_t clip_arg_15039 = add64(f32_res_15033, y_15038);\n        int64_t max_res_15040 = sma",
            "x64((int64_t) 0, clip_arg_15039);\n        int64_t min_res_15041 = smin64(clip_arg_14529, max_res_15040);\n        bool x_15042 = sle64((int64_t) 0, min_res_15041);\n        bool y_15043 = slt64(min_res_15041, h_14505);\n        bool bounds_check_15044 = x_15042 && y_15043;\n        int64_t y_15045 = sub64(ndatax_15037, (int64_t) 1);\n        int64_t clip_arg_15046 = add64(f32_res_15034, y_15045);\n        int64_t max_res_15047 = smax64((int64_t) 0, clip_arg_15046);\n        int64_t min_res_15048 = smin64(clip_arg_14530, max_res_15047);\n        bool x_15049 = sle64((int64_t) 0, min_res_15048);\n        bool y_15050 = slt64(min_res_15048, w_14506);\n        bool bounds_check_15051 = x_15049 && y_15050;\n        bool index_ok_15052 = bounds_check_15044 && bounds_check_15051;\n        bool index_certs_15053;\n        \n        if (!index_ok_15052) {\n            {\n                if (atomic_cmpxchg_i32_global(global_failure, -1, 0) == -1) {\n                    global_failure_args[0] = (int64_t) min_res_15041;\n                    global_failure_args[1] = (int64_t) min_res_15048;\n                    global_failure_args[2] = (int64_t) h_14505;\n                    global_failure_args[3] = (int64_t) w_14506;\n                    ;\n                }\n                local_failure = true;\n                goto error_2;\n            }\n        }\n        \n        float defunc_0_f_res_15054;\n        \n        defunc_0_f_res_15054 = ((__global\n                                 float *) input_mem_16683)[min_res_15041 *\n                                                           (n_14507 * w_14506) +\n                                                           min_res_15048 *\n                                                           n_14507 +\n                                                           gtid_14984];\n        ((__local float *) color_16783)[gtid_15029 * ((int64_t) 16 *\n                                                      newSizzeX_14509) +\n                                        gtid_15030 * ",
            "(int64_t) 16 +\n                                        gtid_15031] = defunc_0_f_res_15054;\n    }\n    \n  error_2:\n    barrier(CLK_LOCAL_MEM_FENCE);\n    if (local_failure)\n        return;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    \n    int64_t gtid_15057 = sext_i32_i64(sext_i64_i32(ltid_pre_16801));\n    int32_t phys_tid_15058 = local_tid_16797;\n    \n    if (slt64(gtid_15057, newSizzeY_14508)) {\n        float i64_res_15060 = sitofp_i64_f32(gtid_15057);\n        float yMappingToOrigin_15061 = ratioy_14519 * i64_res_15060;\n        float floor_res_15062;\n        \n        floor_res_15062 = futrts_floor32(yMappingToOrigin_15061);\n        \n        float yMappingToOriginFrac_15063 = yMappingToOrigin_15061 -\n              floor_res_15062;\n        \n        ((__local float *) color_16782)[gtid_15057] =\n            yMappingToOriginFrac_15063;\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    \n    int64_t gtid_15069 = sext_i32_i64(sext_i64_i32(ltid_pre_16804));\n    int64_t gtid_15070 = sext_i32_i64(sext_i64_i32(ltid_pre_16805));\n    int32_t phys_tid_15071 = local_tid_16797;\n    \n    if (slt64(gtid_15069, newSizzeY_14508) && slt64(gtid_15070,\n                                                    newSizzeX_14509)) {\n        float i64_res_15075 = sitofp_i64_f32(gtid_15070);\n        float xMappingToOrigin_15076 = ratiox_14516 * i64_res_15075;\n        float floor_res_15077;\n        \n        floor_res_15077 = futrts_floor32(xMappingToOrigin_15076);\n        \n        float xMappingToOriginFrac_15078 = xMappingToOrigin_15076 -\n              floor_res_15077;\n        \n        ((__local float *) color_16780)[gtid_15069 * newSizzeX_14509 +\n                                        gtid_15070] =\n            xMappingToOriginFrac_15078;\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    \n    int64_t gtid_15085 = sext_i32_i64(sext_i64_i32(ltid_pre_16810));\n    int64_t gtid_15086 = sext_i32_i64(sext_i64_i32(ltid_pre_16811));\n    int64_t gtid_15087 = sext_i32_i64(sext_i64_i32(ltid_pre_16812));\n    int32_t phys_tid_15088 =",
            " local_tid_16797;\n    \n    if ((slt64(gtid_15085, newSizzeY_14508) && slt64(gtid_15086,\n                                                     newSizzeX_14509)) &&\n        slt64(gtid_15087, (int64_t) 4)) {\n        float xMappingToOriginFrac_15091;\n        \n        xMappingToOriginFrac_15091 = ((__local\n                                       float *) color_16780)[gtid_15085 *\n                                                             newSizzeX_14509 +\n                                                             gtid_15086];\n        \n        int64_t binop_x_15098 = (int64_t) 4 * gtid_15087;\n        int64_t new_index_15099 = (int64_t) 3 + binop_x_15098;\n        float x_15100;\n        \n        x_15100 = ((__local float *) color_16783)[gtid_15085 * ((int64_t) 16 *\n                                                                newSizzeX_14509) +\n                                                  gtid_15086 * (int64_t) 16 +\n                                                  new_index_15099];\n        \n        int64_t new_index_15101 = (int64_t) 2 + binop_x_15098;\n        float y_15102;\n        \n        y_15102 = ((__local float *) color_16783)[gtid_15085 * ((int64_t) 16 *\n                                                                newSizzeX_14509) +\n                                                  gtid_15086 * (int64_t) 16 +\n                                                  new_index_15101];\n        \n        float x_15103 = x_15100 - y_15102;\n        float x_15104;\n        \n        x_15104 = ((__local float *) color_16783)[gtid_15085 * ((int64_t) 16 *\n                                                                newSizzeX_14509) +\n                                                  gtid_15086 * (int64_t) 16 +\n                                                  binop_x_15098];\n        \n        int64_t new_index_15105 = (int64_t) 1 + binop_x_15098;\n        float y_15106;\n        \n        y_15106 = ((__local float *) color_16783)[gtid_15085 * ((int64_t) 16 *\n                ",
            "                                                newSizzeX_14509) +\n                                                  gtid_15086 * (int64_t) 16 +\n                                                  new_index_15105];\n        \n        float y_15107 = x_15104 - y_15106;\n        float a_15108 = x_15103 - y_15107;\n        float b_15109 = y_15107 - a_15108;\n        float c_15110 = y_15102 - x_15104;\n        float y_15111 = xMappingToOriginFrac_15091 * a_15108;\n        float y_15112 = b_15109 + y_15111;\n        float y_15113 = xMappingToOriginFrac_15091 * y_15112;\n        float y_15114 = c_15110 + y_15113;\n        float y_15115 = xMappingToOriginFrac_15091 * y_15114;\n        float cubicPolate_res_15116 = y_15106 + y_15115;\n        \n        ((__local float *) color_16781)[gtid_15085 * ((int64_t) 4 *\n                                                      newSizzeX_14509) +\n                                        gtid_15086 * (int64_t) 4 + gtid_15087] =\n            cubicPolate_res_15116;\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    \n    int64_t gtid_15118 = sext_i32_i64(sext_i64_i32(ltid_pre_16804));\n    int64_t gtid_15119 = sext_i32_i64(sext_i64_i32(ltid_pre_16805));\n    int32_t phys_tid_15120 = local_tid_16797;\n    \n    if (slt64(gtid_15118, newSizzeY_14508) && slt64(gtid_15119,\n                                                    newSizzeX_14509)) {\n        float yMappingToOriginFrac_15121;\n        \n        yMappingToOriginFrac_15121 = ((__local\n                                       float *) color_16782)[gtid_15118];\n        \n        float x_15123;\n        \n        x_15123 = ((__local float *) color_16781)[gtid_15118 * ((int64_t) 4 *\n                                                                newSizzeX_14509) +\n                                                  gtid_15119 * (int64_t) 4 +\n                                                  (int64_t) 3];\n        \n        float y_15124;\n        \n        y_15124 = ((__local float *) color_16781)[gtid_15118 * ((int64_t) 4 *\n       ",
            "                                                         newSizzeX_14509) +\n                                                  gtid_15119 * (int64_t) 4 +\n                                                  (int64_t) 2];\n        \n        float x_15125 = x_15123 - y_15124;\n        float x_15126;\n        \n        x_15126 = ((__local float *) color_16781)[gtid_15118 * ((int64_t) 4 *\n                                                                newSizzeX_14509) +\n                                                  gtid_15119 * (int64_t) 4];\n        \n        float y_15127;\n        \n        y_15127 = ((__local float *) color_16781)[gtid_15118 * ((int64_t) 4 *\n                                                                newSizzeX_14509) +\n                                                  gtid_15119 * (int64_t) 4 +\n                                                  (int64_t) 1];\n        \n        float y_15128 = x_15126 - y_15127;\n        float a_15129 = x_15125 - y_15128;\n        float b_15130 = y_15128 - a_15129;\n        float c_15131 = y_15124 - x_15126;\n        float y_15132 = yMappingToOriginFrac_15121 * a_15129;\n        float y_15133 = b_15130 + y_15132;\n        float y_15134 = yMappingToOriginFrac_15121 * y_15133;\n        float y_15135 = c_15131 + y_15134;\n        float y_15136 = yMappingToOriginFrac_15121 * y_15135;\n        float cubicPolate_res_15137 = y_15127 + y_15136;\n        float max_res_15138 = fmax32(0.0F, cubicPolate_res_15137);\n        float min_res_15139 = fmin32(1.0F, max_res_15138);\n        \n        ((__local float *) color_16780)[gtid_15118 * newSizzeX_14509 +\n                                        gtid_15119] = min_res_15139;\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    for (int64_t i_16830 = 0; i_16830 < sdiv_up64(newSizzeY_14508 *\n                                                  newSizzeX_14509 -\n                                                  sext_i32_i64(local_tid_16797),\n                                                  computed_group_sizze_14778",
            ");\n         i_16830++) {\n        float tmp_16831;\n        \n        tmp_16831 = ((__local float *) color_16780)[squot64(i_16830 *\n                                                            computed_group_sizze_14778 +\n                                                            sext_i32_i64(local_tid_16797),\n                                                            newSizzeX_14509) *\n                                                    newSizzeX_14509 + (i_16830 *\n                                                                       computed_group_sizze_14778 +\n                                                                       sext_i32_i64(local_tid_16797) -\n                                                                       squot64(i_16830 *\n                                                                               computed_group_sizze_14778 +\n                                                                               sext_i32_i64(local_tid_16797),\n                                                                               newSizzeX_14509) *\n                                                                       newSizzeX_14509)];\n        ((__global float *) mem_16724)[gtid_14984 * (newSizzeX_14509 *\n                                                     newSizzeY_14508) +\n                                       squot64(i_16830 *\n                                               computed_group_sizze_14778 +\n                                               sext_i32_i64(local_tid_16797),\n                                               newSizzeX_14509) *\n                                       newSizzeX_14509 + (i_16830 *\n                                                          computed_group_sizze_14778 +\n                                                          sext_i32_i64(local_tid_16797) -\n                                                          squot64(i_16830 *\n                                                                  computed_group_sizze_14778",
            " +\n                                                                  sext_i32_i64(local_tid_16797),\n                                                                  newSizzeX_14509) *\n                                                          newSizzeX_14509)] =\n            tmp_16831;\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    \n  error_7:\n    return;\n}\n__kernel void builtinzhiota_i64ziiota_i64_16801(int32_t n_16797,\n                                                int64_t x_16798,\n                                                int64_t s_16799, __global\n                                                unsigned char *mem_16796)\n{\n    const int block_dim0 = 0;\n    const int block_dim1 = 1;\n    const int block_dim2 = 2;\n    int32_t iota_gtid_16801;\n    int32_t iota_ltid_16802;\n    int32_t iota_gid_16803;\n    \n    iota_gtid_16801 = get_global_id(0);\n    iota_ltid_16802 = get_local_id(0);\n    iota_gid_16803 = get_group_id(0);\n    if (slt64(iota_gtid_16801, n_16797)) {\n        ((__global int64_t *) mem_16796)[sext_i32_i64(iota_gtid_16801)] =\n            add64(mul64(sext_i32_i64(iota_gtid_16801), s_16799), x_16798);\n    }\n    \n  error_0:\n    return;\n}\n__kernel void gpu_map_transpose_f32(const int block_dim0, const int block_dim1,\n                                    const int block_dim2,\n                                    uint block_9_backing_offset_0,\n                                    int32_t destoffset_1, int32_t srcoffset_3,\n                                    int32_t num_arrays_4, int32_t x_elems_5,\n                                    int32_t y_elems_6, int32_t mulx_7,\n                                    int32_t muly_8, __global\n                                    unsigned char *destmem_0, __global\n                                    unsigned char *srcmem_2)\n{\n    volatile unsigned char *block_9_backing_0 =\n                           &shared_mem[block_9_backing_offset_0];\n    __local unsigned char *block_9;\n    \n    block_9 = (__local unsigned char *) block_9_backing_",
            "0;\n    \n    int32_t get_global_id_0_37;\n    \n    get_global_id_0_37 = get_global_id(0);\n    \n    int32_t get_local_id_0_38;\n    \n    get_local_id_0_38 = get_local_id(0);\n    \n    int32_t get_local_id_1_39;\n    \n    get_local_id_1_39 = get_local_id(1);\n    \n    int32_t get_group_id_0_40;\n    \n    get_group_id_0_40 = get_group_id(0);\n    \n    int32_t get_group_id_1_41;\n    \n    get_group_id_1_41 = get_group_id(1);\n    \n    int32_t get_group_id_2_42;\n    \n    get_group_id_2_42 = get_group_id(2);\n    \n    int32_t our_array_offset_30 = get_group_id_2_42 * x_elems_5 * y_elems_6;\n    int32_t odata_offset_33 = squot32(destoffset_1, 4) + our_array_offset_30;\n    int32_t idata_offset_34 = squot32(srcoffset_3, 4) + our_array_offset_30;\n    int32_t x_index_31 = get_global_id_0_37;\n    int32_t y_index_32 = get_group_id_1_41 * 32 + get_local_id_1_39;\n    float val_44;\n    \n    if (slt32(x_index_31, x_elems_5)) {\n        for (int32_t j_43 = 0; j_43 < 4; j_43++) {\n            int32_t index_in_35 = (y_index_32 + j_43 * 8) * x_elems_5 +\n                    x_index_31;\n            \n            if (slt32(y_index_32 + j_43 * 8, y_elems_6)) {\n                val_44 = ((__global\n                           float *) srcmem_2)[sext_i32_i64(idata_offset_34 +\n                                              index_in_35)];\n                ((__local float *) block_9)[sext_i32_i64((get_local_id_1_39 +\n                                                          j_43 * 8) * 33 +\n                                            get_local_id_0_38)] = val_44;\n            }\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    x_index_31 = get_group_id_1_41 * 32 + get_local_id_0_38;\n    y_index_32 = get_group_id_0_40 * 32 + get_local_id_1_39;\n    if (slt32(x_index_31, y_elems_6)) {\n        for (int32_t j_43 = 0; j_43 < 4; j_43++) {\n            int32_t index_out_36 = (y_index_32 + j_43 * 8) * y_elems_6 +\n                    x_index_31;\n            \n            if (slt32(y_index_32 + j_43 * 8, x_elems_5)) {\n      ",
            "          val_44 = ((__local\n                           float *) block_9)[sext_i32_i64(get_local_id_0_38 *\n                                             33 + get_local_id_1_39 + j_43 *\n                                             8)];\n                ((__global float *) destmem_0)[sext_i32_i64(odata_offset_33 +\n                                               index_out_36)] = val_44;\n            }\n        }\n    }\n    \n  error_0:\n    return;\n}\n__kernel void gpu_map_transpose_f32_low_height(const int block_dim0, const\n                                               int block_dim1, const\n                                               int block_dim2,\n                                               uint block_9_backing_offset_0,\n                                               int32_t destoffset_1,\n                                               int32_t srcoffset_3,\n                                               int32_t num_arrays_4,\n                                               int32_t x_elems_5,\n                                               int32_t y_elems_6,\n                                               int32_t mulx_7, int32_t muly_8,\n                                               __global\n                                               unsigned char *destmem_0,\n                                               __global unsigned char *srcmem_2)\n{\n    volatile unsigned char *block_9_backing_0 =\n                           &shared_mem[block_9_backing_offset_0];\n    __local unsigned char *block_9;\n    \n    block_9 = (__local unsigned char *) block_9_backing_0;\n    \n    int32_t get_global_id_0_37;\n    \n    get_global_id_0_37 = get_global_id(0);\n    \n    int32_t get_local_id_0_38;\n    \n    get_local_id_0_38 = get_local_id(0);\n    \n    int32_t get_local_id_1_39;\n    \n    get_local_id_1_39 = get_local_id(1);\n    \n    int32_t get_group_id_0_40;\n    \n    get_group_id_0_40 = get_group_id(0);\n    \n    int32_t get_group_id_1_41;\n    \n    get_group_id_1_41 = get_group_id(1);\n    \n    int32_",
            "t get_group_id_2_42;\n    \n    get_group_id_2_42 = get_group_id(2);\n    \n    int32_t our_array_offset_30 = get_group_id_2_42 * x_elems_5 * y_elems_6;\n    int32_t odata_offset_33 = squot32(destoffset_1, 4) + our_array_offset_30;\n    int32_t idata_offset_34 = squot32(srcoffset_3, 4) + our_array_offset_30;\n    int32_t x_index_31 = get_group_id_0_40 * 16 * mulx_7 + get_local_id_0_38 +\n            srem32(get_local_id_1_39, mulx_7) * 16;\n    int32_t y_index_32 = get_group_id_1_41 * 16 + squot32(get_local_id_1_39,\n                                                          mulx_7);\n    float val_44;\n    int32_t index_in_35 = y_index_32 * x_elems_5 + x_index_31;\n    \n    if (slt32(x_index_31, x_elems_5) && slt32(y_index_32, y_elems_6)) {\n        val_44 = ((__global float *) srcmem_2)[sext_i32_i64(idata_offset_34 +\n                                               index_in_35)];\n        ((__local float *) block_9)[sext_i32_i64(get_local_id_1_39 * 17 +\n                                    get_local_id_0_38)] = val_44;\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    x_index_31 = get_group_id_1_41 * 16 + squot32(get_local_id_0_38, mulx_7);\n    y_index_32 = get_group_id_0_40 * 16 * mulx_7 + get_local_id_1_39 +\n        srem32(get_local_id_0_38, mulx_7) * 16;\n    \n    int32_t index_out_36 = y_index_32 * y_elems_6 + x_index_31;\n    \n    if (slt32(x_index_31, y_elems_6) && slt32(y_index_32, x_elems_5)) {\n        val_44 = ((__local float *) block_9)[sext_i32_i64(get_local_id_0_38 *\n                                             17 + get_local_id_1_39)];\n        ((__global float *) destmem_0)[sext_i32_i64(odata_offset_33 +\n                                       index_out_36)] = val_44;\n    }\n    \n  error_0:\n    return;\n}\n__kernel void gpu_map_transpose_f32_low_width(const int block_dim0, const\n                                              int block_dim1, const\n                                              int block_dim2,\n                                              uint block_9_backing_offset_0,\n",
            "                                              int32_t destoffset_1,\n                                              int32_t srcoffset_3,\n                                              int32_t num_arrays_4,\n                                              int32_t x_elems_5,\n                                              int32_t y_elems_6, int32_t mulx_7,\n                                              int32_t muly_8, __global\n                                              unsigned char *destmem_0, __global\n                                              unsigned char *srcmem_2)\n{\n    volatile unsigned char *block_9_backing_0 =\n                           &shared_mem[block_9_backing_offset_0];\n    __local unsigned char *block_9;\n    \n    block_9 = (__local unsigned char *) block_9_backing_0;\n    \n    int32_t get_global_id_0_37;\n    \n    get_global_id_0_37 = get_global_id(0);\n    \n    int32_t get_local_id_0_38;\n    \n    get_local_id_0_38 = get_local_id(0);\n    \n    int32_t get_local_id_1_39;\n    \n    get_local_id_1_39 = get_local_id(1);\n    \n    int32_t get_group_id_0_40;\n    \n    get_group_id_0_40 = get_group_id(0);\n    \n    int32_t get_group_id_1_41;\n    \n    get_group_id_1_41 = get_group_id(1);\n    \n    int32_t get_group_id_2_42;\n    \n    get_group_id_2_42 = get_group_id(2);\n    \n    int32_t our_array_offset_30 = get_group_id_2_42 * x_elems_5 * y_elems_6;\n    int32_t odata_offset_33 = squot32(destoffset_1, 4) + our_array_offset_30;\n    int32_t idata_offset_34 = squot32(srcoffset_3, 4) + our_array_offset_30;\n    int32_t x_index_31 = get_group_id_0_40 * 16 + squot32(get_local_id_0_38,\n                                                          muly_8);\n    int32_t y_index_32 = get_group_id_1_41 * 16 * muly_8 + get_local_id_1_39 +\n            srem32(get_local_id_0_38, muly_8) * 16;\n    float val_44;\n    int32_t index_in_35 = y_index_32 * x_elems_5 + x_index_31;\n    \n    if (slt32(x_index_31, x_elems_5) && slt32(y_index_32, y_elems_6)) {\n        val_44 = ((__global float *) srcmem_2)[",
            "sext_i32_i64(idata_offset_34 +\n                                               index_in_35)];\n        ((__local float *) block_9)[sext_i32_i64(get_local_id_1_39 * 17 +\n                                    get_local_id_0_38)] = val_44;\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    x_index_31 = get_group_id_1_41 * 16 * muly_8 + get_local_id_0_38 +\n        srem32(get_local_id_1_39, muly_8) * 16;\n    y_index_32 = get_group_id_0_40 * 16 + squot32(get_local_id_1_39, muly_8);\n    \n    int32_t index_out_36 = y_index_32 * y_elems_6 + x_index_31;\n    \n    if (slt32(x_index_31, y_elems_6) && slt32(y_index_32, x_elems_5)) {\n        val_44 = ((__local float *) block_9)[sext_i32_i64(get_local_id_0_38 *\n                                             17 + get_local_id_1_39)];\n        ((__global float *) destmem_0)[sext_i32_i64(odata_offset_33 +\n                                       index_out_36)] = val_44;\n    }\n    \n  error_0:\n    return;\n}\n__kernel void gpu_map_transpose_f32_small(uint block_9_backing_offset_0,\n                                          int32_t destoffset_1,\n                                          int32_t srcoffset_3,\n                                          int32_t num_arrays_4,\n                                          int32_t x_elems_5, int32_t y_elems_6,\n                                          int32_t mulx_7, int32_t muly_8,\n                                          __global unsigned char *destmem_0,\n                                          __global unsigned char *srcmem_2)\n{\n    const int block_dim0 = 0;\n    const int block_dim1 = 1;\n    const int block_dim2 = 2;\n    volatile unsigned char *block_9_backing_0 =\n                           &shared_mem[block_9_backing_offset_0];\n    __local unsigned char *block_9;\n    \n    block_9 = (__local unsigned char *) block_9_backing_0;\n    \n    int32_t get_global_id_0_37;\n    \n    get_global_id_0_37 = get_global_id(0);\n    \n    int32_t get_local_id_0_38;\n    \n    get_local_id_0_38 = get_local_id(0);\n    \n    int32_t get_",
            "local_id_1_39;\n    \n    get_local_id_1_39 = get_local_id(1);\n    \n    int32_t get_group_id_0_40;\n    \n    get_group_id_0_40 = get_group_id(0);\n    \n    int32_t get_group_id_1_41;\n    \n    get_group_id_1_41 = get_group_id(1);\n    \n    int32_t get_group_id_2_42;\n    \n    get_group_id_2_42 = get_group_id(2);\n    \n    int32_t our_array_offset_30 = squot32(get_global_id_0_37, y_elems_6 *\n                                          x_elems_5) * (y_elems_6 * x_elems_5);\n    int32_t x_index_31 = squot32(srem32(get_global_id_0_37, y_elems_6 *\n                                        x_elems_5), y_elems_6);\n    int32_t y_index_32 = srem32(get_global_id_0_37, y_elems_6);\n    float val_44;\n    int32_t odata_offset_33 = squot32(destoffset_1, 4) + our_array_offset_30;\n    int32_t idata_offset_34 = squot32(srcoffset_3, 4) + our_array_offset_30;\n    int32_t index_in_35 = y_index_32 * x_elems_5 + x_index_31;\n    int32_t index_out_36 = x_index_31 * y_elems_6 + y_index_32;\n    \n    if (slt32(get_global_id_0_37, x_elems_5 * y_elems_6 * num_arrays_4)) {\n        val_44 = ((__global float *) srcmem_2)[sext_i32_i64(idata_offset_34 +\n                                               index_in_35)];\n        ((__global float *) destmem_0)[sext_i32_i64(odata_offset_33 +\n                                       index_out_36)] = val_44;\n    }\n    \n  error_0:\n    return;\n}\n__kernel void gpu_map_transpose_i64(const int block_dim0, const int block_dim1,\n                                    const int block_dim2,\n                                    uint block_9_backing_offset_0,\n                                    int32_t destoffset_1, int32_t srcoffset_3,\n                                    int32_t num_arrays_4, int32_t x_elems_5,\n                                    int32_t y_elems_6, int32_t mulx_7,\n                                    int32_t muly_8, __global\n                                    unsigned char *destmem_0, __global\n                                    unsigned char *srcmem_2)\n{\n    volatile unsi",
            "gned char *block_9_backing_0 =\n                           &shared_mem[block_9_backing_offset_0];\n    __local unsigned char *block_9;\n    \n    block_9 = (__local unsigned char *) block_9_backing_0;\n    \n    int32_t get_global_id_0_37;\n    \n    get_global_id_0_37 = get_global_id(0);\n    \n    int32_t get_local_id_0_38;\n    \n    get_local_id_0_38 = get_local_id(0);\n    \n    int32_t get_local_id_1_39;\n    \n    get_local_id_1_39 = get_local_id(1);\n    \n    int32_t get_group_id_0_40;\n    \n    get_group_id_0_40 = get_group_id(0);\n    \n    int32_t get_group_id_1_41;\n    \n    get_group_id_1_41 = get_group_id(1);\n    \n    int32_t get_group_id_2_42;\n    \n    get_group_id_2_42 = get_group_id(2);\n    \n    int32_t our_array_offset_30 = get_group_id_2_42 * x_elems_5 * y_elems_6;\n    int32_t odata_offset_33 = squot32(destoffset_1, 8) + our_array_offset_30;\n    int32_t idata_offset_34 = squot32(srcoffset_3, 8) + our_array_offset_30;\n    int32_t x_index_31 = get_global_id_0_37;\n    int32_t y_index_32 = get_group_id_1_41 * 32 + get_local_id_1_39;\n    int64_t val_44;\n    \n    if (slt32(x_index_31, x_elems_5)) {\n        for (int32_t j_43 = 0; j_43 < 4; j_43++) {\n            int32_t index_in_35 = (y_index_32 + j_43 * 8) * x_elems_5 +\n                    x_index_31;\n            \n            if (slt32(y_index_32 + j_43 * 8, y_elems_6)) {\n                val_44 = ((__global\n                           int64_t *) srcmem_2)[sext_i32_i64(idata_offset_34 +\n                                                index_in_35)];\n                ((__local int64_t *) block_9)[sext_i32_i64((get_local_id_1_39 +\n                                                            j_43 * 8) * 33 +\n                                              get_local_id_0_38)] = val_44;\n            }\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    x_index_31 = get_group_id_1_41 * 32 + get_local_id_0_38;\n    y_index_32 = get_group_id_0_40 * 32 + get_local_id_1_39;\n    if (slt32(x_index_31, y_elems_6)) {\n        for (int32_t j_43 = ",
            "0; j_43 < 4; j_43++) {\n            int32_t index_out_36 = (y_index_32 + j_43 * 8) * y_elems_6 +\n                    x_index_31;\n            \n            if (slt32(y_index_32 + j_43 * 8, x_elems_5)) {\n                val_44 = ((__local\n                           int64_t *) block_9)[sext_i32_i64(get_local_id_0_38 *\n                                               33 + get_local_id_1_39 + j_43 *\n                                               8)];\n                ((__global int64_t *) destmem_0)[sext_i32_i64(odata_offset_33 +\n                                                 index_out_36)] = val_44;\n            }\n        }\n    }\n    \n  error_0:\n    return;\n}\n__kernel void gpu_map_transpose_i64_low_height(const int block_dim0, const\n                                               int block_dim1, const\n                                               int block_dim2,\n                                               uint block_9_backing_offset_0,\n                                               int32_t destoffset_1,\n                                               int32_t srcoffset_3,\n                                               int32_t num_arrays_4,\n                                               int32_t x_elems_5,\n                                               int32_t y_elems_6,\n                                               int32_t mulx_7, int32_t muly_8,\n                                               __global\n                                               unsigned char *destmem_0,\n                                               __global unsigned char *srcmem_2)\n{\n    volatile unsigned char *block_9_backing_0 =\n                           &shared_mem[block_9_backing_offset_0];\n    __local unsigned char *block_9;\n    \n    block_9 = (__local unsigned char *) block_9_backing_0;\n    \n    int32_t get_global_id_0_37;\n    \n    get_global_id_0_37 = get_global_id(0);\n    \n    int32_t get_local_id_0_38;\n    \n    get_local_id_0_38 = get_local_id(0);\n    \n    int32_t get_local_id_1_39;\n    \n    ",
            "get_local_id_1_39 = get_local_id(1);\n    \n    int32_t get_group_id_0_40;\n    \n    get_group_id_0_40 = get_group_id(0);\n    \n    int32_t get_group_id_1_41;\n    \n    get_group_id_1_41 = get_group_id(1);\n    \n    int32_t get_group_id_2_42;\n    \n    get_group_id_2_42 = get_group_id(2);\n    \n    int32_t our_array_offset_30 = get_group_id_2_42 * x_elems_5 * y_elems_6;\n    int32_t odata_offset_33 = squot32(destoffset_1, 8) + our_array_offset_30;\n    int32_t idata_offset_34 = squot32(srcoffset_3, 8) + our_array_offset_30;\n    int32_t x_index_31 = get_group_id_0_40 * 16 * mulx_7 + get_local_id_0_38 +\n            srem32(get_local_id_1_39, mulx_7) * 16;\n    int32_t y_index_32 = get_group_id_1_41 * 16 + squot32(get_local_id_1_39,\n                                                          mulx_7);\n    int64_t val_44;\n    int32_t index_in_35 = y_index_32 * x_elems_5 + x_index_31;\n    \n    if (slt32(x_index_31, x_elems_5) && slt32(y_index_32, y_elems_6)) {\n        val_44 = ((__global int64_t *) srcmem_2)[sext_i32_i64(idata_offset_34 +\n                                                 index_in_35)];\n        ((__local int64_t *) block_9)[sext_i32_i64(get_local_id_1_39 * 17 +\n                                      get_local_id_0_38)] = val_44;\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    x_index_31 = get_group_id_1_41 * 16 + squot32(get_local_id_0_38, mulx_7);\n    y_index_32 = get_group_id_0_40 * 16 * mulx_7 + get_local_id_1_39 +\n        srem32(get_local_id_0_38, mulx_7) * 16;\n    \n    int32_t index_out_36 = y_index_32 * y_elems_6 + x_index_31;\n    \n    if (slt32(x_index_31, y_elems_6) && slt32(y_index_32, x_elems_5)) {\n        val_44 = ((__local int64_t *) block_9)[sext_i32_i64(get_local_id_0_38 *\n                                               17 + get_local_id_1_39)];\n        ((__global int64_t *) destmem_0)[sext_i32_i64(odata_offset_33 +\n                                         index_out_36)] = val_44;\n    }\n    \n  error_0:\n    return;\n}\n__kernel void gpu_map_transpose_i64_low_width(c",
            "onst int block_dim0, const\n                                              int block_dim1, const\n                                              int block_dim2,\n                                              uint block_9_backing_offset_0,\n                                              int32_t destoffset_1,\n                                              int32_t srcoffset_3,\n                                              int32_t num_arrays_4,\n                                              int32_t x_elems_5,\n                                              int32_t y_elems_6, int32_t mulx_7,\n                                              int32_t muly_8, __global\n                                              unsigned char *destmem_0, __global\n                                              unsigned char *srcmem_2)\n{\n    volatile unsigned char *block_9_backing_0 =\n                           &shared_mem[block_9_backing_offset_0];\n    __local unsigned char *block_9;\n    \n    block_9 = (__local unsigned char *) block_9_backing_0;\n    \n    int32_t get_global_id_0_37;\n    \n    get_global_id_0_37 = get_global_id(0);\n    \n    int32_t get_local_id_0_38;\n    \n    get_local_id_0_38 = get_local_id(0);\n    \n    int32_t get_local_id_1_39;\n    \n    get_local_id_1_39 = get_local_id(1);\n    \n    int32_t get_group_id_0_40;\n    \n    get_group_id_0_40 = get_group_id(0);\n    \n    int32_t get_group_id_1_41;\n    \n    get_group_id_1_41 = get_group_id(1);\n    \n    int32_t get_group_id_2_42;\n    \n    get_group_id_2_42 = get_group_id(2);\n    \n    int32_t our_array_offset_30 = get_group_id_2_42 * x_elems_5 * y_elems_6;\n    int32_t odata_offset_33 = squot32(destoffset_1, 8) + our_array_offset_30;\n    int32_t idata_offset_34 = squot32(srcoffset_3, 8) + our_array_offset_30;\n    int32_t x_index_31 = get_group_id_0_40 * 16 + squot32(get_local_id_0_38,\n                                                          muly_8);\n    int32_t y_index_32 = get_group_id_1_41 * 16 * muly_8 + get_local_id_1_39 +\n            srem32(get_",
            "local_id_0_38, muly_8) * 16;\n    int64_t val_44;\n    int32_t index_in_35 = y_index_32 * x_elems_5 + x_index_31;\n    \n    if (slt32(x_index_31, x_elems_5) && slt32(y_index_32, y_elems_6)) {\n        val_44 = ((__global int64_t *) srcmem_2)[sext_i32_i64(idata_offset_34 +\n                                                 index_in_35)];\n        ((__local int64_t *) block_9)[sext_i32_i64(get_local_id_1_39 * 17 +\n                                      get_local_id_0_38)] = val_44;\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    x_index_31 = get_group_id_1_41 * 16 * muly_8 + get_local_id_0_38 +\n        srem32(get_local_id_1_39, muly_8) * 16;\n    y_index_32 = get_group_id_0_40 * 16 + squot32(get_local_id_1_39, muly_8);\n    \n    int32_t index_out_36 = y_index_32 * y_elems_6 + x_index_31;\n    \n    if (slt32(x_index_31, y_elems_6) && slt32(y_index_32, x_elems_5)) {\n        val_44 = ((__local int64_t *) block_9)[sext_i32_i64(get_local_id_0_38 *\n                                               17 + get_local_id_1_39)];\n        ((__global int64_t *) destmem_0)[sext_i32_i64(odata_offset_33 +\n                                         index_out_36)] = val_44;\n    }\n    \n  error_0:\n    return;\n}\n__kernel void gpu_map_transpose_i64_small(uint block_9_backing_offset_0,\n                                          int32_t destoffset_1,\n                                          int32_t srcoffset_3,\n                                          int32_t num_arrays_4,\n                                          int32_t x_elems_5, int32_t y_elems_6,\n                                          int32_t mulx_7, int32_t muly_8,\n                                          __global unsigned char *destmem_0,\n                                          __global unsigned char *srcmem_2)\n{\n    const int block_dim0 = 0;\n    const int block_dim1 = 1;\n    const int block_dim2 = 2;\n    volatile unsigned char *block_9_backing_0 =\n                           &shared_mem[block_9_backing_offset_0];\n    __local unsigned char *block_9;\n",
            "    \n    block_9 = (__local unsigned char *) block_9_backing_0;\n    \n    int32_t get_global_id_0_37;\n    \n    get_global_id_0_37 = get_global_id(0);\n    \n    int32_t get_local_id_0_38;\n    \n    get_local_id_0_38 = get_local_id(0);\n    \n    int32_t get_local_id_1_39;\n    \n    get_local_id_1_39 = get_local_id(1);\n    \n    int32_t get_group_id_0_40;\n    \n    get_group_id_0_40 = get_group_id(0);\n    \n    int32_t get_group_id_1_41;\n    \n    get_group_id_1_41 = get_group_id(1);\n    \n    int32_t get_group_id_2_42;\n    \n    get_group_id_2_42 = get_group_id(2);\n    \n    int32_t our_array_offset_30 = squot32(get_global_id_0_37, y_elems_6 *\n                                          x_elems_5) * (y_elems_6 * x_elems_5);\n    int32_t x_index_31 = squot32(srem32(get_global_id_0_37, y_elems_6 *\n                                        x_elems_5), y_elems_6);\n    int32_t y_index_32 = srem32(get_global_id_0_37, y_elems_6);\n    int64_t val_44;\n    int32_t odata_offset_33 = squot32(destoffset_1, 8) + our_array_offset_30;\n    int32_t idata_offset_34 = squot32(srcoffset_3, 8) + our_array_offset_30;\n    int32_t index_in_35 = y_index_32 * x_elems_5 + x_index_31;\n    int32_t index_out_36 = x_index_31 * y_elems_6 + y_index_32;\n    \n    if (slt32(get_global_id_0_37, x_elems_5 * y_elems_6 * num_arrays_4)) {\n        val_44 = ((__global int64_t *) srcmem_2)[sext_i32_i64(idata_offset_34 +\n                                                 index_in_35)];\n        ((__global int64_t *) destmem_0)[sext_i32_i64(odata_offset_33 +\n                                         index_out_36)] = val_44;\n    }\n    \n  error_0:\n    return;\n}\n__kernel void shufflerzireplicate_16806(int64_t h_14666, int64_t w_14667,\n                                        __global unsigned char *mem_16685,\n                                        __global unsigned char *mem_16689)\n{\n    const int block_dim0 = 0;\n    const int block_dim1 = 1;\n    const int block_dim2 = 2;\n    int32_t replicate_gtid_16806;\n    int32_t replicate_ltid_16807",
            ";\n    int32_t replicate_gid_16808;\n    \n    replicate_gtid_16806 = get_global_id(0);\n    replicate_ltid_16807 = get_local_id(0);\n    replicate_gid_16808 = get_group_id(0);\n    \n    int64_t slice_16813 = w_14667;\n    int64_t slice_16814 = h_14666 * slice_16813;\n    int64_t rep_i_16811 = squot64(sext_i32_i64(replicate_gtid_16806),\n                                  slice_16813);\n    int64_t remnant_16815 = sext_i32_i64(replicate_gtid_16806) - rep_i_16811 *\n            slice_16813;\n    int64_t rep_i_16812 = remnant_16815;\n    int64_t remnant_16816 = remnant_16815 - rep_i_16812;\n    \n    if (slt64(replicate_gtid_16806, h_14666 * w_14667)) {\n        int64_t tmp_16817;\n        \n        tmp_16817 = ((__global int64_t *) mem_16685)[rep_i_16812];\n        ((__global int64_t *) mem_16689)[rep_i_16811 * w_14667 + rep_i_16812] =\n            tmp_16817;\n    }\n    \n  error_0:\n    return;\n}\n__kernel void shufflerzisegmap_16500(__global int *global_failure,\n                                     int64_t h_14666, int64_t w_14667, __global\n                                     unsigned char *mem_16694)\n{\n    #define segmap_group_sizze_16495 (shufflerzisegmap_group_sizze_16471)\n    \n    const int block_dim0 = 0;\n    const int block_dim1 = 1;\n    const int block_dim2 = 2;\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t global_tid_16818;\n    int32_t local_tid_16819;\n    int64_t group_sizze_16822;\n    int32_t wave_sizze_16821;\n    int32_t group_tid_16820;\n    \n    global_tid_16818 = get_global_id(0);\n    local_tid_16819 = get_local_id(0);\n    group_sizze_16822 = get_local_size(0);\n    wave_sizze_16821 = LOCKSTEP_WIDTH;\n    group_tid_16820 = get_group_id(0);\n    \n    int32_t phys_tid_16500 = global_tid_16818;\n    int64_t global_tid_16823 = sext_i32_i64(group_tid_16820) *\n            segmap_group_sizze_16495 + sext_i32_i64(local_tid_16819);\n    int64_t slice_16824 = w_14667;\n    int64_t slice_16825 = h_14666 * slice_16824;\n    int64_t gtid_16498 = squot64(global_tid_16823, sl",
            "ice_16824);\n    int64_t remnant_16826 = global_tid_16823 - gtid_16498 * slice_16824;\n    int64_t gtid_16499 = remnant_16826;\n    int64_t remnant_16827 = remnant_16826 - gtid_16499;\n    \n    if (slt64(gtid_16498, h_14666) && slt64(gtid_16499, w_14667)) {\n        ((__global int64_t *) mem_16694)[gtid_16498 * w_14667 + gtid_16499] =\n            gtid_16498;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_group_sizze_16495\n}\n__kernel void shufflerzisegmap_16555(__global int *global_failure,\n                                     int64_t h_14666, int64_t w_14667,\n                                     int64_t num_groups_16550, __global\n                                     unsigned char *mem_16689, __global\n                                     unsigned char *mem_16694, __global\n                                     unsigned char *mem_16736)\n{\n    #define segmap_group_sizze_16549 (shufflerzisegmap_group_sizze_16519)\n    \n    const int block_dim0 = 0;\n    const int block_dim1 = 1;\n    const int block_dim2 = 2;\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t global_tid_16838;\n    int32_t local_tid_16839;\n    int64_t group_sizze_16842;\n    int32_t wave_sizze_16841;\n    int32_t group_tid_16840;\n    \n    global_tid_16838 = get_global_id(0);\n    local_tid_16839 = get_local_id(0);\n    group_sizze_16842 = get_local_size(0);\n    wave_sizze_16841 = LOCKSTEP_WIDTH;\n    group_tid_16840 = get_group_id(0);\n    \n    int32_t phys_tid_16555 = global_tid_16838;\n    int32_t phys_group_id_16843;\n    \n    phys_group_id_16843 = get_group_id(0);\n    for (int32_t i_16844 = 0; i_16844 <\n         sdiv_up32(sext_i64_i32(sdiv_up64(h_14666 * w_14667,\n                                          segmap_group_sizze_16549)) -\n                   phys_group_id_16843, sext_i64_i32(num_groups_16550));\n         i_16844++) {\n        int32_t virt_group_id_16845 = phys_group_id_16843 + i_16844 *\n                sext_i64_i32(num_groups_16550);\n        int64_t global_tid_16846 = sext_i32_i64(virt_gr",
            "oup_id_16845) *\n                segmap_group_sizze_16549 + sext_i32_i64(local_tid_16839);\n        int64_t slice_16847 = w_14667;\n        int64_t slice_16848 = h_14666 * slice_16847;\n        int64_t gtid_16553 = squot64(global_tid_16846, slice_16847);\n        int64_t remnant_16849 = global_tid_16846 - gtid_16553 * slice_16847;\n        int64_t gtid_16554 = remnant_16849;\n        int64_t remnant_16850 = remnant_16849 - gtid_16554;\n        \n        if (slt64(gtid_16553, h_14666) && slt64(gtid_16554, w_14667)) {\n            int64_t color_16778[(int64_t) 2];\n            int64_t x_16556;\n            \n            x_16556 = ((__global int64_t *) mem_16694)[gtid_16553 * w_14667 +\n                                                       gtid_16554];\n            \n            int64_t x_16557;\n            \n            x_16557 = ((__global int64_t *) mem_16689)[gtid_16553 * w_14667 +\n                                                       gtid_16554];\n            color_16778[(int64_t) 0] = x_16556;\n            color_16778[(int64_t) 1] = x_16557;\n            for (int64_t i_16851 = 0; i_16851 < (int64_t) 2; i_16851++) {\n                int64_t tmp_16852;\n                \n                tmp_16852 = color_16778[i_16851];\n                ((__global int64_t *) mem_16736)[gtid_16553 * w_14667 +\n                                                 gtid_16554 + i_16851 *\n                                                 (w_14667 * h_14666)] =\n                    tmp_16852;\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_0:\n    return;\n    #undef segmap_group_sizze_16549\n}\n",
            NULL};
static const char *tuning_param_names[] =
                  {"bicubicInterpolationImage.segmap_group_size_15175",
                   "bicubicInterpolationImage.segmap_group_size_15228",
                   "bicubicInterpolationImage.segmap_group_size_15313",
                   "bicubicInterpolationImage.segmap_group_size_15437",
                   "bicubicInterpolationImage.segmap_group_size_15623",
                   "bicubicInterpolationImage.segmap_group_size_15696",
                   "bicubicInterpolationImage.segmap_group_size_15770",
                   "bicubicInterpolationImage.segmap_group_size_16293",
                   "bicubicInterpolationImage.suff_intra_par_0",
                   "builtin#iota_i64.group_size_16804",
                   "shuffler.group_size_16809",
                   "shuffler.segmap_group_size_16471",
                   "shuffler.segmap_group_size_16519",
                   "shuffler.segmap_num_groups_16521"};
static const char *tuning_param_vars[] =
                  {"bicubicInterpolationImagezisegmap_group_sizze_15175",
                   "bicubicInterpolationImagezisegmap_group_sizze_15228",
                   "bicubicInterpolationImagezisegmap_group_sizze_15313",
                   "bicubicInterpolationImagezisegmap_group_sizze_15437",
                   "bicubicInterpolationImagezisegmap_group_sizze_15623",
                   "bicubicInterpolationImagezisegmap_group_sizze_15696",
                   "bicubicInterpolationImagezisegmap_group_sizze_15770",
                   "bicubicInterpolationImagezisegmap_group_sizze_16293",
                   "bicubicInterpolationImagezisuff_intra_par_0",
                   "builtinzhiota_i64zigroup_sizze_16804",
                   "shufflerzigroup_sizze_16809",
                   "shufflerzisegmap_group_sizze_16471",
                   "shufflerzisegmap_group_sizze_16519",
                   "shufflerzisegmap_num_groups_16521"};
static const char *tuning_param_classes[] = {"group_size", "group_size",
                                             "group_size", "group_size",
                                             "group_size", "group_size",
                                             "group_size", "group_size",
                                             "threshold(32,)", "group_size",
                                             "group_size", "group_size",
                                             "group_size", "num_groups"};
struct tuning_params {
    int64_t *bicubicInterpolationImagezisegmap_group_sizze_15175;
    int64_t *bicubicInterpolationImagezisegmap_group_sizze_15228;
    int64_t *bicubicInterpolationImagezisegmap_group_sizze_15313;
    int64_t *bicubicInterpolationImagezisegmap_group_sizze_15437;
    int64_t *bicubicInterpolationImagezisegmap_group_sizze_15623;
    int64_t *bicubicInterpolationImagezisegmap_group_sizze_15696;
    int64_t *bicubicInterpolationImagezisegmap_group_sizze_15770;
    int64_t *bicubicInterpolationImagezisegmap_group_sizze_16293;
    int64_t *bicubicInterpolationImagezisuff_intra_par_0;
    int64_t *builtinzhiota_i64zigroup_sizze_16804;
    int64_t *shufflerzigroup_sizze_16809;
    int64_t *shufflerzisegmap_group_sizze_16471;
    int64_t *shufflerzisegmap_group_sizze_16519;
    int64_t *shufflerzisegmap_num_groups_16521;
};
struct futhark_context_config {
    int in_use;
    struct cuda_config cu_cfg;
    int profiling;
    int64_t tuning_params[14];
    int num_nvrtc_opts;
    const char **nvrtc_opts;
};
struct futhark_context_config *futhark_context_config_new(void)
{
    struct futhark_context_config *cfg =
                                  (struct futhark_context_config *) malloc(sizeof(struct futhark_context_config));
    
    if (cfg == NULL)
        return NULL;
    cfg->in_use = 0;
    cfg->profiling = 0;
    cfg->num_nvrtc_opts = 0;
    cfg->nvrtc_opts = (const char **) malloc(sizeof(const char *));
    cfg->nvrtc_opts[0] = NULL;
    cfg->tuning_params[0] = 0;
    cfg->tuning_params[1] = 0;
    cfg->tuning_params[2] = 0;
    cfg->tuning_params[3] = 0;
    cfg->tuning_params[4] = 0;
    cfg->tuning_params[5] = 0;
    cfg->tuning_params[6] = 0;
    cfg->tuning_params[7] = 0;
    cfg->tuning_params[8] = 32;
    cfg->tuning_params[9] = 0;
    cfg->tuning_params[10] = 0;
    cfg->tuning_params[11] = 0;
    cfg->tuning_params[12] = 0;
    cfg->tuning_params[13] = 0;
    cuda_config_init(&cfg->cu_cfg, 14, tuning_param_names, tuning_param_vars,
                     cfg->tuning_params, tuning_param_classes);
    return cfg;
}
void futhark_context_config_free(struct futhark_context_config *cfg)
{
    assert(!cfg->in_use);
    free(cfg->nvrtc_opts);
    free(cfg);
}
void futhark_context_config_add_nvrtc_option(struct futhark_context_config *cfg,
                                             const char *opt)
{
    cfg->nvrtc_opts[cfg->num_nvrtc_opts] = opt;
    cfg->num_nvrtc_opts++;
    cfg->nvrtc_opts = (const char **) realloc(cfg->nvrtc_opts,
                                              (cfg->num_nvrtc_opts + 1) *
                                              sizeof(const char *));
    cfg->nvrtc_opts[cfg->num_nvrtc_opts] = NULL;
}
void futhark_context_config_set_debugging(struct futhark_context_config *cfg,
                                          int flag)
{
    cfg->cu_cfg.logging = cfg->cu_cfg.debugging = flag;
}
void futhark_context_config_set_profiling(struct futhark_context_config *cfg,
                                          int flag)
{
    cfg->profiling = flag;
}
void futhark_context_config_set_logging(struct futhark_context_config *cfg,
                                        int flag)
{
    cfg->cu_cfg.logging = flag;
}
void futhark_context_config_set_device(struct futhark_context_config *cfg, const
                                       char *s)
{
    set_preferred_device(&cfg->cu_cfg, s);
}
void futhark_context_config_dump_program_to(struct futhark_context_config *cfg,
                                            const char *path)
{
    cfg->cu_cfg.dump_program_to = path;
}
void futhark_context_config_load_program_from(struct futhark_context_config *cfg,
                                              const char *path)
{
    cfg->cu_cfg.load_program_from = path;
}
void futhark_context_config_dump_ptx_to(struct futhark_context_config *cfg,
                                        const char *path)
{
    cfg->cu_cfg.dump_ptx_to = path;
}
void futhark_context_config_load_ptx_from(struct futhark_context_config *cfg,
                                          const char *path)
{
    cfg->cu_cfg.load_ptx_from = path;
}
void futhark_context_config_set_default_group_size(struct futhark_context_config *cfg,
                                                   int size)
{
    cfg->cu_cfg.default_block_size = size;
    cfg->cu_cfg.default_block_size_changed = 1;
}
void futhark_context_config_set_default_num_groups(struct futhark_context_config *cfg,
                                                   int num)
{
    cfg->cu_cfg.default_grid_size = num;
    cfg->cu_cfg.default_grid_size_changed = 1;
}
void futhark_context_config_set_default_tile_size(struct futhark_context_config *cfg,
                                                  int size)
{
    cfg->cu_cfg.default_tile_size = size;
    cfg->cu_cfg.default_tile_size_changed = 1;
}
void futhark_context_config_set_default_reg_tile_size(struct futhark_context_config *cfg,
                                                      int size)
{
    cfg->cu_cfg.default_reg_tile_size = size;
}
void futhark_context_config_set_default_threshold(struct futhark_context_config *cfg,
                                                  int size)
{
    cfg->cu_cfg.default_threshold = size;
}
int futhark_context_config_set_tuning_param(struct futhark_context_config *cfg,
                                            const char *param_name,
                                            size_t new_value)
{
    for (int i = 0; i < 14; i++) {
        if (strcmp(param_name, tuning_param_names[i]) == 0) {
            cfg->tuning_params[i] = new_value;
            return 0;
        }
    }
    if (strcmp(param_name, "default_group_size") == 0) {
        cfg->cu_cfg.default_block_size = new_value;
        return 0;
    }
    if (strcmp(param_name, "default_num_groups") == 0) {
        cfg->cu_cfg.default_grid_size = new_value;
        return 0;
    }
    if (strcmp(param_name, "default_threshold") == 0) {
        cfg->cu_cfg.default_threshold = new_value;
        return 0;
    }
    if (strcmp(param_name, "default_tile_size") == 0) {
        cfg->cu_cfg.default_tile_size = new_value;
        return 0;
    }
    if (strcmp(param_name, "default_reg_tile_size") == 0) {
        cfg->cu_cfg.default_reg_tile_size = new_value;
        return 0;
    }
    return 1;
}
struct futhark_context {
    struct futhark_context_config *cfg;
    int detail_memory;
    int debugging;
    int profiling;
    int profiling_paused;
    int logging;
    lock_t lock;
    char *error;
    FILE *log;
    int64_t peak_mem_usage_device;
    int64_t cur_mem_usage_device;
    int64_t peak_mem_usage_default;
    int64_t cur_mem_usage_default;
    struct {
        int dummy;
    } constants;
    CUfunction bicubicInterpolationImagezisegmap_16062;
    int64_t bicubicInterpolationImagezisegmap_16062_total_runtime;
    int bicubicInterpolationImagezisegmap_16062_runs;
    CUfunction bicubicInterpolationImagezisegmap_16083;
    int64_t bicubicInterpolationImagezisegmap_16083_total_runtime;
    int bicubicInterpolationImagezisegmap_16083_runs;
    CUfunction bicubicInterpolationImagezisegmap_16106;
    int64_t bicubicInterpolationImagezisegmap_16106_total_runtime;
    int bicubicInterpolationImagezisegmap_16106_runs;
    CUfunction bicubicInterpolationImagezisegmap_16146;
    int64_t bicubicInterpolationImagezisegmap_16146_total_runtime;
    int bicubicInterpolationImagezisegmap_16146_runs;
    CUfunction bicubicInterpolationImagezisegmap_16170;
    int64_t bicubicInterpolationImagezisegmap_16170_total_runtime;
    int bicubicInterpolationImagezisegmap_16170_runs;
    CUfunction bicubicInterpolationImagezisegmap_16200;
    int64_t bicubicInterpolationImagezisegmap_16200_total_runtime;
    int bicubicInterpolationImagezisegmap_16200_runs;
    CUfunction bicubicInterpolationImagezisegmap_16240;
    int64_t bicubicInterpolationImagezisegmap_16240_total_runtime;
    int bicubicInterpolationImagezisegmap_16240_runs;
    CUfunction bicubicInterpolationImagezisegmap_16442;
    int64_t bicubicInterpolationImagezisegmap_16442_total_runtime;
    int bicubicInterpolationImagezisegmap_16442_runs;
    CUfunction bicubicInterpolationImagezisegmap_intragroup_14985;
    int64_t bicubicInterpolationImagezisegmap_intragroup_14985_total_runtime;
    int bicubicInterpolationImagezisegmap_intragroup_14985_runs;
    CUfunction builtinzhiota_i64ziiota_i64_16801;
    int64_t builtinzhiota_i64ziiota_i64_16801_total_runtime;
    int builtinzhiota_i64ziiota_i64_16801_runs;
    CUfunction gpu_map_transpose_f32;
    int64_t gpu_map_transpose_f32_total_runtime;
    int gpu_map_transpose_f32_runs;
    CUfunction gpu_map_transpose_f32_low_height;
    int64_t gpu_map_transpose_f32_low_height_total_runtime;
    int gpu_map_transpose_f32_low_height_runs;
    CUfunction gpu_map_transpose_f32_low_width;
    int64_t gpu_map_transpose_f32_low_width_total_runtime;
    int gpu_map_transpose_f32_low_width_runs;
    CUfunction gpu_map_transpose_f32_small;
    int64_t gpu_map_transpose_f32_small_total_runtime;
    int gpu_map_transpose_f32_small_runs;
    CUfunction gpu_map_transpose_i64;
    int64_t gpu_map_transpose_i64_total_runtime;
    int gpu_map_transpose_i64_runs;
    CUfunction gpu_map_transpose_i64_low_height;
    int64_t gpu_map_transpose_i64_low_height_total_runtime;
    int gpu_map_transpose_i64_low_height_runs;
    CUfunction gpu_map_transpose_i64_low_width;
    int64_t gpu_map_transpose_i64_low_width_total_runtime;
    int gpu_map_transpose_i64_low_width_runs;
    CUfunction gpu_map_transpose_i64_small;
    int64_t gpu_map_transpose_i64_small_total_runtime;
    int gpu_map_transpose_i64_small_runs;
    CUfunction shufflerzireplicate_16806;
    int64_t shufflerzireplicate_16806_total_runtime;
    int shufflerzireplicate_16806_runs;
    CUfunction shufflerzisegmap_16500;
    int64_t shufflerzisegmap_16500_total_runtime;
    int shufflerzisegmap_16500_runs;
    CUfunction shufflerzisegmap_16555;
    int64_t shufflerzisegmap_16555_total_runtime;
    int shufflerzisegmap_16555_runs;
    int64_t copy_dev_to_dev_total_runtime;
    int copy_dev_to_dev_runs;
    int64_t copy_dev_to_host_total_runtime;
    int copy_dev_to_host_runs;
    int64_t copy_host_to_dev_total_runtime;
    int copy_host_to_dev_runs;
    int64_t copy_scalar_to_dev_total_runtime;
    int copy_scalar_to_dev_runs;
    int64_t copy_scalar_from_dev_total_runtime;
    int copy_scalar_from_dev_runs;
    CUdeviceptr global_failure;
    CUdeviceptr global_failure_args;
    struct cuda_context cuda;
    struct tuning_params tuning_params;
    int32_t failure_is_an_option;
    int total_runs;
    long total_runtime;
};
struct futhark_context *futhark_context_new(struct futhark_context_config *cfg)
{
    assert(!cfg->in_use);
    
    struct futhark_context *ctx =
                           (struct futhark_context *) malloc(sizeof(struct futhark_context));
    
    if (ctx == NULL)
        return NULL;
    ctx->cfg = cfg;
    ctx->cfg->in_use = 1;
    ctx->debugging = ctx->detail_memory = cfg->cu_cfg.debugging;
    ctx->profiling = cfg->profiling;
    ctx->profiling_paused = 0;
    ctx->logging = cfg->cu_cfg.logging;
    ctx->error = NULL;
    ctx->log = stderr;
    ctx->cuda.profiling_records_capacity = 200;
    ctx->cuda.profiling_records_used = 0;
    ctx->cuda.profiling_records = malloc(ctx->cuda.profiling_records_capacity *
        sizeof(struct profiling_record));
    ctx->cuda.cfg = cfg->cu_cfg;
    create_lock(&ctx->lock);
    ctx->failure_is_an_option = 0;
    ctx->total_runs = 0;
    ctx->total_runtime = 0;
    ctx->peak_mem_usage_device = 0;
    ctx->cur_mem_usage_device = 0;
    ctx->peak_mem_usage_default = 0;
    ctx->cur_mem_usage_default = 0;
    ctx->error = cuda_setup(&ctx->cuda, cuda_program, cfg->nvrtc_opts);
    if (ctx->error != NULL)
        return NULL;
    
    int32_t no_error = -1;
    
    CUDA_SUCCEED_FATAL(cuMemAlloc(&ctx->global_failure, sizeof(no_error)));
    CUDA_SUCCEED_FATAL(cuMemcpyHtoD(ctx->global_failure, &no_error,
                                    sizeof(no_error)));
    // The +1 is to avoid zero-byte allocations.
    CUDA_SUCCEED_FATAL(cuMemAlloc(&ctx->global_failure_args, sizeof(int64_t) *
                                  (4 + 1)));
    CUDA_SUCCEED_FATAL(cuModuleGetFunction(&ctx->bicubicInterpolationImagezisegmap_16062,
                                           ctx->cuda.module,
                                           "bicubicInterpolationImagezisegmap_16062"));
    ctx->bicubicInterpolationImagezisegmap_16062_total_runtime = 0;
    ctx->bicubicInterpolationImagezisegmap_16062_runs = 0;
    CUDA_SUCCEED_FATAL(cuModuleGetFunction(&ctx->bicubicInterpolationImagezisegmap_16083,
                                           ctx->cuda.module,
                                           "bicubicInterpolationImagezisegmap_16083"));
    ctx->bicubicInterpolationImagezisegmap_16083_total_runtime = 0;
    ctx->bicubicInterpolationImagezisegmap_16083_runs = 0;
    CUDA_SUCCEED_FATAL(cuModuleGetFunction(&ctx->bicubicInterpolationImagezisegmap_16106,
                                           ctx->cuda.module,
                                           "bicubicInterpolationImagezisegmap_16106"));
    ctx->bicubicInterpolationImagezisegmap_16106_total_runtime = 0;
    ctx->bicubicInterpolationImagezisegmap_16106_runs = 0;
    CUDA_SUCCEED_FATAL(cuModuleGetFunction(&ctx->bicubicInterpolationImagezisegmap_16146,
                                           ctx->cuda.module,
                                           "bicubicInterpolationImagezisegmap_16146"));
    ctx->bicubicInterpolationImagezisegmap_16146_total_runtime = 0;
    ctx->bicubicInterpolationImagezisegmap_16146_runs = 0;
    CUDA_SUCCEED_FATAL(cuModuleGetFunction(&ctx->bicubicInterpolationImagezisegmap_16170,
                                           ctx->cuda.module,
                                           "bicubicInterpolationImagezisegmap_16170"));
    ctx->bicubicInterpolationImagezisegmap_16170_total_runtime = 0;
    ctx->bicubicInterpolationImagezisegmap_16170_runs = 0;
    CUDA_SUCCEED_FATAL(cuModuleGetFunction(&ctx->bicubicInterpolationImagezisegmap_16200,
                                           ctx->cuda.module,
                                           "bicubicInterpolationImagezisegmap_16200"));
    ctx->bicubicInterpolationImagezisegmap_16200_total_runtime = 0;
    ctx->bicubicInterpolationImagezisegmap_16200_runs = 0;
    CUDA_SUCCEED_FATAL(cuModuleGetFunction(&ctx->bicubicInterpolationImagezisegmap_16240,
                                           ctx->cuda.module,
                                           "bicubicInterpolationImagezisegmap_16240"));
    ctx->bicubicInterpolationImagezisegmap_16240_total_runtime = 0;
    ctx->bicubicInterpolationImagezisegmap_16240_runs = 0;
    CUDA_SUCCEED_FATAL(cuModuleGetFunction(&ctx->bicubicInterpolationImagezisegmap_16442,
                                           ctx->cuda.module,
                                           "bicubicInterpolationImagezisegmap_16442"));
    ctx->bicubicInterpolationImagezisegmap_16442_total_runtime = 0;
    ctx->bicubicInterpolationImagezisegmap_16442_runs = 0;
    CUDA_SUCCEED_FATAL(cuModuleGetFunction(&ctx->bicubicInterpolationImagezisegmap_intragroup_14985,
                                           ctx->cuda.module,
                                           "bicubicInterpolationImagezisegmap_intragroup_14985"));
    ctx->bicubicInterpolationImagezisegmap_intragroup_14985_total_runtime = 0;
    ctx->bicubicInterpolationImagezisegmap_intragroup_14985_runs = 0;
    CUDA_SUCCEED_FATAL(cuModuleGetFunction(&ctx->builtinzhiota_i64ziiota_i64_16801,
                                           ctx->cuda.module,
                                           "builtinzhiota_i64ziiota_i64_16801"));
    ctx->builtinzhiota_i64ziiota_i64_16801_total_runtime = 0;
    ctx->builtinzhiota_i64ziiota_i64_16801_runs = 0;
    CUDA_SUCCEED_FATAL(cuModuleGetFunction(&ctx->gpu_map_transpose_f32,
                                           ctx->cuda.module,
                                           "gpu_map_transpose_f32"));
    ctx->gpu_map_transpose_f32_total_runtime = 0;
    ctx->gpu_map_transpose_f32_runs = 0;
    CUDA_SUCCEED_FATAL(cuModuleGetFunction(&ctx->gpu_map_transpose_f32_low_height,
                                           ctx->cuda.module,
                                           "gpu_map_transpose_f32_low_height"));
    ctx->gpu_map_transpose_f32_low_height_total_runtime = 0;
    ctx->gpu_map_transpose_f32_low_height_runs = 0;
    CUDA_SUCCEED_FATAL(cuModuleGetFunction(&ctx->gpu_map_transpose_f32_low_width,
                                           ctx->cuda.module,
                                           "gpu_map_transpose_f32_low_width"));
    ctx->gpu_map_transpose_f32_low_width_total_runtime = 0;
    ctx->gpu_map_transpose_f32_low_width_runs = 0;
    CUDA_SUCCEED_FATAL(cuModuleGetFunction(&ctx->gpu_map_transpose_f32_small,
                                           ctx->cuda.module,
                                           "gpu_map_transpose_f32_small"));
    ctx->gpu_map_transpose_f32_small_total_runtime = 0;
    ctx->gpu_map_transpose_f32_small_runs = 0;
    CUDA_SUCCEED_FATAL(cuModuleGetFunction(&ctx->gpu_map_transpose_i64,
                                           ctx->cuda.module,
                                           "gpu_map_transpose_i64"));
    ctx->gpu_map_transpose_i64_total_runtime = 0;
    ctx->gpu_map_transpose_i64_runs = 0;
    CUDA_SUCCEED_FATAL(cuModuleGetFunction(&ctx->gpu_map_transpose_i64_low_height,
                                           ctx->cuda.module,
                                           "gpu_map_transpose_i64_low_height"));
    ctx->gpu_map_transpose_i64_low_height_total_runtime = 0;
    ctx->gpu_map_transpose_i64_low_height_runs = 0;
    CUDA_SUCCEED_FATAL(cuModuleGetFunction(&ctx->gpu_map_transpose_i64_low_width,
                                           ctx->cuda.module,
                                           "gpu_map_transpose_i64_low_width"));
    ctx->gpu_map_transpose_i64_low_width_total_runtime = 0;
    ctx->gpu_map_transpose_i64_low_width_runs = 0;
    CUDA_SUCCEED_FATAL(cuModuleGetFunction(&ctx->gpu_map_transpose_i64_small,
                                           ctx->cuda.module,
                                           "gpu_map_transpose_i64_small"));
    ctx->gpu_map_transpose_i64_small_total_runtime = 0;
    ctx->gpu_map_transpose_i64_small_runs = 0;
    CUDA_SUCCEED_FATAL(cuModuleGetFunction(&ctx->shufflerzireplicate_16806,
                                           ctx->cuda.module,
                                           "shufflerzireplicate_16806"));
    ctx->shufflerzireplicate_16806_total_runtime = 0;
    ctx->shufflerzireplicate_16806_runs = 0;
    CUDA_SUCCEED_FATAL(cuModuleGetFunction(&ctx->shufflerzisegmap_16500,
                                           ctx->cuda.module,
                                           "shufflerzisegmap_16500"));
    ctx->shufflerzisegmap_16500_total_runtime = 0;
    ctx->shufflerzisegmap_16500_runs = 0;
    CUDA_SUCCEED_FATAL(cuModuleGetFunction(&ctx->shufflerzisegmap_16555,
                                           ctx->cuda.module,
                                           "shufflerzisegmap_16555"));
    ctx->shufflerzisegmap_16555_total_runtime = 0;
    ctx->shufflerzisegmap_16555_runs = 0;
    ctx->copy_dev_to_dev_total_runtime = 0;
    ctx->copy_dev_to_dev_runs = 0;
    ctx->copy_dev_to_host_total_runtime = 0;
    ctx->copy_dev_to_host_runs = 0;
    ctx->copy_host_to_dev_total_runtime = 0;
    ctx->copy_host_to_dev_runs = 0;
    ctx->copy_scalar_to_dev_total_runtime = 0;
    ctx->copy_scalar_to_dev_runs = 0;
    ctx->copy_scalar_from_dev_total_runtime = 0;
    ctx->copy_scalar_from_dev_runs = 0;
    ctx->tuning_params.bicubicInterpolationImagezisegmap_group_sizze_15175 =
        &cfg->tuning_params[0];
    ctx->tuning_params.bicubicInterpolationImagezisegmap_group_sizze_15228 =
        &cfg->tuning_params[1];
    ctx->tuning_params.bicubicInterpolationImagezisegmap_group_sizze_15313 =
        &cfg->tuning_params[2];
    ctx->tuning_params.bicubicInterpolationImagezisegmap_group_sizze_15437 =
        &cfg->tuning_params[3];
    ctx->tuning_params.bicubicInterpolationImagezisegmap_group_sizze_15623 =
        &cfg->tuning_params[4];
    ctx->tuning_params.bicubicInterpolationImagezisegmap_group_sizze_15696 =
        &cfg->tuning_params[5];
    ctx->tuning_params.bicubicInterpolationImagezisegmap_group_sizze_15770 =
        &cfg->tuning_params[6];
    ctx->tuning_params.bicubicInterpolationImagezisegmap_group_sizze_16293 =
        &cfg->tuning_params[7];
    ctx->tuning_params.bicubicInterpolationImagezisuff_intra_par_0 =
        &cfg->tuning_params[8];
    ctx->tuning_params.builtinzhiota_i64zigroup_sizze_16804 =
        &cfg->tuning_params[9];
    ctx->tuning_params.shufflerzigroup_sizze_16809 = &cfg->tuning_params[10];
    ctx->tuning_params.shufflerzisegmap_group_sizze_16471 =
        &cfg->tuning_params[11];
    ctx->tuning_params.shufflerzisegmap_group_sizze_16519 =
        &cfg->tuning_params[12];
    ctx->tuning_params.shufflerzisegmap_num_groups_16521 =
        &cfg->tuning_params[13];
    init_constants(ctx);
    // Clear the free list of any deallocations that occurred while initialising constants.
    CUDA_SUCCEED_FATAL(cuda_free_all(&ctx->cuda));
    futhark_context_sync(ctx);
    return ctx;
}
void futhark_context_free(struct futhark_context *ctx)
{
    free_constants(ctx);
    cuda_cleanup(&ctx->cuda);
    free_lock(&ctx->lock);
    ctx->cfg->in_use = 0;
    free(ctx);
}
int futhark_context_sync(struct futhark_context *ctx)
{
    CUDA_SUCCEED_OR_RETURN(cuCtxPushCurrent(ctx->cuda.cu_ctx));
    CUDA_SUCCEED_OR_RETURN(cuCtxSynchronize());
    if (ctx->failure_is_an_option) {
        int32_t failure_idx;
        
        CUDA_SUCCEED_OR_RETURN(cuMemcpyDtoH(&failure_idx, ctx->global_failure,
                                            sizeof(int32_t)));
        ctx->failure_is_an_option = 0;
        if (failure_idx >= 0) {
            int32_t no_failure = -1;
            
            CUDA_SUCCEED_OR_RETURN(cuMemcpyHtoD(ctx->global_failure,
                                                &no_failure, sizeof(int32_t)));
            
            int64_t args[4 + 1];
            
            CUDA_SUCCEED_OR_RETURN(cuMemcpyDtoH(&args, ctx->global_failure_args,
                                                sizeof(args)));
            switch (failure_idx) {
                
              case 0:
                {
                    ctx->error =
                        msgprintf("Index [%lld, %lld] out of bounds for array of shape [%lld][%lld].\n-> #0  fut/bicubic.fut:34:17-36:22\n   #1  /prelude/soacs.fut:59:3-10\n   #2  /prelude/array.fut:195:3-17\n   #3  /prelude/functional.fut:39:59-65\n   #4  /prelude/soacs.fut:59:3-10\n   #5  /prelude/array.fut:203:3-34\n   #6  /prelude/functional.fut:39:59-65\n   #7  /prelude/soacs.fut:59:3-10\n   #8  /prelude/array.fut:211:3-39\n   #9  fut/bicubic.fut:27:9-37:9\n   #10 fut/bicubic.fut:52:36-89\n   #11 /prelude/soacs.fut:59:3-10\n   #12 /prelude/array.fut:195:3-17\n   #13 fut/bicubic.fut:52:18-90\n   #14 fut/entries.fut:16:7-51\n   #15 fut/entries.fut:15:1-16:51\n",
                                  args[0], args[1], args[2], args[3]);
                    break;
                }
                
              case 1:
                {
                    ctx->error =
                        msgprintf("Index [%lld, %lld] out of bounds for array of shape [%lld][%lld].\n-> #0  fut/bicubic.fut:34:17-36:22\n   #1  /prelude/soacs.fut:59:3-10\n   #2  /prelude/array.fut:195:3-17\n   #3  /prelude/functional.fut:39:59-65\n   #4  /prelude/soacs.fut:59:3-10\n   #5  /prelude/array.fut:203:3-34\n   #6  /prelude/functional.fut:39:59-65\n   #7  /prelude/soacs.fut:59:3-10\n   #8  /prelude/array.fut:211:3-39\n   #9  fut/bicubic.fut:27:9-37:9\n   #10 fut/bicubic.fut:52:36-89\n   #11 /prelude/soacs.fut:59:3-10\n   #12 /prelude/array.fut:195:3-17\n   #13 fut/bicubic.fut:52:18-90\n   #14 fut/entries.fut:16:7-51\n   #15 fut/entries.fut:15:1-16:51\n",
                                  args[0], args[1], args[2], args[3]);
                    break;
                }
            }
            return 1;
        }
    }
    CUDA_SUCCEED_OR_RETURN(cuCtxPopCurrent(&ctx->cuda.cu_ctx));
    return 0;
}
static int memblock_unref_device(struct futhark_context *ctx,
                                 struct memblock_device *block, const
                                 char *desc)
{
    if (block->references != NULL) {
        *block->references -= 1;
        if (ctx->detail_memory)
            fprintf(ctx->log,
                    "Unreferencing block %s (allocated as %s) in %s: %d references remaining.\n",
                    desc, block->desc, "space 'device'", *block->references);
        if (*block->references == 0) {
            ctx->cur_mem_usage_device -= block->size;
            CUDA_SUCCEED_OR_RETURN(cuda_free(&ctx->cuda, block->mem, desc));
            free(block->references);
            if (ctx->detail_memory)
                fprintf(ctx->log,
                        "%lld bytes freed (now allocated: %lld bytes)\n",
                        (long long) block->size,
                        (long long) ctx->cur_mem_usage_device);
        }
        block->references = NULL;
    }
    return 0;
}
static int memblock_alloc_device(struct futhark_context *ctx,
                                 struct memblock_device *block, int64_t size,
                                 const char *desc)
{
    if (size < 0)
        futhark_panic(1,
                      "Negative allocation of %lld bytes attempted for %s in %s.\n",
                      (long long) size, desc, "space 'device'",
                      ctx->cur_mem_usage_device);
    
    int ret = memblock_unref_device(ctx, block, desc);
    
    ctx->cur_mem_usage_device += size;
    if (ctx->detail_memory)
        fprintf(ctx->log,
                "Allocating %lld bytes for %s in %s (then allocated: %lld bytes)",
                (long long) size, desc, "space 'device'",
                (long long) ctx->cur_mem_usage_device);
    if (ctx->cur_mem_usage_device > ctx->peak_mem_usage_device) {
        ctx->peak_mem_usage_device = ctx->cur_mem_usage_device;
        if (ctx->detail_memory)
            fprintf(ctx->log, " (new peak).\n");
    } else if (ctx->detail_memory)
        fprintf(ctx->log, ".\n");
    CUDA_SUCCEED_OR_RETURN(cuda_alloc(&ctx->cuda, (size_t) size, desc,
                                      &block->mem));
    block->references = (int *) malloc(sizeof(int));
    *block->references = 1;
    block->size = size;
    block->desc = desc;
    return ret;
}
static int memblock_set_device(struct futhark_context *ctx,
                               struct memblock_device *lhs,
                               struct memblock_device *rhs, const
                               char *lhs_desc)
{
    int ret = memblock_unref_device(ctx, lhs, lhs_desc);
    
    if (rhs->references != NULL)
        (*rhs->references)++;
    *lhs = *rhs;
    return ret;
}
static int memblock_unref(struct futhark_context *ctx, struct memblock *block,
                          const char *desc)
{
    if (block->references != NULL) {
        *block->references -= 1;
        if (ctx->detail_memory)
            fprintf(ctx->log,
                    "Unreferencing block %s (allocated as %s) in %s: %d references remaining.\n",
                    desc, block->desc, "default space", *block->references);
        if (*block->references == 0) {
            ctx->cur_mem_usage_default -= block->size;
            free(block->mem);
            free(block->references);
            if (ctx->detail_memory)
                fprintf(ctx->log,
                        "%lld bytes freed (now allocated: %lld bytes)\n",
                        (long long) block->size,
                        (long long) ctx->cur_mem_usage_default);
        }
        block->references = NULL;
    }
    return 0;
}
static int memblock_alloc(struct futhark_context *ctx, struct memblock *block,
                          int64_t size, const char *desc)
{
    if (size < 0)
        futhark_panic(1,
                      "Negative allocation of %lld bytes attempted for %s in %s.\n",
                      (long long) size, desc, "default space",
                      ctx->cur_mem_usage_default);
    
    int ret = memblock_unref(ctx, block, desc);
    
    ctx->cur_mem_usage_default += size;
    if (ctx->detail_memory)
        fprintf(ctx->log,
                "Allocating %lld bytes for %s in %s (then allocated: %lld bytes)",
                (long long) size, desc, "default space",
                (long long) ctx->cur_mem_usage_default);
    if (ctx->cur_mem_usage_default > ctx->peak_mem_usage_default) {
        ctx->peak_mem_usage_default = ctx->cur_mem_usage_default;
        if (ctx->detail_memory)
            fprintf(ctx->log, " (new peak).\n");
    } else if (ctx->detail_memory)
        fprintf(ctx->log, ".\n");
    block->mem = (unsigned char *) malloc((size_t) size);
    block->references = (int *) malloc(sizeof(int));
    *block->references = 1;
    block->size = size;
    block->desc = desc;
    return ret;
}
static int memblock_set(struct futhark_context *ctx, struct memblock *lhs,
                        struct memblock *rhs, const char *lhs_desc)
{
    int ret = memblock_unref(ctx, lhs, lhs_desc);
    
    if (rhs->references != NULL)
        (*rhs->references)++;
    *lhs = *rhs;
    return ret;
}
int futhark_get_tuning_param_count(void)
{
    return sizeof(tuning_param_names) / sizeof(tuning_param_names[0]);
}
const char *futhark_get_tuning_param_name(int i)
{
    return tuning_param_names[i];
}
const char *futhark_get_tuning_param_class(int i)
{
    return tuning_param_classes[i];
}
char *futhark_context_report(struct futhark_context *ctx)
{
    if (futhark_context_sync(ctx) != 0)
        return NULL;
    
    struct str_builder builder;
    
    str_builder_init(&builder);
    if (ctx->detail_memory || ctx->profiling || ctx->logging) {
        str_builder(&builder,
                    "Peak memory usage for space 'device': %lld bytes.\n",
                    (long long) ctx->peak_mem_usage_device);
        { }
    }
    if (ctx->profiling) {
        CUDA_SUCCEED_FATAL(cuda_tally_profiling_records(&ctx->cuda));
        str_builder(&builder,
                    "copy_dev_to_dev                                   ran %5d times; avg: %8ldus; total: %8ldus\n",
                    ctx->copy_dev_to_dev_runs,
                    (long) ctx->copy_dev_to_dev_total_runtime /
                    (ctx->copy_dev_to_dev_runs !=
                     0 ? ctx->copy_dev_to_dev_runs : 1),
                    (long) ctx->copy_dev_to_dev_total_runtime);
        ctx->total_runtime += ctx->copy_dev_to_dev_total_runtime;
        ctx->total_runs += ctx->copy_dev_to_dev_runs;
        str_builder(&builder,
                    "copy_dev_to_host                                  ran %5d times; avg: %8ldus; total: %8ldus\n",
                    ctx->copy_dev_to_host_runs,
                    (long) ctx->copy_dev_to_host_total_runtime /
                    (ctx->copy_dev_to_host_runs !=
                     0 ? ctx->copy_dev_to_host_runs : 1),
                    (long) ctx->copy_dev_to_host_total_runtime);
        ctx->total_runtime += ctx->copy_dev_to_host_total_runtime;
        ctx->total_runs += ctx->copy_dev_to_host_runs;
        str_builder(&builder,
                    "copy_host_to_dev                                  ran %5d times; avg: %8ldus; total: %8ldus\n",
                    ctx->copy_host_to_dev_runs,
                    (long) ctx->copy_host_to_dev_total_runtime /
                    (ctx->copy_host_to_dev_runs !=
                     0 ? ctx->copy_host_to_dev_runs : 1),
                    (long) ctx->copy_host_to_dev_total_runtime);
        ctx->total_runtime += ctx->copy_host_to_dev_total_runtime;
        ctx->total_runs += ctx->copy_host_to_dev_runs;
        str_builder(&builder,
                    "copy_scalar_to_dev                                ran %5d times; avg: %8ldus; total: %8ldus\n",
                    ctx->copy_scalar_to_dev_runs,
                    (long) ctx->copy_scalar_to_dev_total_runtime /
                    (ctx->copy_scalar_to_dev_runs !=
                     0 ? ctx->copy_scalar_to_dev_runs : 1),
                    (long) ctx->copy_scalar_to_dev_total_runtime);
        ctx->total_runtime += ctx->copy_scalar_to_dev_total_runtime;
        ctx->total_runs += ctx->copy_scalar_to_dev_runs;
        str_builder(&builder,
                    "copy_scalar_from_dev                              ran %5d times; avg: %8ldus; total: %8ldus\n",
                    ctx->copy_scalar_from_dev_runs,
                    (long) ctx->copy_scalar_from_dev_total_runtime /
                    (ctx->copy_scalar_from_dev_runs !=
                     0 ? ctx->copy_scalar_from_dev_runs : 1),
                    (long) ctx->copy_scalar_from_dev_total_runtime);
        ctx->total_runtime += ctx->copy_scalar_from_dev_total_runtime;
        ctx->total_runs += ctx->copy_scalar_from_dev_runs;
        str_builder(&builder,
                    "bicubicInterpolationImage.segmap_16062            ran %5d times; avg: %8ldus; total: %8ldus\n",
                    ctx->bicubicInterpolationImagezisegmap_16062_runs,
                    (long) ctx->bicubicInterpolationImagezisegmap_16062_total_runtime /
                    (ctx->bicubicInterpolationImagezisegmap_16062_runs !=
                     0 ? ctx->bicubicInterpolationImagezisegmap_16062_runs : 1),
                    (long) ctx->bicubicInterpolationImagezisegmap_16062_total_runtime);
        ctx->total_runtime +=
            ctx->bicubicInterpolationImagezisegmap_16062_total_runtime;
        ctx->total_runs += ctx->bicubicInterpolationImagezisegmap_16062_runs;
        str_builder(&builder,
                    "bicubicInterpolationImage.segmap_16083            ran %5d times; avg: %8ldus; total: %8ldus\n",
                    ctx->bicubicInterpolationImagezisegmap_16083_runs,
                    (long) ctx->bicubicInterpolationImagezisegmap_16083_total_runtime /
                    (ctx->bicubicInterpolationImagezisegmap_16083_runs !=
                     0 ? ctx->bicubicInterpolationImagezisegmap_16083_runs : 1),
                    (long) ctx->bicubicInterpolationImagezisegmap_16083_total_runtime);
        ctx->total_runtime +=
            ctx->bicubicInterpolationImagezisegmap_16083_total_runtime;
        ctx->total_runs += ctx->bicubicInterpolationImagezisegmap_16083_runs;
        str_builder(&builder,
                    "bicubicInterpolationImage.segmap_16106            ran %5d times; avg: %8ldus; total: %8ldus\n",
                    ctx->bicubicInterpolationImagezisegmap_16106_runs,
                    (long) ctx->bicubicInterpolationImagezisegmap_16106_total_runtime /
                    (ctx->bicubicInterpolationImagezisegmap_16106_runs !=
                     0 ? ctx->bicubicInterpolationImagezisegmap_16106_runs : 1),
                    (long) ctx->bicubicInterpolationImagezisegmap_16106_total_runtime);
        ctx->total_runtime +=
            ctx->bicubicInterpolationImagezisegmap_16106_total_runtime;
        ctx->total_runs += ctx->bicubicInterpolationImagezisegmap_16106_runs;
        str_builder(&builder,
                    "bicubicInterpolationImage.segmap_16146            ran %5d times; avg: %8ldus; total: %8ldus\n",
                    ctx->bicubicInterpolationImagezisegmap_16146_runs,
                    (long) ctx->bicubicInterpolationImagezisegmap_16146_total_runtime /
                    (ctx->bicubicInterpolationImagezisegmap_16146_runs !=
                     0 ? ctx->bicubicInterpolationImagezisegmap_16146_runs : 1),
                    (long) ctx->bicubicInterpolationImagezisegmap_16146_total_runtime);
        ctx->total_runtime +=
            ctx->bicubicInterpolationImagezisegmap_16146_total_runtime;
        ctx->total_runs += ctx->bicubicInterpolationImagezisegmap_16146_runs;
        str_builder(&builder,
                    "bicubicInterpolationImage.segmap_16170            ran %5d times; avg: %8ldus; total: %8ldus\n",
                    ctx->bicubicInterpolationImagezisegmap_16170_runs,
                    (long) ctx->bicubicInterpolationImagezisegmap_16170_total_runtime /
                    (ctx->bicubicInterpolationImagezisegmap_16170_runs !=
                     0 ? ctx->bicubicInterpolationImagezisegmap_16170_runs : 1),
                    (long) ctx->bicubicInterpolationImagezisegmap_16170_total_runtime);
        ctx->total_runtime +=
            ctx->bicubicInterpolationImagezisegmap_16170_total_runtime;
        ctx->total_runs += ctx->bicubicInterpolationImagezisegmap_16170_runs;
        str_builder(&builder,
                    "bicubicInterpolationImage.segmap_16200            ran %5d times; avg: %8ldus; total: %8ldus\n",
                    ctx->bicubicInterpolationImagezisegmap_16200_runs,
                    (long) ctx->bicubicInterpolationImagezisegmap_16200_total_runtime /
                    (ctx->bicubicInterpolationImagezisegmap_16200_runs !=
                     0 ? ctx->bicubicInterpolationImagezisegmap_16200_runs : 1),
                    (long) ctx->bicubicInterpolationImagezisegmap_16200_total_runtime);
        ctx->total_runtime +=
            ctx->bicubicInterpolationImagezisegmap_16200_total_runtime;
        ctx->total_runs += ctx->bicubicInterpolationImagezisegmap_16200_runs;
        str_builder(&builder,
                    "bicubicInterpolationImage.segmap_16240            ran %5d times; avg: %8ldus; total: %8ldus\n",
                    ctx->bicubicInterpolationImagezisegmap_16240_runs,
                    (long) ctx->bicubicInterpolationImagezisegmap_16240_total_runtime /
                    (ctx->bicubicInterpolationImagezisegmap_16240_runs !=
                     0 ? ctx->bicubicInterpolationImagezisegmap_16240_runs : 1),
                    (long) ctx->bicubicInterpolationImagezisegmap_16240_total_runtime);
        ctx->total_runtime +=
            ctx->bicubicInterpolationImagezisegmap_16240_total_runtime;
        ctx->total_runs += ctx->bicubicInterpolationImagezisegmap_16240_runs;
        str_builder(&builder,
                    "bicubicInterpolationImage.segmap_16442            ran %5d times; avg: %8ldus; total: %8ldus\n",
                    ctx->bicubicInterpolationImagezisegmap_16442_runs,
                    (long) ctx->bicubicInterpolationImagezisegmap_16442_total_runtime /
                    (ctx->bicubicInterpolationImagezisegmap_16442_runs !=
                     0 ? ctx->bicubicInterpolationImagezisegmap_16442_runs : 1),
                    (long) ctx->bicubicInterpolationImagezisegmap_16442_total_runtime);
        ctx->total_runtime +=
            ctx->bicubicInterpolationImagezisegmap_16442_total_runtime;
        ctx->total_runs += ctx->bicubicInterpolationImagezisegmap_16442_runs;
        str_builder(&builder,
                    "bicubicInterpolationImage.segmap_intragroup_14985 ran %5d times; avg: %8ldus; total: %8ldus\n",
                    ctx->bicubicInterpolationImagezisegmap_intragroup_14985_runs,
                    (long) ctx->bicubicInterpolationImagezisegmap_intragroup_14985_total_runtime /
                    (ctx->bicubicInterpolationImagezisegmap_intragroup_14985_runs !=
                     0 ? ctx->bicubicInterpolationImagezisegmap_intragroup_14985_runs : 1),
                    (long) ctx->bicubicInterpolationImagezisegmap_intragroup_14985_total_runtime);
        ctx->total_runtime +=
            ctx->bicubicInterpolationImagezisegmap_intragroup_14985_total_runtime;
        ctx->total_runs +=
            ctx->bicubicInterpolationImagezisegmap_intragroup_14985_runs;
        str_builder(&builder,
                    "builtin#iota_i64.iota_i64_16801                   ran %5d times; avg: %8ldus; total: %8ldus\n",
                    ctx->builtinzhiota_i64ziiota_i64_16801_runs,
                    (long) ctx->builtinzhiota_i64ziiota_i64_16801_total_runtime /
                    (ctx->builtinzhiota_i64ziiota_i64_16801_runs !=
                     0 ? ctx->builtinzhiota_i64ziiota_i64_16801_runs : 1),
                    (long) ctx->builtinzhiota_i64ziiota_i64_16801_total_runtime);
        ctx->total_runtime +=
            ctx->builtinzhiota_i64ziiota_i64_16801_total_runtime;
        ctx->total_runs += ctx->builtinzhiota_i64ziiota_i64_16801_runs;
        str_builder(&builder,
                    "gpu_map_transpose_f32                             ran %5d times; avg: %8ldus; total: %8ldus\n",
                    ctx->gpu_map_transpose_f32_runs,
                    (long) ctx->gpu_map_transpose_f32_total_runtime /
                    (ctx->gpu_map_transpose_f32_runs !=
                     0 ? ctx->gpu_map_transpose_f32_runs : 1),
                    (long) ctx->gpu_map_transpose_f32_total_runtime);
        ctx->total_runtime += ctx->gpu_map_transpose_f32_total_runtime;
        ctx->total_runs += ctx->gpu_map_transpose_f32_runs;
        str_builder(&builder,
                    "gpu_map_transpose_f32_low_height                  ran %5d times; avg: %8ldus; total: %8ldus\n",
                    ctx->gpu_map_transpose_f32_low_height_runs,
                    (long) ctx->gpu_map_transpose_f32_low_height_total_runtime /
                    (ctx->gpu_map_transpose_f32_low_height_runs !=
                     0 ? ctx->gpu_map_transpose_f32_low_height_runs : 1),
                    (long) ctx->gpu_map_transpose_f32_low_height_total_runtime);
        ctx->total_runtime +=
            ctx->gpu_map_transpose_f32_low_height_total_runtime;
        ctx->total_runs += ctx->gpu_map_transpose_f32_low_height_runs;
        str_builder(&builder,
                    "gpu_map_transpose_f32_low_width                   ran %5d times; avg: %8ldus; total: %8ldus\n",
                    ctx->gpu_map_transpose_f32_low_width_runs,
                    (long) ctx->gpu_map_transpose_f32_low_width_total_runtime /
                    (ctx->gpu_map_transpose_f32_low_width_runs !=
                     0 ? ctx->gpu_map_transpose_f32_low_width_runs : 1),
                    (long) ctx->gpu_map_transpose_f32_low_width_total_runtime);
        ctx->total_runtime +=
            ctx->gpu_map_transpose_f32_low_width_total_runtime;
        ctx->total_runs += ctx->gpu_map_transpose_f32_low_width_runs;
        str_builder(&builder,
                    "gpu_map_transpose_f32_small                       ran %5d times; avg: %8ldus; total: %8ldus\n",
                    ctx->gpu_map_transpose_f32_small_runs,
                    (long) ctx->gpu_map_transpose_f32_small_total_runtime /
                    (ctx->gpu_map_transpose_f32_small_runs !=
                     0 ? ctx->gpu_map_transpose_f32_small_runs : 1),
                    (long) ctx->gpu_map_transpose_f32_small_total_runtime);
        ctx->total_runtime += ctx->gpu_map_transpose_f32_small_total_runtime;
        ctx->total_runs += ctx->gpu_map_transpose_f32_small_runs;
        str_builder(&builder,
                    "gpu_map_transpose_i64                             ran %5d times; avg: %8ldus; total: %8ldus\n",
                    ctx->gpu_map_transpose_i64_runs,
                    (long) ctx->gpu_map_transpose_i64_total_runtime /
                    (ctx->gpu_map_transpose_i64_runs !=
                     0 ? ctx->gpu_map_transpose_i64_runs : 1),
                    (long) ctx->gpu_map_transpose_i64_total_runtime);
        ctx->total_runtime += ctx->gpu_map_transpose_i64_total_runtime;
        ctx->total_runs += ctx->gpu_map_transpose_i64_runs;
        str_builder(&builder,
                    "gpu_map_transpose_i64_low_height                  ran %5d times; avg: %8ldus; total: %8ldus\n",
                    ctx->gpu_map_transpose_i64_low_height_runs,
                    (long) ctx->gpu_map_transpose_i64_low_height_total_runtime /
                    (ctx->gpu_map_transpose_i64_low_height_runs !=
                     0 ? ctx->gpu_map_transpose_i64_low_height_runs : 1),
                    (long) ctx->gpu_map_transpose_i64_low_height_total_runtime);
        ctx->total_runtime +=
            ctx->gpu_map_transpose_i64_low_height_total_runtime;
        ctx->total_runs += ctx->gpu_map_transpose_i64_low_height_runs;
        str_builder(&builder,
                    "gpu_map_transpose_i64_low_width                   ran %5d times; avg: %8ldus; total: %8ldus\n",
                    ctx->gpu_map_transpose_i64_low_width_runs,
                    (long) ctx->gpu_map_transpose_i64_low_width_total_runtime /
                    (ctx->gpu_map_transpose_i64_low_width_runs !=
                     0 ? ctx->gpu_map_transpose_i64_low_width_runs : 1),
                    (long) ctx->gpu_map_transpose_i64_low_width_total_runtime);
        ctx->total_runtime +=
            ctx->gpu_map_transpose_i64_low_width_total_runtime;
        ctx->total_runs += ctx->gpu_map_transpose_i64_low_width_runs;
        str_builder(&builder,
                    "gpu_map_transpose_i64_small                       ran %5d times; avg: %8ldus; total: %8ldus\n",
                    ctx->gpu_map_transpose_i64_small_runs,
                    (long) ctx->gpu_map_transpose_i64_small_total_runtime /
                    (ctx->gpu_map_transpose_i64_small_runs !=
                     0 ? ctx->gpu_map_transpose_i64_small_runs : 1),
                    (long) ctx->gpu_map_transpose_i64_small_total_runtime);
        ctx->total_runtime += ctx->gpu_map_transpose_i64_small_total_runtime;
        ctx->total_runs += ctx->gpu_map_transpose_i64_small_runs;
        str_builder(&builder,
                    "shuffler.replicate_16806                          ran %5d times; avg: %8ldus; total: %8ldus\n",
                    ctx->shufflerzireplicate_16806_runs,
                    (long) ctx->shufflerzireplicate_16806_total_runtime /
                    (ctx->shufflerzireplicate_16806_runs !=
                     0 ? ctx->shufflerzireplicate_16806_runs : 1),
                    (long) ctx->shufflerzireplicate_16806_total_runtime);
        ctx->total_runtime += ctx->shufflerzireplicate_16806_total_runtime;
        ctx->total_runs += ctx->shufflerzireplicate_16806_runs;
        str_builder(&builder,
                    "shuffler.segmap_16500                             ran %5d times; avg: %8ldus; total: %8ldus\n",
                    ctx->shufflerzisegmap_16500_runs,
                    (long) ctx->shufflerzisegmap_16500_total_runtime /
                    (ctx->shufflerzisegmap_16500_runs !=
                     0 ? ctx->shufflerzisegmap_16500_runs : 1),
                    (long) ctx->shufflerzisegmap_16500_total_runtime);
        ctx->total_runtime += ctx->shufflerzisegmap_16500_total_runtime;
        ctx->total_runs += ctx->shufflerzisegmap_16500_runs;
        str_builder(&builder,
                    "shuffler.segmap_16555                             ran %5d times; avg: %8ldus; total: %8ldus\n",
                    ctx->shufflerzisegmap_16555_runs,
                    (long) ctx->shufflerzisegmap_16555_total_runtime /
                    (ctx->shufflerzisegmap_16555_runs !=
                     0 ? ctx->shufflerzisegmap_16555_runs : 1),
                    (long) ctx->shufflerzisegmap_16555_total_runtime);
        ctx->total_runtime += ctx->shufflerzisegmap_16555_total_runtime;
        ctx->total_runs += ctx->shufflerzisegmap_16555_runs;
        str_builder(&builder, "%d operations with cumulative runtime: %6ldus\n",
                    ctx->total_runs, ctx->total_runtime);
    }
    return builder.str;
}
char *futhark_context_get_error(struct futhark_context *ctx)
{
    char *error = ctx->error;
    
    ctx->error = NULL;
    return error;
}
void futhark_context_set_logging_file(struct futhark_context *ctx, FILE *f)
{
    ctx->log = f;
}
void futhark_context_pause_profiling(struct futhark_context *ctx)
{
    ctx->profiling_paused = 1;
}
void futhark_context_unpause_profiling(struct futhark_context *ctx)
{
    ctx->profiling_paused = 0;
}
int futhark_context_clear_caches(struct futhark_context *ctx)
{
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cuda.cu_ctx));
    ctx->peak_mem_usage_device = 0;
    ctx->peak_mem_usage_default = 0;
    if (ctx->error == NULL)
        CUDA_SUCCEED_NONFATAL(cuda_free_all(&ctx->cuda));
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cuda.cu_ctx));
    lock_unlock(&ctx->lock);
    return ctx->error != NULL;
}

static int futrts_builtinzhgpu_map_transpose_f32(struct futhark_context *ctx,
                                                 struct memblock_device destmem_0,
                                                 int32_t destoffset_1,
                                                 struct memblock_device srcmem_2,
                                                 int32_t srcoffset_3,
                                                 int32_t num_arrays_4,
                                                 int32_t x_elems_5,
                                                 int32_t y_elems_6);
static int futrts_builtinzhgpu_map_transpose_i64(struct futhark_context *ctx,
                                                 struct memblock_device destmem_0,
                                                 int32_t destoffset_1,
                                                 struct memblock_device srcmem_2,
                                                 int32_t srcoffset_3,
                                                 int32_t num_arrays_4,
                                                 int32_t x_elems_5,
                                                 int32_t y_elems_6);
static int futrts_builtinzhiota_i64(struct futhark_context *ctx,
                                    struct memblock_device mem_16796,
                                    int32_t n_16797, int64_t x_16798,
                                    int64_t s_16799);
static int futrts_entry_bicubicInterpolationImage(struct futhark_context *ctx,
                                                  struct memblock_device *mem_out_p_16989,
                                                  struct memblock_device input_mem_16683,
                                                  int64_t h_14505,
                                                  int64_t w_14506,
                                                  int64_t n_14507,
                                                  int64_t newSizzeY_14508,
                                                  int64_t newSizzeX_14509);
static int futrts_entry_shuffler(struct futhark_context *ctx,
                                 struct memblock_device *mem_out_p_17043,
                                 int64_t seed_14665, int64_t h_14666,
                                 int64_t w_14667);

static int init_constants(struct futhark_context *ctx)
{
    (void) ctx;
    
    int err = 0;
    
    
  cleanup:
    return err;
}
static int free_constants(struct futhark_context *ctx)
{
    (void) ctx;
    return 0;
}
struct futhark_i64_3d {
    struct memblock_device mem;
    int64_t shape[3];
};
struct futhark_i64_3d *futhark_new_i64_3d(struct futhark_context *ctx, const
                                          int64_t *data, int64_t dim0,
                                          int64_t dim1, int64_t dim2)
{
    struct futhark_i64_3d *bad = NULL;
    struct futhark_i64_3d *arr =
                          (struct futhark_i64_3d *) malloc(sizeof(struct futhark_i64_3d));
    
    if (arr == NULL)
        return bad;
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cuda.cu_ctx));
    arr->mem.references = NULL;
    if (memblock_alloc_device(ctx, &arr->mem, dim0 * dim1 * dim2 * 8,
                              "arr->mem"))
        return NULL;
    arr->shape[0] = dim0;
    arr->shape[1] = dim1;
    arr->shape[2] = dim2;
    {
        cudaEvent_t *pevents = NULL;
        
        if (ctx->profiling && !ctx->profiling_paused) {
            pevents = cuda_get_events(&ctx->cuda, &ctx->copy_host_to_dev_runs,
                                      &ctx->copy_host_to_dev_total_runtime);
            CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[0], 0));
        }
        CUDA_SUCCEED_OR_RETURN(cuMemcpyHtoD(arr->mem.mem + 0, data + 0,
                                            (size_t) (dim0 * dim1 * dim2) * 8));
        if (pevents != NULL)
            CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[1], 0));
    }
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cuda.cu_ctx));
    lock_unlock(&ctx->lock);
    return arr;
}
struct futhark_i64_3d *futhark_new_raw_i64_3d(struct futhark_context *ctx, const
                                              CUdeviceptr data, int64_t offset,
                                              int64_t dim0, int64_t dim1,
                                              int64_t dim2)
{
    struct futhark_i64_3d *bad = NULL;
    struct futhark_i64_3d *arr =
                          (struct futhark_i64_3d *) malloc(sizeof(struct futhark_i64_3d));
    
    if (arr == NULL)
        return bad;
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cuda.cu_ctx));
    arr->mem.references = NULL;
    if (memblock_alloc_device(ctx, &arr->mem, dim0 * dim1 * dim2 * 8,
                              "arr->mem"))
        return NULL;
    arr->shape[0] = dim0;
    arr->shape[1] = dim1;
    arr->shape[2] = dim2;
    {
        cudaEvent_t *pevents = NULL;
        
        if (ctx->profiling && !ctx->profiling_paused) {
            pevents = cuda_get_events(&ctx->cuda, &ctx->copy_dev_to_dev_runs,
                                      &ctx->copy_dev_to_dev_total_runtime);
            CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[0], 0));
        }
        CUDA_SUCCEED_OR_RETURN(cuMemcpy(arr->mem.mem + 0, data + offset,
                                        (size_t) (dim0 * dim1 * dim2) * 8));
        if (pevents != NULL)
            CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[1], 0));
    }
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cuda.cu_ctx));
    lock_unlock(&ctx->lock);
    return arr;
}
int futhark_free_i64_3d(struct futhark_context *ctx, struct futhark_i64_3d *arr)
{
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cuda.cu_ctx));
    if (memblock_unref_device(ctx, &arr->mem, "arr->mem") != 0)
        return 1;
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cuda.cu_ctx));
    lock_unlock(&ctx->lock);
    free(arr);
    return 0;
}
int futhark_values_i64_3d(struct futhark_context *ctx,
                          struct futhark_i64_3d *arr, int64_t *data)
{
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cuda.cu_ctx));
    {
        cudaEvent_t *pevents = NULL;
        
        if (ctx->profiling && !ctx->profiling_paused) {
            pevents = cuda_get_events(&ctx->cuda, &ctx->copy_dev_to_host_runs,
                                      &ctx->copy_dev_to_host_total_runtime);
            CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[0], 0));
        }
        CUDA_SUCCEED_OR_RETURN(cuMemcpyDtoH(data + 0, arr->mem.mem + 0,
                                            (size_t) (arr->shape[0] *
                                                      arr->shape[1] *
                                                      arr->shape[2]) * 8));
        if (pevents != NULL)
            CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[1], 0));
    }
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cuda.cu_ctx));
    lock_unlock(&ctx->lock);
    return 0;
}
CUdeviceptr futhark_values_raw_i64_3d(struct futhark_context *ctx,
                                      struct futhark_i64_3d *arr)
{
    (void) ctx;
    return arr->mem.mem;
}
const int64_t *futhark_shape_i64_3d(struct futhark_context *ctx,
                                    struct futhark_i64_3d *arr)
{
    (void) ctx;
    return arr->shape;
}
struct futhark_f32_3d {
    struct memblock_device mem;
    int64_t shape[3];
};
struct futhark_f32_3d *futhark_new_f32_3d(struct futhark_context *ctx, const
                                          float *data, int64_t dim0,
                                          int64_t dim1, int64_t dim2)
{
    struct futhark_f32_3d *bad = NULL;
    struct futhark_f32_3d *arr =
                          (struct futhark_f32_3d *) malloc(sizeof(struct futhark_f32_3d));
    
    if (arr == NULL)
        return bad;
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cuda.cu_ctx));
    arr->mem.references = NULL;
    if (memblock_alloc_device(ctx, &arr->mem, dim0 * dim1 * dim2 * 4,
                              "arr->mem"))
        return NULL;
    arr->shape[0] = dim0;
    arr->shape[1] = dim1;
    arr->shape[2] = dim2;
    {
        cudaEvent_t *pevents = NULL;
        
        if (ctx->profiling && !ctx->profiling_paused) {
            pevents = cuda_get_events(&ctx->cuda, &ctx->copy_host_to_dev_runs,
                                      &ctx->copy_host_to_dev_total_runtime);
            CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[0], 0));
        }
        CUDA_SUCCEED_OR_RETURN(cuMemcpyHtoD(arr->mem.mem + 0, data + 0,
                                            (size_t) (dim0 * dim1 * dim2) * 4));
        if (pevents != NULL)
            CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[1], 0));
    }
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cuda.cu_ctx));
    lock_unlock(&ctx->lock);
    return arr;
}
struct futhark_f32_3d *futhark_new_raw_f32_3d(struct futhark_context *ctx, const
                                              CUdeviceptr data, int64_t offset,
                                              int64_t dim0, int64_t dim1,
                                              int64_t dim2)
{
    struct futhark_f32_3d *bad = NULL;
    struct futhark_f32_3d *arr =
                          (struct futhark_f32_3d *) malloc(sizeof(struct futhark_f32_3d));
    
    if (arr == NULL)
        return bad;
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cuda.cu_ctx));
    arr->mem.references = NULL;
    if (memblock_alloc_device(ctx, &arr->mem, dim0 * dim1 * dim2 * 4,
                              "arr->mem"))
        return NULL;
    arr->shape[0] = dim0;
    arr->shape[1] = dim1;
    arr->shape[2] = dim2;
    {
        cudaEvent_t *pevents = NULL;
        
        if (ctx->profiling && !ctx->profiling_paused) {
            pevents = cuda_get_events(&ctx->cuda, &ctx->copy_dev_to_dev_runs,
                                      &ctx->copy_dev_to_dev_total_runtime);
            CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[0], 0));
        }
        CUDA_SUCCEED_OR_RETURN(cuMemcpy(arr->mem.mem + 0, data + offset,
                                        (size_t) (dim0 * dim1 * dim2) * 4));
        if (pevents != NULL)
            CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[1], 0));
    }
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cuda.cu_ctx));
    lock_unlock(&ctx->lock);
    return arr;
}
int futhark_free_f32_3d(struct futhark_context *ctx, struct futhark_f32_3d *arr)
{
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cuda.cu_ctx));
    if (memblock_unref_device(ctx, &arr->mem, "arr->mem") != 0)
        return 1;
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cuda.cu_ctx));
    lock_unlock(&ctx->lock);
    free(arr);
    return 0;
}
int futhark_values_f32_3d(struct futhark_context *ctx,
                          struct futhark_f32_3d *arr, float *data)
{
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cuda.cu_ctx));
    {
        cudaEvent_t *pevents = NULL;
        
        if (ctx->profiling && !ctx->profiling_paused) {
            pevents = cuda_get_events(&ctx->cuda, &ctx->copy_dev_to_host_runs,
                                      &ctx->copy_dev_to_host_total_runtime);
            CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[0], 0));
        }
        CUDA_SUCCEED_OR_RETURN(cuMemcpyDtoH(data + 0, arr->mem.mem + 0,
                                            (size_t) (arr->shape[0] *
                                                      arr->shape[1] *
                                                      arr->shape[2]) * 4));
        if (pevents != NULL)
            CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[1], 0));
    }
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cuda.cu_ctx));
    lock_unlock(&ctx->lock);
    return 0;
}
CUdeviceptr futhark_values_raw_f32_3d(struct futhark_context *ctx,
                                      struct futhark_f32_3d *arr)
{
    (void) ctx;
    return arr->mem.mem;
}
const int64_t *futhark_shape_f32_3d(struct futhark_context *ctx,
                                    struct futhark_f32_3d *arr)
{
    (void) ctx;
    return arr->shape;
}

static int futrts_builtinzhgpu_map_transpose_f32(struct futhark_context *ctx,
                                                 struct memblock_device destmem_0,
                                                 int32_t destoffset_1,
                                                 struct memblock_device srcmem_2,
                                                 int32_t srcoffset_3,
                                                 int32_t num_arrays_4,
                                                 int32_t x_elems_5,
                                                 int32_t y_elems_6)
{
    (void) ctx;
    
    int err = 0;
    
    if (!(num_arrays_4 == 0 || (x_elems_5 == 0 || y_elems_6 == 0))) {
        int32_t muly_8 = squot32(16, x_elems_5);
        int32_t mulx_7 = squot32(16, y_elems_6);
        
        if (num_arrays_4 == 1 && (x_elems_5 == 1 || y_elems_6 == 1)) {
            {
                cudaEvent_t *pevents = NULL;
                
                if (ctx->profiling && !ctx->profiling_paused) {
                    pevents = cuda_get_events(&ctx->cuda,
                                              &ctx->copy_dev_to_dev_runs,
                                              &ctx->copy_dev_to_dev_total_runtime);
                    CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[0], 0));
                }
                CUDA_SUCCEED_OR_RETURN(cuMemcpy(destmem_0.mem +
                                                sext_i32_i64(destoffset_1),
                                                srcmem_2.mem +
                                                sext_i32_i64(srcoffset_3),
                                                sext_i32_i64(x_elems_5 *
                                                y_elems_6 * 4)));
                if (pevents != NULL)
                    CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[1], 0));
            }
        } else {
            if (sle32(x_elems_5, 8) && slt32(16, y_elems_6)) {
                unsigned int shared_sizze_16932 = (int64_t) 1088;
                CUdeviceptr kernel_arg_16934 = destmem_0.mem;
                CUdeviceptr kernel_arg_16935 = srcmem_2.mem;
                unsigned int shared_offset_16933 = 0;
                
                if ((((((1 && sdiv_up32(x_elems_5, 16) != 0) &&
                        sdiv_up32(sdiv_up32(y_elems_6, muly_8), 16) != 0) &&
                       num_arrays_4 != 0) && 16 != 0) && 16 != 0) && 1 != 0) {
                    int perm[3] = {0, 1, 2};
                    
                    if (sdiv_up32(sdiv_up32(y_elems_6, muly_8), 16) >= 1 <<
                        16) {
                        perm[1] = perm[0];
                        perm[0] = 1;
                    }
                    if (num_arrays_4 >= 1 << 16) {
                        perm[2] = perm[0];
                        perm[0] = 2;
                    }
                    
                    size_t grid[3];
                    
                    grid[perm[0]] = sdiv_up32(x_elems_5, 16);
                    grid[perm[1]] = sdiv_up32(sdiv_up32(y_elems_6, muly_8), 16);
                    grid[perm[2]] = num_arrays_4;
                    
                    void *kernel_args_16929[] = {&perm[0], &perm[1], &perm[2],
                                                 &shared_offset_16933,
                                                 &destoffset_1, &srcoffset_3,
                                                 &num_arrays_4, &x_elems_5,
                                                 &y_elems_6, &mulx_7, &muly_8,
                                                 &kernel_arg_16934,
                                                 &kernel_arg_16935};
                    int64_t time_start_16930 = 0, time_end_16931 = 0;
                    
                    if (ctx->debugging) {
                        fprintf(ctx->log,
                                "Launching %s with grid size [%ld, %ld, %ld] and block size [%ld, %ld, %ld]; shared memory: %d bytes.\n",
                                "gpu_map_transpose_f32_low_width",
                                (long) sdiv_up32(x_elems_5, 16),
                                (long) sdiv_up32(sdiv_up32(y_elems_6, muly_8),
                                                 16), (long) num_arrays_4,
                                (long) 16, (long) 16, (long) 1, (int) (0 +
                                                                       (shared_sizze_16932 +
                                                                        (8 -
                                                                         shared_sizze_16932 %
                                                                         8) %
                                                                        8)));
                        time_start_16930 = get_wall_time();
                    }
                    
                    cudaEvent_t *pevents = NULL;
                    
                    if (ctx->profiling && !ctx->profiling_paused) {
                        pevents = cuda_get_events(&ctx->cuda,
                                                  &ctx->gpu_map_transpose_f32_low_width_runs,
                                                  &ctx->gpu_map_transpose_f32_low_width_total_runtime);
                        CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[0], 0));
                    }
                    CUDA_SUCCEED_OR_RETURN(cuLaunchKernel(ctx->gpu_map_transpose_f32_low_width,
                                                          grid[0], grid[1],
                                                          grid[2], 16, 16, 1,
                                                          0 +
                                                          (shared_sizze_16932 +
                                                           (8 -
                                                            shared_sizze_16932 %
                                                            8) % 8), NULL,
                                                          kernel_args_16929,
                                                          NULL));
                    if (pevents != NULL)
                        CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[1], 0));
                    if (ctx->debugging) {
                        CUDA_SUCCEED_FATAL(cuCtxSynchronize());
                        time_end_16931 = get_wall_time();
                        fprintf(ctx->log, "Kernel %s runtime: %ldus\n",
                                "gpu_map_transpose_f32_low_width",
                                time_end_16931 - time_start_16930);
                    }
                }
            } else {
                if (sle32(y_elems_6, 8) && slt32(16, x_elems_5)) {
                    unsigned int shared_sizze_16939 = (int64_t) 1088;
                    CUdeviceptr kernel_arg_16941 = destmem_0.mem;
                    CUdeviceptr kernel_arg_16942 = srcmem_2.mem;
                    unsigned int shared_offset_16940 = 0;
                    
                    if ((((((1 && sdiv_up32(sdiv_up32(x_elems_5, mulx_7), 16) !=
                             0) && sdiv_up32(y_elems_6, 16) != 0) &&
                           num_arrays_4 != 0) && 16 != 0) && 16 != 0) && 1 !=
                        0) {
                        int perm[3] = {0, 1, 2};
                        
                        if (sdiv_up32(y_elems_6, 16) >= 1 << 16) {
                            perm[1] = perm[0];
                            perm[0] = 1;
                        }
                        if (num_arrays_4 >= 1 << 16) {
                            perm[2] = perm[0];
                            perm[0] = 2;
                        }
                        
                        size_t grid[3];
                        
                        grid[perm[0]] = sdiv_up32(sdiv_up32(x_elems_5, mulx_7),
                                                  16);
                        grid[perm[1]] = sdiv_up32(y_elems_6, 16);
                        grid[perm[2]] = num_arrays_4;
                        
                        void *kernel_args_16936[] = {&perm[0], &perm[1],
                                                     &perm[2],
                                                     &shared_offset_16940,
                                                     &destoffset_1,
                                                     &srcoffset_3,
                                                     &num_arrays_4, &x_elems_5,
                                                     &y_elems_6, &mulx_7,
                                                     &muly_8, &kernel_arg_16941,
                                                     &kernel_arg_16942};
                        int64_t time_start_16937 = 0, time_end_16938 = 0;
                        
                        if (ctx->debugging) {
                            fprintf(ctx->log,
                                    "Launching %s with grid size [%ld, %ld, %ld] and block size [%ld, %ld, %ld]; shared memory: %d bytes.\n",
                                    "gpu_map_transpose_f32_low_height",
                                    (long) sdiv_up32(sdiv_up32(x_elems_5,
                                                               mulx_7), 16),
                                    (long) sdiv_up32(y_elems_6, 16),
                                    (long) num_arrays_4, (long) 16, (long) 16,
                                    (long) 1, (int) (0 + (shared_sizze_16939 +
                                                          (8 -
                                                           shared_sizze_16939 %
                                                           8) % 8)));
                            time_start_16937 = get_wall_time();
                        }
                        
                        cudaEvent_t *pevents = NULL;
                        
                        if (ctx->profiling && !ctx->profiling_paused) {
                            pevents = cuda_get_events(&ctx->cuda,
                                                      &ctx->gpu_map_transpose_f32_low_height_runs,
                                                      &ctx->gpu_map_transpose_f32_low_height_total_runtime);
                            CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[0], 0));
                        }
                        CUDA_SUCCEED_OR_RETURN(cuLaunchKernel(ctx->gpu_map_transpose_f32_low_height,
                                                              grid[0], grid[1],
                                                              grid[2], 16, 16,
                                                              1, 0 +
                                                              (shared_sizze_16939 +
                                                               (8 -
                                                                shared_sizze_16939 %
                                                                8) % 8), NULL,
                                                              kernel_args_16936,
                                                              NULL));
                        if (pevents != NULL)
                            CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[1], 0));
                        if (ctx->debugging) {
                            CUDA_SUCCEED_FATAL(cuCtxSynchronize());
                            time_end_16938 = get_wall_time();
                            fprintf(ctx->log, "Kernel %s runtime: %ldus\n",
                                    "gpu_map_transpose_f32_low_height",
                                    time_end_16938 - time_start_16937);
                        }
                    }
                } else {
                    if (sle32(x_elems_5, 8) && sle32(y_elems_6, 8)) {
                        unsigned int shared_sizze_16946 = (int64_t) 1;
                        CUdeviceptr kernel_arg_16948 = destmem_0.mem;
                        CUdeviceptr kernel_arg_16949 = srcmem_2.mem;
                        unsigned int shared_offset_16947 = 0;
                        
                        if ((((((1 && sdiv_up32(num_arrays_4 * x_elems_5 *
                                                y_elems_6, 256) != 0) && 1 !=
                                0) && 1 != 0) && 256 != 0) && 1 != 0) && 1 !=
                            0) {
                            int perm[3] = {0, 1, 2};
                            
                            if (1 >= 1 << 16) {
                                perm[1] = perm[0];
                                perm[0] = 1;
                            }
                            if (1 >= 1 << 16) {
                                perm[2] = perm[0];
                                perm[0] = 2;
                            }
                            
                            size_t grid[3];
                            
                            grid[perm[0]] = sdiv_up32(num_arrays_4 * x_elems_5 *
                                                      y_elems_6, 256);
                            grid[perm[1]] = 1;
                            grid[perm[2]] = 1;
                            
                            void *kernel_args_16943[] = {&shared_offset_16947,
                                                         &destoffset_1,
                                                         &srcoffset_3,
                                                         &num_arrays_4,
                                                         &x_elems_5, &y_elems_6,
                                                         &mulx_7, &muly_8,
                                                         &kernel_arg_16948,
                                                         &kernel_arg_16949};
                            int64_t time_start_16944 = 0, time_end_16945 = 0;
                            
                            if (ctx->debugging) {
                                fprintf(ctx->log,
                                        "Launching %s with grid size [%ld, %ld, %ld] and block size [%ld, %ld, %ld]; shared memory: %d bytes.\n",
                                        "gpu_map_transpose_f32_small",
                                        (long) sdiv_up32(num_arrays_4 *
                                                         x_elems_5 * y_elems_6,
                                                         256), (long) 1,
                                        (long) 1, (long) 256, (long) 1,
                                        (long) 1, (int) (0 +
                                                         (shared_sizze_16946 +
                                                          (8 -
                                                           shared_sizze_16946 %
                                                           8) % 8)));
                                time_start_16944 = get_wall_time();
                            }
                            
                            cudaEvent_t *pevents = NULL;
                            
                            if (ctx->profiling && !ctx->profiling_paused) {
                                pevents = cuda_get_events(&ctx->cuda,
                                                          &ctx->gpu_map_transpose_f32_small_runs,
                                                          &ctx->gpu_map_transpose_f32_small_total_runtime);
                                CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[0],
                                                                   0));
                            }
                            CUDA_SUCCEED_OR_RETURN(cuLaunchKernel(ctx->gpu_map_transpose_f32_small,
                                                                  grid[0],
                                                                  grid[1],
                                                                  grid[2], 256,
                                                                  1, 1, 0 +
                                                                  (shared_sizze_16946 +
                                                                   (8 -
                                                                    shared_sizze_16946 %
                                                                    8) % 8),
                                                                  NULL,
                                                                  kernel_args_16943,
                                                                  NULL));
                            if (pevents != NULL)
                                CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[1],
                                                                   0));
                            if (ctx->debugging) {
                                CUDA_SUCCEED_FATAL(cuCtxSynchronize());
                                time_end_16945 = get_wall_time();
                                fprintf(ctx->log, "Kernel %s runtime: %ldus\n",
                                        "gpu_map_transpose_f32_small",
                                        time_end_16945 - time_start_16944);
                            }
                        }
                    } else {
                        unsigned int shared_sizze_16953 = (int64_t) 4224;
                        CUdeviceptr kernel_arg_16955 = destmem_0.mem;
                        CUdeviceptr kernel_arg_16956 = srcmem_2.mem;
                        unsigned int shared_offset_16954 = 0;
                        
                        if ((((((1 && sdiv_up32(x_elems_5, 32) != 0) &&
                                sdiv_up32(y_elems_6, 32) != 0) &&
                               num_arrays_4 != 0) && 32 != 0) && 8 != 0) && 1 !=
                            0) {
                            int perm[3] = {0, 1, 2};
                            
                            if (sdiv_up32(y_elems_6, 32) >= 1 << 16) {
                                perm[1] = perm[0];
                                perm[0] = 1;
                            }
                            if (num_arrays_4 >= 1 << 16) {
                                perm[2] = perm[0];
                                perm[0] = 2;
                            }
                            
                            size_t grid[3];
                            
                            grid[perm[0]] = sdiv_up32(x_elems_5, 32);
                            grid[perm[1]] = sdiv_up32(y_elems_6, 32);
                            grid[perm[2]] = num_arrays_4;
                            
                            void *kernel_args_16950[] = {&perm[0], &perm[1],
                                                         &perm[2],
                                                         &shared_offset_16954,
                                                         &destoffset_1,
                                                         &srcoffset_3,
                                                         &num_arrays_4,
                                                         &x_elems_5, &y_elems_6,
                                                         &mulx_7, &muly_8,
                                                         &kernel_arg_16955,
                                                         &kernel_arg_16956};
                            int64_t time_start_16951 = 0, time_end_16952 = 0;
                            
                            if (ctx->debugging) {
                                fprintf(ctx->log,
                                        "Launching %s with grid size [%ld, %ld, %ld] and block size [%ld, %ld, %ld]; shared memory: %d bytes.\n",
                                        "gpu_map_transpose_f32",
                                        (long) sdiv_up32(x_elems_5, 32),
                                        (long) sdiv_up32(y_elems_6, 32),
                                        (long) num_arrays_4, (long) 32,
                                        (long) 8, (long) 1, (int) (0 +
                                                                   (shared_sizze_16953 +
                                                                    (8 -
                                                                     shared_sizze_16953 %
                                                                     8) % 8)));
                                time_start_16951 = get_wall_time();
                            }
                            
                            cudaEvent_t *pevents = NULL;
                            
                            if (ctx->profiling && !ctx->profiling_paused) {
                                pevents = cuda_get_events(&ctx->cuda,
                                                          &ctx->gpu_map_transpose_f32_runs,
                                                          &ctx->gpu_map_transpose_f32_total_runtime);
                                CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[0],
                                                                   0));
                            }
                            CUDA_SUCCEED_OR_RETURN(cuLaunchKernel(ctx->gpu_map_transpose_f32,
                                                                  grid[0],
                                                                  grid[1],
                                                                  grid[2], 32,
                                                                  8, 1, 0 +
                                                                  (shared_sizze_16953 +
                                                                   (8 -
                                                                    shared_sizze_16953 %
                                                                    8) % 8),
                                                                  NULL,
                                                                  kernel_args_16950,
                                                                  NULL));
                            if (pevents != NULL)
                                CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[1],
                                                                   0));
                            if (ctx->debugging) {
                                CUDA_SUCCEED_FATAL(cuCtxSynchronize());
                                time_end_16952 = get_wall_time();
                                fprintf(ctx->log, "Kernel %s runtime: %ldus\n",
                                        "gpu_map_transpose_f32",
                                        time_end_16952 - time_start_16951);
                            }
                        }
                    }
                }
            }
        }
    }
    
  cleanup:
    { }
    return err;
}
static int futrts_builtinzhgpu_map_transpose_i64(struct futhark_context *ctx,
                                                 struct memblock_device destmem_0,
                                                 int32_t destoffset_1,
                                                 struct memblock_device srcmem_2,
                                                 int32_t srcoffset_3,
                                                 int32_t num_arrays_4,
                                                 int32_t x_elems_5,
                                                 int32_t y_elems_6)
{
    (void) ctx;
    
    int err = 0;
    
    if (!(num_arrays_4 == 0 || (x_elems_5 == 0 || y_elems_6 == 0))) {
        int32_t muly_8 = squot32(16, x_elems_5);
        int32_t mulx_7 = squot32(16, y_elems_6);
        
        if (num_arrays_4 == 1 && (x_elems_5 == 1 || y_elems_6 == 1)) {
            {
                cudaEvent_t *pevents = NULL;
                
                if (ctx->profiling && !ctx->profiling_paused) {
                    pevents = cuda_get_events(&ctx->cuda,
                                              &ctx->copy_dev_to_dev_runs,
                                              &ctx->copy_dev_to_dev_total_runtime);
                    CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[0], 0));
                }
                CUDA_SUCCEED_OR_RETURN(cuMemcpy(destmem_0.mem +
                                                sext_i32_i64(destoffset_1),
                                                srcmem_2.mem +
                                                sext_i32_i64(srcoffset_3),
                                                sext_i32_i64(x_elems_5 *
                                                y_elems_6 * 8)));
                if (pevents != NULL)
                    CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[1], 0));
            }
        } else {
            if (sle32(x_elems_5, 8) && slt32(16, y_elems_6)) {
                unsigned int shared_sizze_16960 = (int64_t) 2176;
                CUdeviceptr kernel_arg_16962 = destmem_0.mem;
                CUdeviceptr kernel_arg_16963 = srcmem_2.mem;
                unsigned int shared_offset_16961 = 0;
                
                if ((((((1 && sdiv_up32(x_elems_5, 16) != 0) &&
                        sdiv_up32(sdiv_up32(y_elems_6, muly_8), 16) != 0) &&
                       num_arrays_4 != 0) && 16 != 0) && 16 != 0) && 1 != 0) {
                    int perm[3] = {0, 1, 2};
                    
                    if (sdiv_up32(sdiv_up32(y_elems_6, muly_8), 16) >= 1 <<
                        16) {
                        perm[1] = perm[0];
                        perm[0] = 1;
                    }
                    if (num_arrays_4 >= 1 << 16) {
                        perm[2] = perm[0];
                        perm[0] = 2;
                    }
                    
                    size_t grid[3];
                    
                    grid[perm[0]] = sdiv_up32(x_elems_5, 16);
                    grid[perm[1]] = sdiv_up32(sdiv_up32(y_elems_6, muly_8), 16);
                    grid[perm[2]] = num_arrays_4;
                    
                    void *kernel_args_16957[] = {&perm[0], &perm[1], &perm[2],
                                                 &shared_offset_16961,
                                                 &destoffset_1, &srcoffset_3,
                                                 &num_arrays_4, &x_elems_5,
                                                 &y_elems_6, &mulx_7, &muly_8,
                                                 &kernel_arg_16962,
                                                 &kernel_arg_16963};
                    int64_t time_start_16958 = 0, time_end_16959 = 0;
                    
                    if (ctx->debugging) {
                        fprintf(ctx->log,
                                "Launching %s with grid size [%ld, %ld, %ld] and block size [%ld, %ld, %ld]; shared memory: %d bytes.\n",
                                "gpu_map_transpose_i64_low_width",
                                (long) sdiv_up32(x_elems_5, 16),
                                (long) sdiv_up32(sdiv_up32(y_elems_6, muly_8),
                                                 16), (long) num_arrays_4,
                                (long) 16, (long) 16, (long) 1, (int) (0 +
                                                                       (shared_sizze_16960 +
                                                                        (8 -
                                                                         shared_sizze_16960 %
                                                                         8) %
                                                                        8)));
                        time_start_16958 = get_wall_time();
                    }
                    
                    cudaEvent_t *pevents = NULL;
                    
                    if (ctx->profiling && !ctx->profiling_paused) {
                        pevents = cuda_get_events(&ctx->cuda,
                                                  &ctx->gpu_map_transpose_i64_low_width_runs,
                                                  &ctx->gpu_map_transpose_i64_low_width_total_runtime);
                        CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[0], 0));
                    }
                    CUDA_SUCCEED_OR_RETURN(cuLaunchKernel(ctx->gpu_map_transpose_i64_low_width,
                                                          grid[0], grid[1],
                                                          grid[2], 16, 16, 1,
                                                          0 +
                                                          (shared_sizze_16960 +
                                                           (8 -
                                                            shared_sizze_16960 %
                                                            8) % 8), NULL,
                                                          kernel_args_16957,
                                                          NULL));
                    if (pevents != NULL)
                        CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[1], 0));
                    if (ctx->debugging) {
                        CUDA_SUCCEED_FATAL(cuCtxSynchronize());
                        time_end_16959 = get_wall_time();
                        fprintf(ctx->log, "Kernel %s runtime: %ldus\n",
                                "gpu_map_transpose_i64_low_width",
                                time_end_16959 - time_start_16958);
                    }
                }
            } else {
                if (sle32(y_elems_6, 8) && slt32(16, x_elems_5)) {
                    unsigned int shared_sizze_16967 = (int64_t) 2176;
                    CUdeviceptr kernel_arg_16969 = destmem_0.mem;
                    CUdeviceptr kernel_arg_16970 = srcmem_2.mem;
                    unsigned int shared_offset_16968 = 0;
                    
                    if ((((((1 && sdiv_up32(sdiv_up32(x_elems_5, mulx_7), 16) !=
                             0) && sdiv_up32(y_elems_6, 16) != 0) &&
                           num_arrays_4 != 0) && 16 != 0) && 16 != 0) && 1 !=
                        0) {
                        int perm[3] = {0, 1, 2};
                        
                        if (sdiv_up32(y_elems_6, 16) >= 1 << 16) {
                            perm[1] = perm[0];
                            perm[0] = 1;
                        }
                        if (num_arrays_4 >= 1 << 16) {
                            perm[2] = perm[0];
                            perm[0] = 2;
                        }
                        
                        size_t grid[3];
                        
                        grid[perm[0]] = sdiv_up32(sdiv_up32(x_elems_5, mulx_7),
                                                  16);
                        grid[perm[1]] = sdiv_up32(y_elems_6, 16);
                        grid[perm[2]] = num_arrays_4;
                        
                        void *kernel_args_16964[] = {&perm[0], &perm[1],
                                                     &perm[2],
                                                     &shared_offset_16968,
                                                     &destoffset_1,
                                                     &srcoffset_3,
                                                     &num_arrays_4, &x_elems_5,
                                                     &y_elems_6, &mulx_7,
                                                     &muly_8, &kernel_arg_16969,
                                                     &kernel_arg_16970};
                        int64_t time_start_16965 = 0, time_end_16966 = 0;
                        
                        if (ctx->debugging) {
                            fprintf(ctx->log,
                                    "Launching %s with grid size [%ld, %ld, %ld] and block size [%ld, %ld, %ld]; shared memory: %d bytes.\n",
                                    "gpu_map_transpose_i64_low_height",
                                    (long) sdiv_up32(sdiv_up32(x_elems_5,
                                                               mulx_7), 16),
                                    (long) sdiv_up32(y_elems_6, 16),
                                    (long) num_arrays_4, (long) 16, (long) 16,
                                    (long) 1, (int) (0 + (shared_sizze_16967 +
                                                          (8 -
                                                           shared_sizze_16967 %
                                                           8) % 8)));
                            time_start_16965 = get_wall_time();
                        }
                        
                        cudaEvent_t *pevents = NULL;
                        
                        if (ctx->profiling && !ctx->profiling_paused) {
                            pevents = cuda_get_events(&ctx->cuda,
                                                      &ctx->gpu_map_transpose_i64_low_height_runs,
                                                      &ctx->gpu_map_transpose_i64_low_height_total_runtime);
                            CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[0], 0));
                        }
                        CUDA_SUCCEED_OR_RETURN(cuLaunchKernel(ctx->gpu_map_transpose_i64_low_height,
                                                              grid[0], grid[1],
                                                              grid[2], 16, 16,
                                                              1, 0 +
                                                              (shared_sizze_16967 +
                                                               (8 -
                                                                shared_sizze_16967 %
                                                                8) % 8), NULL,
                                                              kernel_args_16964,
                                                              NULL));
                        if (pevents != NULL)
                            CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[1], 0));
                        if (ctx->debugging) {
                            CUDA_SUCCEED_FATAL(cuCtxSynchronize());
                            time_end_16966 = get_wall_time();
                            fprintf(ctx->log, "Kernel %s runtime: %ldus\n",
                                    "gpu_map_transpose_i64_low_height",
                                    time_end_16966 - time_start_16965);
                        }
                    }
                } else {
                    if (sle32(x_elems_5, 8) && sle32(y_elems_6, 8)) {
                        unsigned int shared_sizze_16974 = (int64_t) 1;
                        CUdeviceptr kernel_arg_16976 = destmem_0.mem;
                        CUdeviceptr kernel_arg_16977 = srcmem_2.mem;
                        unsigned int shared_offset_16975 = 0;
                        
                        if ((((((1 && sdiv_up32(num_arrays_4 * x_elems_5 *
                                                y_elems_6, 256) != 0) && 1 !=
                                0) && 1 != 0) && 256 != 0) && 1 != 0) && 1 !=
                            0) {
                            int perm[3] = {0, 1, 2};
                            
                            if (1 >= 1 << 16) {
                                perm[1] = perm[0];
                                perm[0] = 1;
                            }
                            if (1 >= 1 << 16) {
                                perm[2] = perm[0];
                                perm[0] = 2;
                            }
                            
                            size_t grid[3];
                            
                            grid[perm[0]] = sdiv_up32(num_arrays_4 * x_elems_5 *
                                                      y_elems_6, 256);
                            grid[perm[1]] = 1;
                            grid[perm[2]] = 1;
                            
                            void *kernel_args_16971[] = {&shared_offset_16975,
                                                         &destoffset_1,
                                                         &srcoffset_3,
                                                         &num_arrays_4,
                                                         &x_elems_5, &y_elems_6,
                                                         &mulx_7, &muly_8,
                                                         &kernel_arg_16976,
                                                         &kernel_arg_16977};
                            int64_t time_start_16972 = 0, time_end_16973 = 0;
                            
                            if (ctx->debugging) {
                                fprintf(ctx->log,
                                        "Launching %s with grid size [%ld, %ld, %ld] and block size [%ld, %ld, %ld]; shared memory: %d bytes.\n",
                                        "gpu_map_transpose_i64_small",
                                        (long) sdiv_up32(num_arrays_4 *
                                                         x_elems_5 * y_elems_6,
                                                         256), (long) 1,
                                        (long) 1, (long) 256, (long) 1,
                                        (long) 1, (int) (0 +
                                                         (shared_sizze_16974 +
                                                          (8 -
                                                           shared_sizze_16974 %
                                                           8) % 8)));
                                time_start_16972 = get_wall_time();
                            }
                            
                            cudaEvent_t *pevents = NULL;
                            
                            if (ctx->profiling && !ctx->profiling_paused) {
                                pevents = cuda_get_events(&ctx->cuda,
                                                          &ctx->gpu_map_transpose_i64_small_runs,
                                                          &ctx->gpu_map_transpose_i64_small_total_runtime);
                                CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[0],
                                                                   0));
                            }
                            CUDA_SUCCEED_OR_RETURN(cuLaunchKernel(ctx->gpu_map_transpose_i64_small,
                                                                  grid[0],
                                                                  grid[1],
                                                                  grid[2], 256,
                                                                  1, 1, 0 +
                                                                  (shared_sizze_16974 +
                                                                   (8 -
                                                                    shared_sizze_16974 %
                                                                    8) % 8),
                                                                  NULL,
                                                                  kernel_args_16971,
                                                                  NULL));
                            if (pevents != NULL)
                                CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[1],
                                                                   0));
                            if (ctx->debugging) {
                                CUDA_SUCCEED_FATAL(cuCtxSynchronize());
                                time_end_16973 = get_wall_time();
                                fprintf(ctx->log, "Kernel %s runtime: %ldus\n",
                                        "gpu_map_transpose_i64_small",
                                        time_end_16973 - time_start_16972);
                            }
                        }
                    } else {
                        unsigned int shared_sizze_16981 = (int64_t) 8448;
                        CUdeviceptr kernel_arg_16983 = destmem_0.mem;
                        CUdeviceptr kernel_arg_16984 = srcmem_2.mem;
                        unsigned int shared_offset_16982 = 0;
                        
                        if ((((((1 && sdiv_up32(x_elems_5, 32) != 0) &&
                                sdiv_up32(y_elems_6, 32) != 0) &&
                               num_arrays_4 != 0) && 32 != 0) && 8 != 0) && 1 !=
                            0) {
                            int perm[3] = {0, 1, 2};
                            
                            if (sdiv_up32(y_elems_6, 32) >= 1 << 16) {
                                perm[1] = perm[0];
                                perm[0] = 1;
                            }
                            if (num_arrays_4 >= 1 << 16) {
                                perm[2] = perm[0];
                                perm[0] = 2;
                            }
                            
                            size_t grid[3];
                            
                            grid[perm[0]] = sdiv_up32(x_elems_5, 32);
                            grid[perm[1]] = sdiv_up32(y_elems_6, 32);
                            grid[perm[2]] = num_arrays_4;
                            
                            void *kernel_args_16978[] = {&perm[0], &perm[1],
                                                         &perm[2],
                                                         &shared_offset_16982,
                                                         &destoffset_1,
                                                         &srcoffset_3,
                                                         &num_arrays_4,
                                                         &x_elems_5, &y_elems_6,
                                                         &mulx_7, &muly_8,
                                                         &kernel_arg_16983,
                                                         &kernel_arg_16984};
                            int64_t time_start_16979 = 0, time_end_16980 = 0;
                            
                            if (ctx->debugging) {
                                fprintf(ctx->log,
                                        "Launching %s with grid size [%ld, %ld, %ld] and block size [%ld, %ld, %ld]; shared memory: %d bytes.\n",
                                        "gpu_map_transpose_i64",
                                        (long) sdiv_up32(x_elems_5, 32),
                                        (long) sdiv_up32(y_elems_6, 32),
                                        (long) num_arrays_4, (long) 32,
                                        (long) 8, (long) 1, (int) (0 +
                                                                   (shared_sizze_16981 +
                                                                    (8 -
                                                                     shared_sizze_16981 %
                                                                     8) % 8)));
                                time_start_16979 = get_wall_time();
                            }
                            
                            cudaEvent_t *pevents = NULL;
                            
                            if (ctx->profiling && !ctx->profiling_paused) {
                                pevents = cuda_get_events(&ctx->cuda,
                                                          &ctx->gpu_map_transpose_i64_runs,
                                                          &ctx->gpu_map_transpose_i64_total_runtime);
                                CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[0],
                                                                   0));
                            }
                            CUDA_SUCCEED_OR_RETURN(cuLaunchKernel(ctx->gpu_map_transpose_i64,
                                                                  grid[0],
                                                                  grid[1],
                                                                  grid[2], 32,
                                                                  8, 1, 0 +
                                                                  (shared_sizze_16981 +
                                                                   (8 -
                                                                    shared_sizze_16981 %
                                                                    8) % 8),
                                                                  NULL,
                                                                  kernel_args_16978,
                                                                  NULL));
                            if (pevents != NULL)
                                CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[1],
                                                                   0));
                            if (ctx->debugging) {
                                CUDA_SUCCEED_FATAL(cuCtxSynchronize());
                                time_end_16980 = get_wall_time();
                                fprintf(ctx->log, "Kernel %s runtime: %ldus\n",
                                        "gpu_map_transpose_i64",
                                        time_end_16980 - time_start_16979);
                            }
                        }
                    }
                }
            }
        }
    }
    
  cleanup:
    { }
    return err;
}
static int futrts_builtinzhiota_i64(struct futhark_context *ctx,
                                    struct memblock_device mem_16796,
                                    int32_t n_16797, int64_t x_16798,
                                    int64_t s_16799)
{
    (void) ctx;
    
    int err = 0;
    int64_t group_sizze_16804;
    
    group_sizze_16804 =
        *ctx->tuning_params.builtinzhiota_i64zigroup_sizze_16804;
    
    int64_t num_groups_16805 = sdiv_up64(n_16797, group_sizze_16804);
    CUdeviceptr kernel_arg_16988 = mem_16796.mem;
    
    if ((((((1 && num_groups_16805 != 0) && 1 != 0) && 1 != 0) &&
          group_sizze_16804 != 0) && 1 != 0) && 1 != 0) {
        int perm[3] = {0, 1, 2};
        
        if (1 >= 1 << 16) {
            perm[1] = perm[0];
            perm[0] = 1;
        }
        if (1 >= 1 << 16) {
            perm[2] = perm[0];
            perm[0] = 2;
        }
        
        size_t grid[3];
        
        grid[perm[0]] = num_groups_16805;
        grid[perm[1]] = 1;
        grid[perm[2]] = 1;
        
        void *kernel_args_16985[] = {&n_16797, &x_16798, &s_16799,
                                     &kernel_arg_16988};
        int64_t time_start_16986 = 0, time_end_16987 = 0;
        
        if (ctx->debugging) {
            fprintf(ctx->log,
                    "Launching %s with grid size [%ld, %ld, %ld] and block size [%ld, %ld, %ld]; shared memory: %d bytes.\n",
                    "builtin#iota_i64.iota_i64_16801", (long) num_groups_16805,
                    (long) 1, (long) 1, (long) group_sizze_16804, (long) 1,
                    (long) 1, (int) 0);
            time_start_16986 = get_wall_time();
        }
        
        cudaEvent_t *pevents = NULL;
        
        if (ctx->profiling && !ctx->profiling_paused) {
            pevents = cuda_get_events(&ctx->cuda,
                                      &ctx->builtinzhiota_i64ziiota_i64_16801_runs,
                                      &ctx->builtinzhiota_i64ziiota_i64_16801_total_runtime);
            CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[0], 0));
        }
        CUDA_SUCCEED_OR_RETURN(cuLaunchKernel(ctx->builtinzhiota_i64ziiota_i64_16801,
                                              grid[0], grid[1], grid[2],
                                              group_sizze_16804, 1, 1, 0, NULL,
                                              kernel_args_16985, NULL));
        if (pevents != NULL)
            CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[1], 0));
        if (ctx->debugging) {
            CUDA_SUCCEED_FATAL(cuCtxSynchronize());
            time_end_16987 = get_wall_time();
            fprintf(ctx->log, "Kernel %s runtime: %ldus\n",
                    "builtin#iota_i64.iota_i64_16801", time_end_16987 -
                    time_start_16986);
        }
    }
    
  cleanup:
    { }
    return err;
}
static int futrts_entry_bicubicInterpolationImage(struct futhark_context *ctx,
                                                  struct memblock_device *mem_out_p_16989,
                                                  struct memblock_device input_mem_16683,
                                                  int64_t h_14505,
                                                  int64_t w_14506,
                                                  int64_t n_14507,
                                                  int64_t newSizzeY_14508,
                                                  int64_t newSizzeX_14509)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device mem_out_16795;
    
    mem_out_16795.references = NULL;
    
    float i64_res_14514 = sitofp_i64_f32(w_14506);
    float i64_res_14515 = sitofp_i64_f32(newSizzeX_14509);
    float ratiox_14516 = i64_res_14514 / i64_res_14515;
    float i64_res_14517 = sitofp_i64_f32(h_14505);
    float i64_res_14518 = sitofp_i64_f32(newSizzeY_14508);
    float ratioy_14519 = i64_res_14517 / i64_res_14518;
    bool bounds_invalid_upwards_14520 = slt64(newSizzeY_14508, (int64_t) 0);
    bool valid_14521 = !bounds_invalid_upwards_14520;
    bool range_valid_c_14522;
    
    if (!valid_14521) {
        ctx->error = msgprintf("Error: %s%lld%s%lld%s%lld%s\n\nBacktrace:\n%s",
                               "Range ", (long long) (int64_t) 0, "..",
                               (long long) (int64_t) 1, "..<",
                               (long long) newSizzeY_14508, " is invalid.",
                               "-> #0  /prelude/array.fut:90:3-10\n   #1  /prelude/array.fut:211:33-38\n   #2  fut/bicubic.fut:27:9-37:9\n   #3  fut/bicubic.fut:52:36-89\n   #4  /prelude/soacs.fut:59:3-10\n   #5  /prelude/array.fut:195:3-17\n   #6  fut/bicubic.fut:52:18-90\n   #7  fut/entries.fut:16:7-51\n   #8  fut/entries.fut:15:1-16:51\n");
        if (memblock_unref_device(ctx, &mem_out_16795, "mem_out_16795") != 0)
            return 1;
        err = 1;
        goto cleanup;
    }
    
    bool bounds_invalid_upwards_14524 = slt64(newSizzeX_14509, (int64_t) 0);
    bool valid_14525 = !bounds_invalid_upwards_14524;
    bool range_valid_c_14526;
    
    if (!valid_14525) {
        ctx->error = msgprintf("Error: %s%lld%s%lld%s%lld%s\n\nBacktrace:\n%s",
                               "Range ", (long long) (int64_t) 0, "..",
                               (long long) (int64_t) 1, "..<",
                               (long long) newSizzeX_14509, " is invalid.",
                               "-> #0  /prelude/array.fut:90:3-10\n   #1  /prelude/array.fut:203:28-33\n   #2  /prelude/functional.fut:39:59-65\n   #3  /prelude/soacs.fut:59:3-10\n   #4  /prelude/array.fut:211:3-39\n   #5  fut/bicubic.fut:27:9-37:9\n   #6  fut/bicubic.fut:52:36-89\n   #7  /prelude/soacs.fut:59:3-10\n   #8  /prelude/array.fut:195:3-17\n   #9  fut/bicubic.fut:52:18-90\n   #10 fut/entries.fut:16:7-51\n   #11 fut/entries.fut:15:1-16:51\n");
        if (memblock_unref_device(ctx, &mem_out_16795, "mem_out_16795") != 0)
            return 1;
        err = 1;
        goto cleanup;
    }
    
    int64_t clip_arg_14529 = sub64(h_14505, (int64_t) 1);
    int64_t clip_arg_14530 = sub64(w_14506, (int64_t) 1);
    int64_t one_intra_par_min_14956 = h_14505 * w_14506;
    int64_t one_intra_par_min_14957 = newSizzeY_14508 * newSizzeX_14509;
    int64_t y_14958 = (int64_t) 4 * newSizzeY_14508;
    int64_t one_intra_par_min_14959 = newSizzeX_14509 * y_14958;
    int64_t y_14960 = (int64_t) 16 * newSizzeY_14508;
    int64_t one_intra_par_min_14961 = newSizzeX_14509 * y_14960;
    int64_t y_14968 = smin64(h_14505, one_intra_par_min_14961);
    int64_t y_14969 = smin64(one_intra_par_min_14959, y_14968);
    int64_t y_14970 = smin64(one_intra_par_min_14957, y_14969);
    int64_t y_14971 = smin64(newSizzeY_14508, y_14970);
    int64_t intra_avail_par_14972 = smin64(one_intra_par_min_14956, y_14971);
    int64_t y_14973 = smax64(h_14505, one_intra_par_min_14961);
    int64_t y_14974 = smax64(one_intra_par_min_14959, y_14973);
    int64_t y_14975 = smax64(one_intra_par_min_14957, y_14974);
    int64_t y_14976 = smax64(newSizzeY_14508, y_14975);
    int64_t computed_group_sizze_14778 = smax64(one_intra_par_min_14956,
                                                y_14976);
    int64_t max_group_sizze_14980;
    
    max_group_sizze_14980 = ctx->cuda.max_block_size;
    
    bool fits_14981 = sle64(computed_group_sizze_14778, max_group_sizze_14980);
    bool suff_intra_par_14979;
    
    suff_intra_par_14979 =
        *ctx->tuning_params.bicubicInterpolationImagezisuff_intra_par_0 <=
        intra_avail_par_14972;
    if (ctx->logging)
        fprintf(ctx->log, "Compared %s <= %ld: %s.\n",
                "bicubicInterpolationImage.suff_intra_par_0",
                (long) intra_avail_par_14972,
                suff_intra_par_14979 ? "true" : "false");
    
    bool intra_suff_and_fits_14982 = suff_intra_par_14979 && fits_14981;
    int64_t nest_sizze_16056 = n_14507 * newSizzeY_14508;
    int64_t segmap_group_sizze_16057;
    
    segmap_group_sizze_16057 =
        *ctx->tuning_params.bicubicInterpolationImagezisegmap_group_sizze_15770;
    
    int64_t nest_sizze_16076 = n_14507 * one_intra_par_min_14957;
    int64_t segmap_group_sizze_16077;
    
    segmap_group_sizze_16077 =
        *ctx->tuning_params.bicubicInterpolationImagezisegmap_group_sizze_15696;
    
    int64_t y_16096 = (int64_t) 16 * newSizzeX_14509;
    int64_t y_16097 = newSizzeY_14508 * y_16096;
    int64_t nest_sizze_16098 = n_14507 * y_16097;
    int64_t segmap_group_sizze_16099;
    
    segmap_group_sizze_16099 =
        *ctx->tuning_params.bicubicInterpolationImagezisegmap_group_sizze_15623;
    
    int64_t segmap_group_sizze_16140;
    
    segmap_group_sizze_16140 =
        *ctx->tuning_params.bicubicInterpolationImagezisegmap_group_sizze_15437;
    
    int64_t segmap_group_sizze_16163;
    
    segmap_group_sizze_16163 =
        *ctx->tuning_params.bicubicInterpolationImagezisegmap_group_sizze_15313;
    
    int64_t y_16190 = (int64_t) 4 * newSizzeX_14509;
    int64_t y_16191 = newSizzeY_14508 * y_16190;
    int64_t nest_sizze_16192 = n_14507 * y_16191;
    int64_t segmap_group_sizze_16193;
    
    segmap_group_sizze_16193 =
        *ctx->tuning_params.bicubicInterpolationImagezisegmap_group_sizze_15228;
    
    int64_t segmap_group_sizze_16234;
    
    segmap_group_sizze_16234 =
        *ctx->tuning_params.bicubicInterpolationImagezisegmap_group_sizze_15175;
    
    int64_t binop_x_16721 = newSizzeX_14509 * nest_sizze_16056;
    int64_t binop_y_16722 = (int64_t) 4 * binop_x_16721;
    int64_t bytes_16723 = smax64((int64_t) 0, binop_y_16722);
    int64_t binop_y_16686 = (int64_t) 8 * newSizzeY_14508;
    int64_t bytes_16687 = smax64((int64_t) 0, binop_y_16686);
    int64_t binop_y_16691 = (int64_t) 8 * one_intra_par_min_14957;
    int64_t bytes_16692 = smax64((int64_t) 0, binop_y_16691);
    int64_t binop_x_16696 = (int64_t) 16 * one_intra_par_min_14957;
    int64_t binop_y_16697 = (int64_t) 4 * binop_x_16696;
    int64_t bytes_16698 = smax64((int64_t) 0, binop_y_16697);
    int64_t bytes_16702 = smax64((int64_t) 0, y_14958);
    int64_t binop_y_16706 = (int64_t) 4 * one_intra_par_min_14957;
    int64_t bytes_16707 = smax64((int64_t) 0, binop_y_16706);
    int64_t binop_y_16712 = (int64_t) 4 * binop_y_16706;
    int64_t bytes_16713 = smax64((int64_t) 0, binop_y_16712);
    int64_t binop_y_16727 = (int64_t) 8 * nest_sizze_16056;
    int64_t bytes_16728 = smax64((int64_t) 0, binop_y_16727);
    int64_t binop_y_16733 = (int64_t) 8 * binop_x_16721;
    int64_t bytes_16734 = smax64((int64_t) 0, binop_y_16733);
    int64_t binop_x_16739 = (int64_t) 16 * binop_x_16721;
    int64_t binop_y_16740 = (int64_t) 4 * binop_x_16739;
    int64_t bytes_16741 = smax64((int64_t) 0, binop_y_16740);
    int64_t binop_y_16745 = (int64_t) 4 * nest_sizze_16056;
    int64_t bytes_16746 = smax64((int64_t) 0, binop_y_16745);
    int64_t binop_y_16758 = (int64_t) 4 * binop_y_16722;
    int64_t bytes_16759 = smax64((int64_t) 0, binop_y_16758);
    int64_t maxSubHelper_16778 = umax64(bytes_16692, bytes_16707);
    int64_t maxSubHelper_16779 = umax64(bytes_16687, bytes_16713);
    struct memblock_device ext_mem_16767;
    
    ext_mem_16767.references = NULL;
    
    int32_t local_memory_capacity_16916;
    
    local_memory_capacity_16916 = ctx->cuda.max_shared_memory;
    if (sle64(maxSubHelper_16778 + srem64((int64_t) 8 -
                                          srem64(maxSubHelper_16778,
                                                 (int64_t) 8), (int64_t) 8) +
              (maxSubHelper_16779 + srem64((int64_t) 8 -
                                           srem64(maxSubHelper_16779,
                                                  (int64_t) 8), (int64_t) 8)) +
              (bytes_16702 + srem64((int64_t) 8 - srem64(bytes_16702,
                                                         (int64_t) 8),
                                    (int64_t) 8)) + (bytes_16698 +
                                                     srem64((int64_t) 8 -
                                                            srem64(bytes_16698,
                                                                   (int64_t) 8),
                                                            (int64_t) 8)),
              sext_i32_i64(local_memory_capacity_16916)) &&
        intra_suff_and_fits_14982) {
        struct memblock_device mem_16724;
        
        mem_16724.references = NULL;
        if (memblock_alloc_device(ctx, &mem_16724, bytes_16723, "mem_16724")) {
            err = 1;
            goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegMap");
        
        unsigned int shared_sizze_16993 = bytes_16698;
        unsigned int shared_sizze_16995 = bytes_16702;
        unsigned int shared_sizze_16997 = maxSubHelper_16779;
        unsigned int shared_sizze_16999 = maxSubHelper_16778;
        CUdeviceptr kernel_arg_17001 = input_mem_16683.mem;
        CUdeviceptr kernel_arg_17002 = mem_16724.mem;
        unsigned int shared_offset_16994 = 0;
        unsigned int shared_offset_16996 = 0 + (shared_sizze_16993 + (8 -
                                                                      shared_sizze_16993 %
                                                                      8) % 8);
        unsigned int shared_offset_16998 = 0 + (shared_sizze_16993 + (8 -
                                                                      shared_sizze_16993 %
                                                                      8) % 8) +
                     (shared_sizze_16995 + (8 - shared_sizze_16995 % 8) % 8);
        unsigned int shared_offset_17000 = 0 + (shared_sizze_16993 + (8 -
                                                                      shared_sizze_16993 %
                                                                      8) % 8) +
                     (shared_sizze_16995 + (8 - shared_sizze_16995 % 8) % 8) +
                     (shared_sizze_16997 + (8 - shared_sizze_16997 % 8) % 8);
        
        if ((((((1 && n_14507 != 0) && 1 != 0) && 1 != 0) &&
              computed_group_sizze_14778 != 0) && 1 != 0) && 1 != 0) {
            int perm[3] = {0, 1, 2};
            
            if (1 >= 1 << 16) {
                perm[1] = perm[0];
                perm[0] = 1;
            }
            if (1 >= 1 << 16) {
                perm[2] = perm[0];
                perm[0] = 2;
            }
            
            size_t grid[3];
            
            grid[perm[0]] = n_14507;
            grid[perm[1]] = 1;
            grid[perm[2]] = 1;
            
            void *kernel_args_16990[] = {&ctx->global_failure,
                                         &ctx->failure_is_an_option,
                                         &ctx->global_failure_args,
                                         &shared_offset_16994,
                                         &shared_offset_16996,
                                         &shared_offset_16998,
                                         &shared_offset_17000, &h_14505,
                                         &w_14506, &n_14507, &newSizzeY_14508,
                                         &newSizzeX_14509, &ratiox_14516,
                                         &ratioy_14519, &clip_arg_14529,
                                         &clip_arg_14530,
                                         &computed_group_sizze_14778,
                                         &kernel_arg_17001, &kernel_arg_17002};
            int64_t time_start_16991 = 0, time_end_16992 = 0;
            
            if (ctx->debugging) {
                fprintf(ctx->log,
                        "Launching %s with grid size [%ld, %ld, %ld] and block size [%ld, %ld, %ld]; shared memory: %d bytes.\n",
                        "bicubicInterpolationImage.segmap_intragroup_14985",
                        (long) n_14507, (long) 1, (long) 1,
                        (long) computed_group_sizze_14778, (long) 1, (long) 1,
                        (int) (0 + (shared_sizze_16993 + (8 -
                                                          shared_sizze_16993 %
                                                          8) % 8) +
                               (shared_sizze_16995 + (8 - shared_sizze_16995 %
                                                      8) % 8) +
                               (shared_sizze_16997 + (8 - shared_sizze_16997 %
                                                      8) % 8) +
                               (shared_sizze_16999 + (8 - shared_sizze_16999 %
                                                      8) % 8)));
                time_start_16991 = get_wall_time();
            }
            
            cudaEvent_t *pevents = NULL;
            
            if (ctx->profiling && !ctx->profiling_paused) {
                pevents = cuda_get_events(&ctx->cuda,
                                          &ctx->bicubicInterpolationImagezisegmap_intragroup_14985_runs,
                                          &ctx->bicubicInterpolationImagezisegmap_intragroup_14985_total_runtime);
                CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[0], 0));
            }
            CUDA_SUCCEED_OR_RETURN(cuLaunchKernel(ctx->bicubicInterpolationImagezisegmap_intragroup_14985,
                                                  grid[0], grid[1], grid[2],
                                                  computed_group_sizze_14778, 1,
                                                  1, 0 + (shared_sizze_16993 +
                                                          (8 -
                                                           shared_sizze_16993 %
                                                           8) % 8) +
                                                  (shared_sizze_16995 + (8 -
                                                                         shared_sizze_16995 %
                                                                         8) %
                                                   8) + (shared_sizze_16997 +
                                                         (8 -
                                                          shared_sizze_16997 %
                                                          8) % 8) +
                                                  (shared_sizze_16999 + (8 -
                                                                         shared_sizze_16999 %
                                                                         8) %
                                                   8), NULL, kernel_args_16990,
                                                  NULL));
            if (pevents != NULL)
                CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[1], 0));
            if (ctx->debugging) {
                CUDA_SUCCEED_FATAL(cuCtxSynchronize());
                time_end_16992 = get_wall_time();
                fprintf(ctx->log, "Kernel %s runtime: %ldus\n",
                        "bicubicInterpolationImage.segmap_intragroup_14985",
                        time_end_16992 - time_start_16991);
            }
        }
        ctx->failure_is_an_option = 1;
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
        if (memblock_set_device(ctx, &ext_mem_16767, &mem_16724, "mem_16724") !=
            0)
            return 1;
        if (memblock_unref_device(ctx, &mem_16724, "mem_16724") != 0)
            return 1;
    } else {
        int64_t segmap_usable_groups_16058 = sdiv_up64(nest_sizze_16056,
                                                       segmap_group_sizze_16057);
        struct memblock_device mem_16729;
        
        mem_16729.references = NULL;
        if (memblock_alloc_device(ctx, &mem_16729, bytes_16728, "mem_16729")) {
            err = 1;
            goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegMap");
        
        CUdeviceptr kernel_arg_17006 = mem_16729.mem;
        
        if ((((((1 && segmap_usable_groups_16058 != 0) && 1 != 0) && 1 != 0) &&
              segmap_group_sizze_16057 != 0) && 1 != 0) && 1 != 0) {
            int perm[3] = {0, 1, 2};
            
            if (1 >= 1 << 16) {
                perm[1] = perm[0];
                perm[0] = 1;
            }
            if (1 >= 1 << 16) {
                perm[2] = perm[0];
                perm[0] = 2;
            }
            
            size_t grid[3];
            
            grid[perm[0]] = segmap_usable_groups_16058;
            grid[perm[1]] = 1;
            grid[perm[2]] = 1;
            
            void *kernel_args_17003[] = {&ctx->global_failure, &n_14507,
                                         &newSizzeY_14508, &ratioy_14519,
                                         &kernel_arg_17006};
            int64_t time_start_17004 = 0, time_end_17005 = 0;
            
            if (ctx->debugging) {
                fprintf(ctx->log,
                        "Launching %s with grid size [%ld, %ld, %ld] and block size [%ld, %ld, %ld]; shared memory: %d bytes.\n",
                        "bicubicInterpolationImage.segmap_16062",
                        (long) segmap_usable_groups_16058, (long) 1, (long) 1,
                        (long) segmap_group_sizze_16057, (long) 1, (long) 1,
                        (int) 0);
                time_start_17004 = get_wall_time();
            }
            
            cudaEvent_t *pevents = NULL;
            
            if (ctx->profiling && !ctx->profiling_paused) {
                pevents = cuda_get_events(&ctx->cuda,
                                          &ctx->bicubicInterpolationImagezisegmap_16062_runs,
                                          &ctx->bicubicInterpolationImagezisegmap_16062_total_runtime);
                CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[0], 0));
            }
            CUDA_SUCCEED_OR_RETURN(cuLaunchKernel(ctx->bicubicInterpolationImagezisegmap_16062,
                                                  grid[0], grid[1], grid[2],
                                                  segmap_group_sizze_16057, 1,
                                                  1, 0, NULL, kernel_args_17003,
                                                  NULL));
            if (pevents != NULL)
                CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[1], 0));
            if (ctx->debugging) {
                CUDA_SUCCEED_FATAL(cuCtxSynchronize());
                time_end_17005 = get_wall_time();
                fprintf(ctx->log, "Kernel %s runtime: %ldus\n",
                        "bicubicInterpolationImage.segmap_16062",
                        time_end_17005 - time_start_17004);
            }
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
        
        int64_t segmap_usable_groups_16078 = sdiv_up64(nest_sizze_16076,
                                                       segmap_group_sizze_16077);
        struct memblock_device mem_16735;
        
        mem_16735.references = NULL;
        if (memblock_alloc_device(ctx, &mem_16735, bytes_16734, "mem_16735")) {
            err = 1;
            goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegMap");
        
        CUdeviceptr kernel_arg_17010 = mem_16735.mem;
        
        if ((((((1 && segmap_usable_groups_16078 != 0) && 1 != 0) && 1 != 0) &&
              segmap_group_sizze_16077 != 0) && 1 != 0) && 1 != 0) {
            int perm[3] = {0, 1, 2};
            
            if (1 >= 1 << 16) {
                perm[1] = perm[0];
                perm[0] = 1;
            }
            if (1 >= 1 << 16) {
                perm[2] = perm[0];
                perm[0] = 2;
            }
            
            size_t grid[3];
            
            grid[perm[0]] = segmap_usable_groups_16078;
            grid[perm[1]] = 1;
            grid[perm[2]] = 1;
            
            void *kernel_args_17007[] = {&ctx->global_failure, &n_14507,
                                         &newSizzeY_14508, &newSizzeX_14509,
                                         &ratiox_14516, &kernel_arg_17010};
            int64_t time_start_17008 = 0, time_end_17009 = 0;
            
            if (ctx->debugging) {
                fprintf(ctx->log,
                        "Launching %s with grid size [%ld, %ld, %ld] and block size [%ld, %ld, %ld]; shared memory: %d bytes.\n",
                        "bicubicInterpolationImage.segmap_16083",
                        (long) segmap_usable_groups_16078, (long) 1, (long) 1,
                        (long) segmap_group_sizze_16077, (long) 1, (long) 1,
                        (int) 0);
                time_start_17008 = get_wall_time();
            }
            
            cudaEvent_t *pevents = NULL;
            
            if (ctx->profiling && !ctx->profiling_paused) {
                pevents = cuda_get_events(&ctx->cuda,
                                          &ctx->bicubicInterpolationImagezisegmap_16083_runs,
                                          &ctx->bicubicInterpolationImagezisegmap_16083_total_runtime);
                CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[0], 0));
            }
            CUDA_SUCCEED_OR_RETURN(cuLaunchKernel(ctx->bicubicInterpolationImagezisegmap_16083,
                                                  grid[0], grid[1], grid[2],
                                                  segmap_group_sizze_16077, 1,
                                                  1, 0, NULL, kernel_args_17007,
                                                  NULL));
            if (pevents != NULL)
                CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[1], 0));
            if (ctx->debugging) {
                CUDA_SUCCEED_FATAL(cuCtxSynchronize());
                time_end_17009 = get_wall_time();
                fprintf(ctx->log, "Kernel %s runtime: %ldus\n",
                        "bicubicInterpolationImage.segmap_16083",
                        time_end_17009 - time_start_17008);
            }
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
        
        int64_t segmap_usable_groups_16100 = sdiv_up64(nest_sizze_16098,
                                                       segmap_group_sizze_16099);
        struct memblock_device mem_16742;
        
        mem_16742.references = NULL;
        if (memblock_alloc_device(ctx, &mem_16742, bytes_16741, "mem_16742")) {
            err = 1;
            goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegMap");
        
        CUdeviceptr kernel_arg_17014 = input_mem_16683.mem;
        CUdeviceptr kernel_arg_17015 = mem_16729.mem;
        CUdeviceptr kernel_arg_17016 = mem_16735.mem;
        CUdeviceptr kernel_arg_17017 = mem_16742.mem;
        
        if ((((((1 && segmap_usable_groups_16100 != 0) && 1 != 0) && 1 != 0) &&
              segmap_group_sizze_16099 != 0) && 1 != 0) && 1 != 0) {
            int perm[3] = {0, 1, 2};
            
            if (1 >= 1 << 16) {
                perm[1] = perm[0];
                perm[0] = 1;
            }
            if (1 >= 1 << 16) {
                perm[2] = perm[0];
                perm[0] = 2;
            }
            
            size_t grid[3];
            
            grid[perm[0]] = segmap_usable_groups_16100;
            grid[perm[1]] = 1;
            grid[perm[2]] = 1;
            
            void *kernel_args_17011[] = {&ctx->global_failure,
                                         &ctx->failure_is_an_option,
                                         &ctx->global_failure_args, &h_14505,
                                         &w_14506, &n_14507, &newSizzeY_14508,
                                         &newSizzeX_14509, &clip_arg_14529,
                                         &clip_arg_14530, &kernel_arg_17014,
                                         &kernel_arg_17015, &kernel_arg_17016,
                                         &kernel_arg_17017};
            int64_t time_start_17012 = 0, time_end_17013 = 0;
            
            if (ctx->debugging) {
                fprintf(ctx->log,
                        "Launching %s with grid size [%ld, %ld, %ld] and block size [%ld, %ld, %ld]; shared memory: %d bytes.\n",
                        "bicubicInterpolationImage.segmap_16106",
                        (long) segmap_usable_groups_16100, (long) 1, (long) 1,
                        (long) segmap_group_sizze_16099, (long) 1, (long) 1,
                        (int) 0);
                time_start_17012 = get_wall_time();
            }
            
            cudaEvent_t *pevents = NULL;
            
            if (ctx->profiling && !ctx->profiling_paused) {
                pevents = cuda_get_events(&ctx->cuda,
                                          &ctx->bicubicInterpolationImagezisegmap_16106_runs,
                                          &ctx->bicubicInterpolationImagezisegmap_16106_total_runtime);
                CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[0], 0));
            }
            CUDA_SUCCEED_OR_RETURN(cuLaunchKernel(ctx->bicubicInterpolationImagezisegmap_16106,
                                                  grid[0], grid[1], grid[2],
                                                  segmap_group_sizze_16099, 1,
                                                  1, 0, NULL, kernel_args_17011,
                                                  NULL));
            if (pevents != NULL)
                CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[1], 0));
            if (ctx->debugging) {
                CUDA_SUCCEED_FATAL(cuCtxSynchronize());
                time_end_17013 = get_wall_time();
                fprintf(ctx->log, "Kernel %s runtime: %ldus\n",
                        "bicubicInterpolationImage.segmap_16106",
                        time_end_17013 - time_start_17012);
            }
        }
        ctx->failure_is_an_option = 1;
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
        if (memblock_unref_device(ctx, &mem_16729, "mem_16729") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_16735, "mem_16735") != 0)
            return 1;
        
        int64_t segmap_usable_groups_16141 = sdiv_up64(nest_sizze_16056,
                                                       segmap_group_sizze_16140);
        struct memblock_device mem_16747;
        
        mem_16747.references = NULL;
        if (memblock_alloc_device(ctx, &mem_16747, bytes_16746, "mem_16747")) {
            err = 1;
            goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegMap");
        
        CUdeviceptr kernel_arg_17021 = mem_16747.mem;
        
        if ((((((1 && segmap_usable_groups_16141 != 0) && 1 != 0) && 1 != 0) &&
              segmap_group_sizze_16140 != 0) && 1 != 0) && 1 != 0) {
            int perm[3] = {0, 1, 2};
            
            if (1 >= 1 << 16) {
                perm[1] = perm[0];
                perm[0] = 1;
            }
            if (1 >= 1 << 16) {
                perm[2] = perm[0];
                perm[0] = 2;
            }
            
            size_t grid[3];
            
            grid[perm[0]] = segmap_usable_groups_16141;
            grid[perm[1]] = 1;
            grid[perm[2]] = 1;
            
            void *kernel_args_17018[] = {&ctx->global_failure, &n_14507,
                                         &newSizzeY_14508, &ratioy_14519,
                                         &kernel_arg_17021};
            int64_t time_start_17019 = 0, time_end_17020 = 0;
            
            if (ctx->debugging) {
                fprintf(ctx->log,
                        "Launching %s with grid size [%ld, %ld, %ld] and block size [%ld, %ld, %ld]; shared memory: %d bytes.\n",
                        "bicubicInterpolationImage.segmap_16146",
                        (long) segmap_usable_groups_16141, (long) 1, (long) 1,
                        (long) segmap_group_sizze_16140, (long) 1, (long) 1,
                        (int) 0);
                time_start_17019 = get_wall_time();
            }
            
            cudaEvent_t *pevents = NULL;
            
            if (ctx->profiling && !ctx->profiling_paused) {
                pevents = cuda_get_events(&ctx->cuda,
                                          &ctx->bicubicInterpolationImagezisegmap_16146_runs,
                                          &ctx->bicubicInterpolationImagezisegmap_16146_total_runtime);
                CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[0], 0));
            }
            CUDA_SUCCEED_OR_RETURN(cuLaunchKernel(ctx->bicubicInterpolationImagezisegmap_16146,
                                                  grid[0], grid[1], grid[2],
                                                  segmap_group_sizze_16140, 1,
                                                  1, 0, NULL, kernel_args_17018,
                                                  NULL));
            if (pevents != NULL)
                CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[1], 0));
            if (ctx->debugging) {
                CUDA_SUCCEED_FATAL(cuCtxSynchronize());
                time_end_17020 = get_wall_time();
                fprintf(ctx->log, "Kernel %s runtime: %ldus\n",
                        "bicubicInterpolationImage.segmap_16146",
                        time_end_17020 - time_start_17019);
            }
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
        
        int64_t segmap_usable_groups_16164 = sdiv_up64(nest_sizze_16076,
                                                       segmap_group_sizze_16163);
        struct memblock_device mem_16753;
        
        mem_16753.references = NULL;
        if (memblock_alloc_device(ctx, &mem_16753, bytes_16723, "mem_16753")) {
            err = 1;
            goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegMap");
        
        CUdeviceptr kernel_arg_17025 = mem_16753.mem;
        
        if ((((((1 && segmap_usable_groups_16164 != 0) && 1 != 0) && 1 != 0) &&
              segmap_group_sizze_16163 != 0) && 1 != 0) && 1 != 0) {
            int perm[3] = {0, 1, 2};
            
            if (1 >= 1 << 16) {
                perm[1] = perm[0];
                perm[0] = 1;
            }
            if (1 >= 1 << 16) {
                perm[2] = perm[0];
                perm[0] = 2;
            }
            
            size_t grid[3];
            
            grid[perm[0]] = segmap_usable_groups_16164;
            grid[perm[1]] = 1;
            grid[perm[2]] = 1;
            
            void *kernel_args_17022[] = {&ctx->global_failure, &n_14507,
                                         &newSizzeY_14508, &newSizzeX_14509,
                                         &ratiox_14516, &kernel_arg_17025};
            int64_t time_start_17023 = 0, time_end_17024 = 0;
            
            if (ctx->debugging) {
                fprintf(ctx->log,
                        "Launching %s with grid size [%ld, %ld, %ld] and block size [%ld, %ld, %ld]; shared memory: %d bytes.\n",
                        "bicubicInterpolationImage.segmap_16170",
                        (long) segmap_usable_groups_16164, (long) 1, (long) 1,
                        (long) segmap_group_sizze_16163, (long) 1, (long) 1,
                        (int) 0);
                time_start_17023 = get_wall_time();
            }
            
            cudaEvent_t *pevents = NULL;
            
            if (ctx->profiling && !ctx->profiling_paused) {
                pevents = cuda_get_events(&ctx->cuda,
                                          &ctx->bicubicInterpolationImagezisegmap_16170_runs,
                                          &ctx->bicubicInterpolationImagezisegmap_16170_total_runtime);
                CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[0], 0));
            }
            CUDA_SUCCEED_OR_RETURN(cuLaunchKernel(ctx->bicubicInterpolationImagezisegmap_16170,
                                                  grid[0], grid[1], grid[2],
                                                  segmap_group_sizze_16163, 1,
                                                  1, 0, NULL, kernel_args_17022,
                                                  NULL));
            if (pevents != NULL)
                CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[1], 0));
            if (ctx->debugging) {
                CUDA_SUCCEED_FATAL(cuCtxSynchronize());
                time_end_17024 = get_wall_time();
                fprintf(ctx->log, "Kernel %s runtime: %ldus\n",
                        "bicubicInterpolationImage.segmap_16170",
                        time_end_17024 - time_start_17023);
            }
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
        
        int64_t segmap_usable_groups_16194 = sdiv_up64(nest_sizze_16192,
                                                       segmap_group_sizze_16193);
        struct memblock_device mem_16760;
        
        mem_16760.references = NULL;
        if (memblock_alloc_device(ctx, &mem_16760, bytes_16759, "mem_16760")) {
            err = 1;
            goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegMap");
        
        CUdeviceptr kernel_arg_17029 = mem_16742.mem;
        CUdeviceptr kernel_arg_17030 = mem_16753.mem;
        CUdeviceptr kernel_arg_17031 = mem_16760.mem;
        
        if ((((((1 && segmap_usable_groups_16194 != 0) && 1 != 0) && 1 != 0) &&
              segmap_group_sizze_16193 != 0) && 1 != 0) && 1 != 0) {
            int perm[3] = {0, 1, 2};
            
            if (1 >= 1 << 16) {
                perm[1] = perm[0];
                perm[0] = 1;
            }
            if (1 >= 1 << 16) {
                perm[2] = perm[0];
                perm[0] = 2;
            }
            
            size_t grid[3];
            
            grid[perm[0]] = segmap_usable_groups_16194;
            grid[perm[1]] = 1;
            grid[perm[2]] = 1;
            
            void *kernel_args_17026[] = {&ctx->global_failure, &n_14507,
                                         &newSizzeY_14508, &newSizzeX_14509,
                                         &kernel_arg_17029, &kernel_arg_17030,
                                         &kernel_arg_17031};
            int64_t time_start_17027 = 0, time_end_17028 = 0;
            
            if (ctx->debugging) {
                fprintf(ctx->log,
                        "Launching %s with grid size [%ld, %ld, %ld] and block size [%ld, %ld, %ld]; shared memory: %d bytes.\n",
                        "bicubicInterpolationImage.segmap_16200",
                        (long) segmap_usable_groups_16194, (long) 1, (long) 1,
                        (long) segmap_group_sizze_16193, (long) 1, (long) 1,
                        (int) 0);
                time_start_17027 = get_wall_time();
            }
            
            cudaEvent_t *pevents = NULL;
            
            if (ctx->profiling && !ctx->profiling_paused) {
                pevents = cuda_get_events(&ctx->cuda,
                                          &ctx->bicubicInterpolationImagezisegmap_16200_runs,
                                          &ctx->bicubicInterpolationImagezisegmap_16200_total_runtime);
                CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[0], 0));
            }
            CUDA_SUCCEED_OR_RETURN(cuLaunchKernel(ctx->bicubicInterpolationImagezisegmap_16200,
                                                  grid[0], grid[1], grid[2],
                                                  segmap_group_sizze_16193, 1,
                                                  1, 0, NULL, kernel_args_17026,
                                                  NULL));
            if (pevents != NULL)
                CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[1], 0));
            if (ctx->debugging) {
                CUDA_SUCCEED_FATAL(cuCtxSynchronize());
                time_end_17028 = get_wall_time();
                fprintf(ctx->log, "Kernel %s runtime: %ldus\n",
                        "bicubicInterpolationImage.segmap_16200",
                        time_end_17028 - time_start_17027);
            }
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
        if (memblock_unref_device(ctx, &mem_16742, "mem_16742") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_16753, "mem_16753") != 0)
            return 1;
        
        int64_t segmap_usable_groups_16235 = sdiv_up64(nest_sizze_16076,
                                                       segmap_group_sizze_16234);
        struct memblock_device mem_16766;
        
        mem_16766.references = NULL;
        if (memblock_alloc_device(ctx, &mem_16766, bytes_16723, "mem_16766")) {
            err = 1;
            goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegMap");
        
        CUdeviceptr kernel_arg_17035 = mem_16747.mem;
        CUdeviceptr kernel_arg_17036 = mem_16760.mem;
        CUdeviceptr kernel_arg_17037 = mem_16766.mem;
        
        if ((((((1 && segmap_usable_groups_16235 != 0) && 1 != 0) && 1 != 0) &&
              segmap_group_sizze_16234 != 0) && 1 != 0) && 1 != 0) {
            int perm[3] = {0, 1, 2};
            
            if (1 >= 1 << 16) {
                perm[1] = perm[0];
                perm[0] = 1;
            }
            if (1 >= 1 << 16) {
                perm[2] = perm[0];
                perm[0] = 2;
            }
            
            size_t grid[3];
            
            grid[perm[0]] = segmap_usable_groups_16235;
            grid[perm[1]] = 1;
            grid[perm[2]] = 1;
            
            void *kernel_args_17032[] = {&ctx->global_failure, &n_14507,
                                         &newSizzeY_14508, &newSizzeX_14509,
                                         &kernel_arg_17035, &kernel_arg_17036,
                                         &kernel_arg_17037};
            int64_t time_start_17033 = 0, time_end_17034 = 0;
            
            if (ctx->debugging) {
                fprintf(ctx->log,
                        "Launching %s with grid size [%ld, %ld, %ld] and block size [%ld, %ld, %ld]; shared memory: %d bytes.\n",
                        "bicubicInterpolationImage.segmap_16240",
                        (long) segmap_usable_groups_16235, (long) 1, (long) 1,
                        (long) segmap_group_sizze_16234, (long) 1, (long) 1,
                        (int) 0);
                time_start_17033 = get_wall_time();
            }
            
            cudaEvent_t *pevents = NULL;
            
            if (ctx->profiling && !ctx->profiling_paused) {
                pevents = cuda_get_events(&ctx->cuda,
                                          &ctx->bicubicInterpolationImagezisegmap_16240_runs,
                                          &ctx->bicubicInterpolationImagezisegmap_16240_total_runtime);
                CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[0], 0));
            }
            CUDA_SUCCEED_OR_RETURN(cuLaunchKernel(ctx->bicubicInterpolationImagezisegmap_16240,
                                                  grid[0], grid[1], grid[2],
                                                  segmap_group_sizze_16234, 1,
                                                  1, 0, NULL, kernel_args_17032,
                                                  NULL));
            if (pevents != NULL)
                CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[1], 0));
            if (ctx->debugging) {
                CUDA_SUCCEED_FATAL(cuCtxSynchronize());
                time_end_17034 = get_wall_time();
                fprintf(ctx->log, "Kernel %s runtime: %ldus\n",
                        "bicubicInterpolationImage.segmap_16240",
                        time_end_17034 - time_start_17033);
            }
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
        if (memblock_unref_device(ctx, &mem_16747, "mem_16747") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_16760, "mem_16760") != 0)
            return 1;
        if (memblock_set_device(ctx, &ext_mem_16767, &mem_16766, "mem_16766") !=
            0)
            return 1;
        if (memblock_unref_device(ctx, &mem_16766, "mem_16766") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_16760, "mem_16760") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_16753, "mem_16753") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_16747, "mem_16747") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_16742, "mem_16742") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_16735, "mem_16735") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_16729, "mem_16729") != 0)
            return 1;
    }
    
    int64_t y_16434 = n_14507 * newSizzeX_14509;
    int64_t nest_sizze_16435 = newSizzeY_14508 * y_16434;
    int64_t segmap_group_sizze_16436;
    
    segmap_group_sizze_16436 =
        *ctx->tuning_params.bicubicInterpolationImagezisegmap_group_sizze_16293;
    
    int64_t segmap_usable_groups_16437 = sdiv_up64(nest_sizze_16435,
                                                   segmap_group_sizze_16436);
    int64_t bytes_16770 = (int64_t) 4 * nest_sizze_16076;
    struct memblock_device mem_16771;
    
    mem_16771.references = NULL;
    if (memblock_alloc_device(ctx, &mem_16771, bytes_16770, "mem_16771")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhgpu_map_transpose_f32(ctx, mem_16771, (int64_t) 0,
                                              ext_mem_16767, (int64_t) 0,
                                              (int64_t) 1, newSizzeY_14508 *
                                              newSizzeX_14509, n_14507) != 0) {
        if (memblock_unref_device(ctx, &mem_16771, "mem_16771") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_16767, "ext_mem_16767") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_16795, "mem_out_16795") != 0)
            return 1;
        err = 1;
        goto cleanup;
    }
    if (memblock_unref_device(ctx, &ext_mem_16767, "ext_mem_16767") != 0)
        return 1;
    
    int64_t bytes_16776 = smax64((int64_t) 0, bytes_16770);
    struct memblock_device mem_16777;
    
    mem_16777.references = NULL;
    if (memblock_alloc_device(ctx, &mem_16777, bytes_16776, "mem_16777")) {
        err = 1;
        goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    CUdeviceptr kernel_arg_17041 = mem_16771.mem;
    CUdeviceptr kernel_arg_17042 = mem_16777.mem;
    
    if ((((((1 && segmap_usable_groups_16437 != 0) && 1 != 0) && 1 != 0) &&
          segmap_group_sizze_16436 != 0) && 1 != 0) && 1 != 0) {
        int perm[3] = {0, 1, 2};
        
        if (1 >= 1 << 16) {
            perm[1] = perm[0];
            perm[0] = 1;
        }
        if (1 >= 1 << 16) {
            perm[2] = perm[0];
            perm[0] = 2;
        }
        
        size_t grid[3];
        
        grid[perm[0]] = segmap_usable_groups_16437;
        grid[perm[1]] = 1;
        grid[perm[2]] = 1;
        
        void *kernel_args_17038[] = {&ctx->global_failure, &n_14507,
                                     &newSizzeY_14508, &newSizzeX_14509,
                                     &kernel_arg_17041, &kernel_arg_17042};
        int64_t time_start_17039 = 0, time_end_17040 = 0;
        
        if (ctx->debugging) {
            fprintf(ctx->log,
                    "Launching %s with grid size [%ld, %ld, %ld] and block size [%ld, %ld, %ld]; shared memory: %d bytes.\n",
                    "bicubicInterpolationImage.segmap_16442",
                    (long) segmap_usable_groups_16437, (long) 1, (long) 1,
                    (long) segmap_group_sizze_16436, (long) 1, (long) 1,
                    (int) 0);
            time_start_17039 = get_wall_time();
        }
        
        cudaEvent_t *pevents = NULL;
        
        if (ctx->profiling && !ctx->profiling_paused) {
            pevents = cuda_get_events(&ctx->cuda,
                                      &ctx->bicubicInterpolationImagezisegmap_16442_runs,
                                      &ctx->bicubicInterpolationImagezisegmap_16442_total_runtime);
            CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[0], 0));
        }
        CUDA_SUCCEED_OR_RETURN(cuLaunchKernel(ctx->bicubicInterpolationImagezisegmap_16442,
                                              grid[0], grid[1], grid[2],
                                              segmap_group_sizze_16436, 1, 1, 0,
                                              NULL, kernel_args_17038, NULL));
        if (pevents != NULL)
            CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[1], 0));
        if (ctx->debugging) {
            CUDA_SUCCEED_FATAL(cuCtxSynchronize());
            time_end_17040 = get_wall_time();
            fprintf(ctx->log, "Kernel %s runtime: %ldus\n",
                    "bicubicInterpolationImage.segmap_16442", time_end_17040 -
                    time_start_17039);
        }
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    if (memblock_unref_device(ctx, &mem_16771, "mem_16771") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_out_16795, &mem_16777, "mem_16777") != 0)
        return 1;
    (*mem_out_p_16989).references = NULL;
    if (memblock_set_device(ctx, &*mem_out_p_16989, &mem_out_16795,
                            "mem_out_16795") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_16777, "mem_16777") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_16771, "mem_16771") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ext_mem_16767, "ext_mem_16767") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_out_16795, "mem_out_16795") != 0)
        return 1;
    
  cleanup:
    { }
    return err;
}
static int futrts_entry_shuffler(struct futhark_context *ctx,
                                 struct memblock_device *mem_out_p_17043,
                                 int64_t seed_14665, int64_t h_14666,
                                 int64_t w_14667)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device mem_out_16795;
    
    mem_out_16795.references = NULL;
    
    int32_t i64_res_14668 = sext_i64_i32(seed_14665);
    int32_t unsign_arg_14669 = 5461 ^ i64_res_14668;
    int32_t unsign_arg_14670 = 1 ^ unsign_arg_14669;
    int32_t unsign_arg_14671 = mul32(48271, unsign_arg_14670);
    int32_t unsign_arg_14672 = umod32(unsign_arg_14671, 2147483647);
    int64_t frameSizze_14673 = mul64(h_14666, w_14667);
    bool bounds_invalid_upwards_14674 = slt64(h_14666, (int64_t) 0);
    bool valid_14675 = !bounds_invalid_upwards_14674;
    bool range_valid_c_14676;
    
    if (!valid_14675) {
        ctx->error = msgprintf("Error: %s%lld%s%lld%s%lld%s\n\nBacktrace:\n%s",
                               "Range ", (long long) (int64_t) 0, "..",
                               (long long) (int64_t) 1, "..<",
                               (long long) h_14666, " is invalid.",
                               "-> #0  /prelude/array.fut:90:3-10\n   #1  /prelude/array.fut:203:28-33\n   #2  fut/shuffle.fut:26:37-75\n   #3  fut/entries.fut:12:29-51\n   #4  fut/entries.fut:7:1-13:33\n");
        if (memblock_unref_device(ctx, &mem_out_16795, "mem_out_16795") != 0)
            return 1;
        err = 1;
        goto cleanup;
    }
    
    bool bounds_invalid_upwards_14678 = slt64(w_14667, (int64_t) 0);
    bool valid_14679 = !bounds_invalid_upwards_14678;
    bool range_valid_c_14680;
    
    if (!valid_14679) {
        ctx->error = msgprintf("Error: %s%lld%s%lld%s%lld%s\n\nBacktrace:\n%s",
                               "Range ", (long long) (int64_t) 0, "..",
                               (long long) (int64_t) 1, "..<",
                               (long long) w_14667, " is invalid.",
                               "-> #0  /prelude/array.fut:90:3-10\n   #1  /prelude/array.fut:195:11-16\n   #2  /prelude/functional.fut:39:59-65\n   #3  /prelude/soacs.fut:59:3-10\n   #4  /prelude/array.fut:203:3-34\n   #5  fut/shuffle.fut:26:37-75\n   #6  fut/entries.fut:12:29-51\n   #7  fut/entries.fut:7:1-13:33\n");
        if (memblock_unref_device(ctx, &mem_out_16795, "mem_out_16795") != 0)
            return 1;
        err = 1;
        goto cleanup;
    }
    
    int64_t binop_y_16683 = (int64_t) 8 * w_14667;
    int64_t bytes_16684 = smax64((int64_t) 0, binop_y_16683);
    struct memblock_device mem_16685;
    
    mem_16685.references = NULL;
    if (memblock_alloc_device(ctx, &mem_16685, bytes_16684, "mem_16685")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhiota_i64(ctx, mem_16685, w_14667, (int64_t) 0,
                                 (int64_t) 1) != 0) {
        if (memblock_unref_device(ctx, &mem_16685, "mem_16685") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_16795, "mem_out_16795") != 0)
            return 1;
        err = 1;
        goto cleanup;
    }
    
    int64_t binop_y_16687 = (int64_t) 8 * frameSizze_14673;
    int64_t bytes_16688 = smax64((int64_t) 0, binop_y_16687);
    struct memblock_device mem_16689;
    
    mem_16689.references = NULL;
    if (memblock_alloc_device(ctx, &mem_16689, bytes_16688, "mem_16689")) {
        err = 1;
        goto cleanup;
    }
    
    int64_t group_sizze_16809;
    
    group_sizze_16809 = *ctx->tuning_params.shufflerzigroup_sizze_16809;
    
    int64_t num_groups_16810 = sdiv_up64(h_14666 * w_14667, group_sizze_16809);
    CUdeviceptr kernel_arg_17047 = mem_16685.mem;
    CUdeviceptr kernel_arg_17048 = mem_16689.mem;
    
    if ((((((1 && num_groups_16810 != 0) && 1 != 0) && 1 != 0) &&
          group_sizze_16809 != 0) && 1 != 0) && 1 != 0) {
        int perm[3] = {0, 1, 2};
        
        if (1 >= 1 << 16) {
            perm[1] = perm[0];
            perm[0] = 1;
        }
        if (1 >= 1 << 16) {
            perm[2] = perm[0];
            perm[0] = 2;
        }
        
        size_t grid[3];
        
        grid[perm[0]] = num_groups_16810;
        grid[perm[1]] = 1;
        grid[perm[2]] = 1;
        
        void *kernel_args_17044[] = {&h_14666, &w_14667, &kernel_arg_17047,
                                     &kernel_arg_17048};
        int64_t time_start_17045 = 0, time_end_17046 = 0;
        
        if (ctx->debugging) {
            fprintf(ctx->log,
                    "Launching %s with grid size [%ld, %ld, %ld] and block size [%ld, %ld, %ld]; shared memory: %d bytes.\n",
                    "shuffler.replicate_16806", (long) num_groups_16810,
                    (long) 1, (long) 1, (long) group_sizze_16809, (long) 1,
                    (long) 1, (int) 0);
            time_start_17045 = get_wall_time();
        }
        
        cudaEvent_t *pevents = NULL;
        
        if (ctx->profiling && !ctx->profiling_paused) {
            pevents = cuda_get_events(&ctx->cuda,
                                      &ctx->shufflerzireplicate_16806_runs,
                                      &ctx->shufflerzireplicate_16806_total_runtime);
            CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[0], 0));
        }
        CUDA_SUCCEED_OR_RETURN(cuLaunchKernel(ctx->shufflerzireplicate_16806,
                                              grid[0], grid[1], grid[2],
                                              group_sizze_16809, 1, 1, 0, NULL,
                                              kernel_args_17044, NULL));
        if (pevents != NULL)
            CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[1], 0));
        if (ctx->debugging) {
            CUDA_SUCCEED_FATAL(cuCtxSynchronize());
            time_end_17046 = get_wall_time();
            fprintf(ctx->log, "Kernel %s runtime: %ldus\n",
                    "shuffler.replicate_16806", time_end_17046 -
                    time_start_17045);
        }
    }
    if (memblock_unref_device(ctx, &mem_16685, "mem_16685") != 0)
        return 1;
    
    int64_t segmap_group_sizze_16495;
    
    segmap_group_sizze_16495 =
        *ctx->tuning_params.shufflerzisegmap_group_sizze_16471;
    
    int64_t segmap_usable_groups_16496 = sdiv_up64(frameSizze_14673,
                                                   segmap_group_sizze_16495);
    struct memblock_device mem_16694;
    
    mem_16694.references = NULL;
    if (memblock_alloc_device(ctx, &mem_16694, bytes_16688, "mem_16694")) {
        err = 1;
        goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    CUdeviceptr kernel_arg_17052 = mem_16694.mem;
    
    if ((((((1 && segmap_usable_groups_16496 != 0) && 1 != 0) && 1 != 0) &&
          segmap_group_sizze_16495 != 0) && 1 != 0) && 1 != 0) {
        int perm[3] = {0, 1, 2};
        
        if (1 >= 1 << 16) {
            perm[1] = perm[0];
            perm[0] = 1;
        }
        if (1 >= 1 << 16) {
            perm[2] = perm[0];
            perm[0] = 2;
        }
        
        size_t grid[3];
        
        grid[perm[0]] = segmap_usable_groups_16496;
        grid[perm[1]] = 1;
        grid[perm[2]] = 1;
        
        void *kernel_args_17049[] = {&ctx->global_failure, &h_14666, &w_14667,
                                     &kernel_arg_17052};
        int64_t time_start_17050 = 0, time_end_17051 = 0;
        
        if (ctx->debugging) {
            fprintf(ctx->log,
                    "Launching %s with grid size [%ld, %ld, %ld] and block size [%ld, %ld, %ld]; shared memory: %d bytes.\n",
                    "shuffler.segmap_16500", (long) segmap_usable_groups_16496,
                    (long) 1, (long) 1, (long) segmap_group_sizze_16495,
                    (long) 1, (long) 1, (int) 0);
            time_start_17050 = get_wall_time();
        }
        
        cudaEvent_t *pevents = NULL;
        
        if (ctx->profiling && !ctx->profiling_paused) {
            pevents = cuda_get_events(&ctx->cuda,
                                      &ctx->shufflerzisegmap_16500_runs,
                                      &ctx->shufflerzisegmap_16500_total_runtime);
            CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[0], 0));
        }
        CUDA_SUCCEED_OR_RETURN(cuLaunchKernel(ctx->shufflerzisegmap_16500,
                                              grid[0], grid[1], grid[2],
                                              segmap_group_sizze_16495, 1, 1, 0,
                                              NULL, kernel_args_17049, NULL));
        if (pevents != NULL)
            CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[1], 0));
        if (ctx->debugging) {
            CUDA_SUCCEED_FATAL(cuCtxSynchronize());
            time_end_17051 = get_wall_time();
            fprintf(ctx->log, "Kernel %s runtime: %ldus\n",
                    "shuffler.segmap_16500", time_end_17051 - time_start_17050);
        }
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    
    bool loop_nonempty_14686 = slt64((int64_t) 0, frameSizze_14673);
    bool zzero_14687 = w_14667 == (int64_t) 0;
    bool nonzzero_14688 = !zzero_14687;
    bool loop_not_taken_14689 = !loop_nonempty_14686;
    bool protect_assert_disj_14690 = nonzzero_14688 || loop_not_taken_14689;
    bool nonzzero_cert_14691;
    
    if (!protect_assert_disj_14690) {
        ctx->error = msgprintf("Error: %s\n\nBacktrace:\n%s",
                               "division by zero",
                               "-> #0  fut/shuffle.fut:28:25-29\n   #1  fut/entries.fut:12:29-51\n   #2  fut/entries.fut:7:1-13:33\n");
        if (memblock_unref_device(ctx, &mem_16694, "mem_16694") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_16689, "mem_16689") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_16685, "mem_16685") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_16795, "mem_out_16795") != 0)
            return 1;
        err = 1;
        goto cleanup;
    }
    
    int64_t uniformPick_arg_14692 = sub64(h_14666, (int64_t) 1);
    int64_t uniformPick_arg_14693 = sub64(w_14667, (int64_t) 1);
    int32_t unsign_arg_14694 = zext_i64_i32(uniformPick_arg_14692);
    int32_t unsign_arg_14695 = add32(1, unsign_arg_14694);
    bool zlze_res_14696 = ule32(unsign_arg_14695, 0);
    int32_t unsign_arg_14697 = zext_i64_i32(uniformPick_arg_14693);
    int32_t unsign_arg_14698 = add32(1, unsign_arg_14697);
    bool zlze_res_14699 = ule32(unsign_arg_14698, 0);
    int32_t shuffleField_2d_res_14700;
    int32_t rng0_14704 = unsign_arg_14672;
    
    for (int64_t i_14703 = 0; i_14703 < frameSizze_14673; i_14703++) {
        int64_t fromH_14707 = sdiv64(i_14703, w_14667);
        int64_t fromW_14708 = smod64(i_14703, w_14667);
        int32_t rand_res_14709;
        int64_t rand_res_14710;
        
        if (zlze_res_14696) {
            rand_res_14709 = rng0_14704;
            rand_res_14710 = (int64_t) 0;
        } else {
            int32_t unsign_arg_14711 = umod32(2147483647, unsign_arg_14695);
            int32_t unsign_arg_14712 = sub32(2147483647, unsign_arg_14711);
            int32_t unsign_arg_14713 = mul32(48271, rng0_14704);
            int32_t unsign_arg_14714 = umod32(unsign_arg_14713, 2147483647);
            bool zgze_res_14715 = ule32(unsign_arg_14712, unsign_arg_14714);
            bool rand_res_f_res_14716;
            int32_t rand_res_f_res_14717;
            int32_t rand_res_f_res_14718;
            bool loop_while_14719;
            int32_t rng_14720;
            int32_t x_14721;
            
            loop_while_14719 = zgze_res_14715;
            rng_14720 = unsign_arg_14714;
            x_14721 = unsign_arg_14714;
            while (loop_while_14719) {
                int32_t unsign_arg_14722 = mul32(48271, rng_14720);
                int32_t unsign_arg_14723 = umod32(unsign_arg_14722, 2147483647);
                bool zgze_res_14724 = ule32(unsign_arg_14712, unsign_arg_14723);
                bool loop_while_tmp_16831 = zgze_res_14724;
                int32_t rng_tmp_16832 = unsign_arg_14723;
                int32_t x_tmp_16833 = unsign_arg_14723;
                
                loop_while_14719 = loop_while_tmp_16831;
                rng_14720 = rng_tmp_16832;
                x_14721 = x_tmp_16833;
            }
            rand_res_f_res_14716 = loop_while_14719;
            rand_res_f_res_14717 = rng_14720;
            rand_res_f_res_14718 = x_14721;
            
            int32_t unsign_arg_14725 = umod32(rand_res_f_res_14718,
                                              unsign_arg_14695);
            int64_t to_i64_res_14726 = zext_i32_i64(unsign_arg_14725);
            
            rand_res_14709 = rand_res_f_res_14717;
            rand_res_14710 = to_i64_res_14726;
        }
        
        int32_t rand_res_14727;
        int64_t rand_res_14728;
        
        if (zlze_res_14699) {
            rand_res_14727 = rand_res_14709;
            rand_res_14728 = (int64_t) 0;
        } else {
            int32_t unsign_arg_14729 = umod32(2147483647, unsign_arg_14698);
            int32_t unsign_arg_14730 = sub32(2147483647, unsign_arg_14729);
            int32_t unsign_arg_14731 = mul32(48271, rand_res_14709);
            int32_t unsign_arg_14732 = umod32(unsign_arg_14731, 2147483647);
            bool zgze_res_14733 = ule32(unsign_arg_14730, unsign_arg_14732);
            bool rand_res_f_res_14734;
            int32_t rand_res_f_res_14735;
            int32_t rand_res_f_res_14736;
            bool loop_while_14737;
            int32_t rng_14738;
            int32_t x_14739;
            
            loop_while_14737 = zgze_res_14733;
            rng_14738 = unsign_arg_14732;
            x_14739 = unsign_arg_14732;
            while (loop_while_14737) {
                int32_t unsign_arg_14740 = mul32(48271, rng_14738);
                int32_t unsign_arg_14741 = umod32(unsign_arg_14740, 2147483647);
                bool zgze_res_14742 = ule32(unsign_arg_14730, unsign_arg_14741);
                bool loop_while_tmp_16834 = zgze_res_14742;
                int32_t rng_tmp_16835 = unsign_arg_14741;
                int32_t x_tmp_16836 = unsign_arg_14741;
                
                loop_while_14737 = loop_while_tmp_16834;
                rng_14738 = rng_tmp_16835;
                x_14739 = x_tmp_16836;
            }
            rand_res_f_res_14734 = loop_while_14737;
            rand_res_f_res_14735 = rng_14738;
            rand_res_f_res_14736 = x_14739;
            
            int32_t unsign_arg_14743 = umod32(rand_res_f_res_14736,
                                              unsign_arg_14698);
            int64_t to_i64_res_14744 = zext_i32_i64(unsign_arg_14743);
            
            rand_res_14727 = rand_res_f_res_14735;
            rand_res_14728 = to_i64_res_14744;
        }
        
        bool x_14745 = sle64((int64_t) 0, rand_res_14710);
        bool y_14746 = slt64(rand_res_14710, h_14666);
        bool bounds_check_14747 = x_14745 && y_14746;
        bool x_14748 = sle64((int64_t) 0, rand_res_14728);
        bool y_14749 = slt64(rand_res_14728, w_14667);
        bool bounds_check_14750 = x_14748 && y_14749;
        bool index_ok_14751 = bounds_check_14747 && bounds_check_14750;
        bool index_certs_14752;
        
        if (!index_ok_14751) {
            ctx->error =
                msgprintf("Error: %s%lld%s%lld%s%lld%s%lld%s\n\nBacktrace:\n%s",
                          "Index [", (long long) rand_res_14710, ", ",
                          (long long) rand_res_14728,
                          "] out of bounds for array of shape [",
                          (long long) h_14666, "][", (long long) w_14667, "].",
                          "-> #0  fut/shuffle.fut:17:18-35\n   #1  fut/shuffle.fut:32:24-57\n   #2  fut/entries.fut:12:29-51\n   #3  fut/entries.fut:7:1-13:33\n");
            if (memblock_unref_device(ctx, &mem_16694, "mem_16694") != 0)
                return 1;
            if (memblock_unref_device(ctx, &mem_16689, "mem_16689") != 0)
                return 1;
            if (memblock_unref_device(ctx, &mem_16685, "mem_16685") != 0)
                return 1;
            if (memblock_unref_device(ctx, &mem_out_16795, "mem_out_16795") !=
                0)
                return 1;
            err = 1;
            goto cleanup;
        }
        
        int64_t swap_2d_res_14753;
        int64_t read_res_17053;
        
        {
            cudaEvent_t *pevents = NULL;
            
            if (ctx->profiling && !ctx->profiling_paused) {
                pevents = cuda_get_events(&ctx->cuda,
                                          &ctx->copy_scalar_from_dev_runs,
                                          &ctx->copy_scalar_from_dev_total_runtime);
                CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[0], 0));
            }
            CUDA_SUCCEED_OR_RETURN(cuMemcpyDtoH(&read_res_17053, mem_16694.mem +
                                                (rand_res_14710 * w_14667 +
                                                 rand_res_14728) *
                                                sizeof(int64_t),
                                                sizeof(int64_t)));
            if (pevents != NULL)
                CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[1], 0));
        }
        if (futhark_context_sync(ctx) != 0)
            return 1;
        swap_2d_res_14753 = read_res_17053;
        
        int64_t swap_2d_res_14754;
        int64_t read_res_17054;
        
        {
            cudaEvent_t *pevents = NULL;
            
            if (ctx->profiling && !ctx->profiling_paused) {
                pevents = cuda_get_events(&ctx->cuda,
                                          &ctx->copy_scalar_from_dev_runs,
                                          &ctx->copy_scalar_from_dev_total_runtime);
                CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[0], 0));
            }
            CUDA_SUCCEED_OR_RETURN(cuMemcpyDtoH(&read_res_17054, mem_16689.mem +
                                                (rand_res_14710 * w_14667 +
                                                 rand_res_14728) *
                                                sizeof(int64_t),
                                                sizeof(int64_t)));
            if (pevents != NULL)
                CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[1], 0));
        }
        if (futhark_context_sync(ctx) != 0)
            return 1;
        swap_2d_res_14754 = read_res_17054;
        
        bool x_14755 = sle64((int64_t) 0, fromH_14707);
        bool y_14756 = slt64(fromH_14707, h_14666);
        bool bounds_check_14757 = x_14755 && y_14756;
        bool x_14758 = sle64((int64_t) 0, fromW_14708);
        bool y_14759 = slt64(fromW_14708, w_14667);
        bool bounds_check_14760 = x_14758 && y_14759;
        bool index_ok_14761 = bounds_check_14757 && bounds_check_14760;
        bool index_certs_14762;
        
        if (!index_ok_14761) {
            ctx->error =
                msgprintf("Error: %s%lld%s%lld%s%lld%s%lld%s\n\nBacktrace:\n%s",
                          "Index [", (long long) fromH_14707, ", ",
                          (long long) fromW_14708,
                          "] out of bounds for array of shape [",
                          (long long) h_14666, "][", (long long) w_14667, "].",
                          "-> #0  fut/shuffle.fut:18:46-63\n   #1  fut/shuffle.fut:32:24-57\n   #2  fut/entries.fut:12:29-51\n   #3  fut/entries.fut:7:1-13:33\n");
            if (memblock_unref_device(ctx, &mem_16694, "mem_16694") != 0)
                return 1;
            if (memblock_unref_device(ctx, &mem_16689, "mem_16689") != 0)
                return 1;
            if (memblock_unref_device(ctx, &mem_16685, "mem_16685") != 0)
                return 1;
            if (memblock_unref_device(ctx, &mem_out_16795, "mem_out_16795") !=
                0)
                return 1;
            err = 1;
            goto cleanup;
        }
        
        int64_t lw_val_14763;
        int64_t read_res_17055;
        
        {
            cudaEvent_t *pevents = NULL;
            
            if (ctx->profiling && !ctx->profiling_paused) {
                pevents = cuda_get_events(&ctx->cuda,
                                          &ctx->copy_scalar_from_dev_runs,
                                          &ctx->copy_scalar_from_dev_total_runtime);
                CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[0], 0));
            }
            CUDA_SUCCEED_OR_RETURN(cuMemcpyDtoH(&read_res_17055, mem_16694.mem +
                                                (fromH_14707 * w_14667 +
                                                 fromW_14708) * sizeof(int64_t),
                                                sizeof(int64_t)));
            if (pevents != NULL)
                CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[1], 0));
        }
        if (futhark_context_sync(ctx) != 0)
            return 1;
        lw_val_14763 = read_res_17055;
        
        int64_t lw_val_14764;
        int64_t read_res_17056;
        
        {
            cudaEvent_t *pevents = NULL;
            
            if (ctx->profiling && !ctx->profiling_paused) {
                pevents = cuda_get_events(&ctx->cuda,
                                          &ctx->copy_scalar_from_dev_runs,
                                          &ctx->copy_scalar_from_dev_total_runtime);
                CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[0], 0));
            }
            CUDA_SUCCEED_OR_RETURN(cuMemcpyDtoH(&read_res_17056, mem_16689.mem +
                                                (fromH_14707 * w_14667 +
                                                 fromW_14708) * sizeof(int64_t),
                                                sizeof(int64_t)));
            if (pevents != NULL)
                CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[1], 0));
        }
        if (futhark_context_sync(ctx) != 0)
            return 1;
        lw_val_14764 = read_res_17056;
        {
            int64_t write_tmp_17057 = lw_val_14763;
            cudaEvent_t *pevents = NULL;
            
            if (ctx->profiling && !ctx->profiling_paused) {
                pevents = cuda_get_events(&ctx->cuda,
                                          &ctx->copy_scalar_to_dev_runs,
                                          &ctx->copy_scalar_to_dev_total_runtime);
                CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[0], 0));
            }
            CUDA_SUCCEED_OR_RETURN(cuMemcpyHtoD(mem_16694.mem +
                                                (rand_res_14710 * w_14667 +
                                                 rand_res_14728) *
                                                sizeof(int64_t),
                                                &write_tmp_17057,
                                                sizeof(int64_t)));
            if (pevents != NULL)
                CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[1], 0));
        }
        {
            int64_t write_tmp_17058 = lw_val_14764;
            cudaEvent_t *pevents = NULL;
            
            if (ctx->profiling && !ctx->profiling_paused) {
                pevents = cuda_get_events(&ctx->cuda,
                                          &ctx->copy_scalar_to_dev_runs,
                                          &ctx->copy_scalar_to_dev_total_runtime);
                CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[0], 0));
            }
            CUDA_SUCCEED_OR_RETURN(cuMemcpyHtoD(mem_16689.mem +
                                                (rand_res_14710 * w_14667 +
                                                 rand_res_14728) *
                                                sizeof(int64_t),
                                                &write_tmp_17058,
                                                sizeof(int64_t)));
            if (pevents != NULL)
                CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[1], 0));
        }
        {
            int64_t write_tmp_17059 = swap_2d_res_14753;
            cudaEvent_t *pevents = NULL;
            
            if (ctx->profiling && !ctx->profiling_paused) {
                pevents = cuda_get_events(&ctx->cuda,
                                          &ctx->copy_scalar_to_dev_runs,
                                          &ctx->copy_scalar_to_dev_total_runtime);
                CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[0], 0));
            }
            CUDA_SUCCEED_OR_RETURN(cuMemcpyHtoD(mem_16694.mem + (fromH_14707 *
                                                                 w_14667 +
                                                                 fromW_14708) *
                                                sizeof(int64_t),
                                                &write_tmp_17059,
                                                sizeof(int64_t)));
            if (pevents != NULL)
                CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[1], 0));
        }
        {
            int64_t write_tmp_17060 = swap_2d_res_14754;
            cudaEvent_t *pevents = NULL;
            
            if (ctx->profiling && !ctx->profiling_paused) {
                pevents = cuda_get_events(&ctx->cuda,
                                          &ctx->copy_scalar_to_dev_runs,
                                          &ctx->copy_scalar_to_dev_total_runtime);
                CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[0], 0));
            }
            CUDA_SUCCEED_OR_RETURN(cuMemcpyHtoD(mem_16689.mem + (fromH_14707 *
                                                                 w_14667 +
                                                                 fromW_14708) *
                                                sizeof(int64_t),
                                                &write_tmp_17060,
                                                sizeof(int64_t)));
            if (pevents != NULL)
                CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[1], 0));
        }
        
        int32_t rng0_tmp_16828 = rand_res_14727;
        
        rng0_14704 = rng0_tmp_16828;
    }
    shuffleField_2d_res_14700 = rng0_14704;
    
    int64_t segmap_group_sizze_16549;
    
    segmap_group_sizze_16549 =
        *ctx->tuning_params.shufflerzisegmap_group_sizze_16519;
    
    int64_t num_groups_16550;
    int32_t max_num_groups_16837;
    
    max_num_groups_16837 =
        *ctx->tuning_params.shufflerzisegmap_num_groups_16521;
    num_groups_16550 = sext_i64_i32(smax64((int64_t) 1,
                                           smin64(sdiv_up64(frameSizze_14673,
                                                            segmap_group_sizze_16549),
                                                  sext_i32_i64(max_num_groups_16837))));
    
    int64_t binop_x_16733 = (int64_t) 2 * h_14666;
    int64_t binop_x_16734 = w_14667 * binop_x_16733;
    int64_t bytes_16735 = (int64_t) 8 * binop_x_16734;
    struct memblock_device mem_16736;
    
    mem_16736.references = NULL;
    if (memblock_alloc_device(ctx, &mem_16736, bytes_16735, "mem_16736")) {
        err = 1;
        goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    CUdeviceptr kernel_arg_17064 = mem_16689.mem;
    CUdeviceptr kernel_arg_17065 = mem_16694.mem;
    CUdeviceptr kernel_arg_17066 = mem_16736.mem;
    
    if ((((((1 && num_groups_16550 != 0) && 1 != 0) && 1 != 0) &&
          segmap_group_sizze_16549 != 0) && 1 != 0) && 1 != 0) {
        int perm[3] = {0, 1, 2};
        
        if (1 >= 1 << 16) {
            perm[1] = perm[0];
            perm[0] = 1;
        }
        if (1 >= 1 << 16) {
            perm[2] = perm[0];
            perm[0] = 2;
        }
        
        size_t grid[3];
        
        grid[perm[0]] = num_groups_16550;
        grid[perm[1]] = 1;
        grid[perm[2]] = 1;
        
        void *kernel_args_17061[] = {&ctx->global_failure, &h_14666, &w_14667,
                                     &num_groups_16550, &kernel_arg_17064,
                                     &kernel_arg_17065, &kernel_arg_17066};
        int64_t time_start_17062 = 0, time_end_17063 = 0;
        
        if (ctx->debugging) {
            fprintf(ctx->log,
                    "Launching %s with grid size [%ld, %ld, %ld] and block size [%ld, %ld, %ld]; shared memory: %d bytes.\n",
                    "shuffler.segmap_16555", (long) num_groups_16550, (long) 1,
                    (long) 1, (long) segmap_group_sizze_16549, (long) 1,
                    (long) 1, (int) 0);
            time_start_17062 = get_wall_time();
        }
        
        cudaEvent_t *pevents = NULL;
        
        if (ctx->profiling && !ctx->profiling_paused) {
            pevents = cuda_get_events(&ctx->cuda,
                                      &ctx->shufflerzisegmap_16555_runs,
                                      &ctx->shufflerzisegmap_16555_total_runtime);
            CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[0], 0));
        }
        CUDA_SUCCEED_OR_RETURN(cuLaunchKernel(ctx->shufflerzisegmap_16555,
                                              grid[0], grid[1], grid[2],
                                              segmap_group_sizze_16549, 1, 1, 0,
                                              NULL, kernel_args_17061, NULL));
        if (pevents != NULL)
            CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[1], 0));
        if (ctx->debugging) {
            CUDA_SUCCEED_FATAL(cuCtxSynchronize());
            time_end_17063 = get_wall_time();
            fprintf(ctx->log, "Kernel %s runtime: %ldus\n",
                    "shuffler.segmap_16555", time_end_17063 - time_start_17062);
        }
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    if (memblock_unref_device(ctx, &mem_16689, "mem_16689") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_16694, "mem_16694") != 0)
        return 1;
    
    int64_t binop_x_16738 = (int64_t) 2 * frameSizze_14673;
    int64_t binop_y_16739 = (int64_t) 8 * binop_x_16738;
    int64_t bytes_16740 = smax64((int64_t) 0, binop_y_16739);
    struct memblock_device mem_16741;
    
    mem_16741.references = NULL;
    if (memblock_alloc_device(ctx, &mem_16741, bytes_16740, "mem_16741")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhgpu_map_transpose_i64(ctx, mem_16741, (int64_t) 0,
                                              mem_16736, (int64_t) 0,
                                              (int64_t) 1, h_14666 * w_14667,
                                              (int64_t) 2) != 0) {
        if (memblock_unref_device(ctx, &mem_16741, "mem_16741") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_16736, "mem_16736") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_16694, "mem_16694") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_16689, "mem_16689") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_16685, "mem_16685") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_16795, "mem_out_16795") != 0)
            return 1;
        err = 1;
        goto cleanup;
    }
    if (memblock_unref_device(ctx, &mem_16736, "mem_16736") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_out_16795, &mem_16741, "mem_16741") != 0)
        return 1;
    (*mem_out_p_17043).references = NULL;
    if (memblock_set_device(ctx, &*mem_out_p_17043, &mem_out_16795,
                            "mem_out_16795") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_16741, "mem_16741") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_16736, "mem_16736") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_16694, "mem_16694") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_16689, "mem_16689") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_16685, "mem_16685") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_out_16795, "mem_out_16795") != 0)
        return 1;
    
  cleanup:
    { }
    return err;
}

int futhark_entry_bicubicInterpolationImage(struct futhark_context *ctx,
                                            struct futhark_f32_3d **out0, const
                                            int64_t in0, const int64_t in1,
                                            const struct futhark_f32_3d *in2)
{
    struct memblock_device input_mem_16683;
    
    input_mem_16683.references = NULL;
    
    int64_t h_14505;
    int64_t w_14506;
    int64_t n_14507;
    int64_t newSizzeY_14508;
    int64_t newSizzeX_14509;
    struct memblock_device mem_out_16795;
    
    mem_out_16795.references = NULL;
    
    int ret = 0;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cuda.cu_ctx));
    newSizzeY_14508 = in0;
    newSizzeX_14509 = in1;
    input_mem_16683 = in2->mem;
    h_14505 = in2->shape[0];
    w_14506 = in2->shape[1];
    n_14507 = in2->shape[2];
    if (!(h_14505 == in2->shape[0] && (w_14506 == in2->shape[1] && n_14507 ==
                                       in2->shape[2]))) {
        ret = 1;
        if (!ctx->error)
            ctx->error =
                msgprintf("Error: entry point arguments have invalid sizes.\n");
    }
    if (ret == 0) {
        ret = futrts_entry_bicubicInterpolationImage(ctx, &mem_out_16795,
                                                     input_mem_16683, h_14505,
                                                     w_14506, n_14507,
                                                     newSizzeY_14508,
                                                     newSizzeX_14509);
        if (ret == 0) {
            assert((*out0 =
                    (struct futhark_f32_3d *) malloc(sizeof(struct futhark_f32_3d))) !=
                NULL);
            (*out0)->mem = mem_out_16795;
            (*out0)->shape[0] = newSizzeY_14508;
            (*out0)->shape[1] = newSizzeX_14509;
            (*out0)->shape[2] = n_14507;
        }
    }
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cuda.cu_ctx));
    lock_unlock(&ctx->lock);
    return ret;
}
int futhark_entry_shuffler(struct futhark_context *ctx,
                           struct futhark_i64_3d **out0, const int64_t in0,
                           const int64_t in1, const int64_t in2)
{
    int64_t seed_14665;
    int64_t h_14666;
    int64_t w_14667;
    struct memblock_device mem_out_16795;
    
    mem_out_16795.references = NULL;
    
    int ret = 0;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cuda.cu_ctx));
    seed_14665 = in0;
    h_14666 = in1;
    w_14667 = in2;
    if (ret == 0) {
        ret = futrts_entry_shuffler(ctx, &mem_out_16795, seed_14665, h_14666,
                                    w_14667);
        if (ret == 0) {
            assert((*out0 =
                    (struct futhark_i64_3d *) malloc(sizeof(struct futhark_i64_3d))) !=
                NULL);
            (*out0)->mem = mem_out_16795;
            (*out0)->shape[0] = h_14666;
            (*out0)->shape[1] = w_14667;
            (*out0)->shape[2] = (int64_t) 2;
        }
    }
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cuda.cu_ctx));
    lock_unlock(&ctx->lock);
    return ret;
}
  
